{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# <center>Record Linkage</center>\n",
    "## <center>Vince Marinelli<br>CPSC548 Spring 2025</center>\n",
    "\n",
    "Record Linkage refers to the task of linking records using a matching set of attributes shared by the two records. For example, we often need to match a list customers with a list of payees, or a list of patients with a list of users of a specific medication, etc. Another common example is the identification and removal of duplicate entries within a dataset. Record Linkage has also been referred to as data linkage, entity resolution, and data matching (<ins>Christen. 2019</ins>).\n",
    "\n",
    "In the simplest case, we have a shared attribute that represents a unique identifier for the record (e.g. SSN, TIN, ISBN, etc). In this case we may assume that this identifier absolutely and completely identities the unique entity. Unfortunately, outside of the world of controlled schemas this is rarely true. More often, we need to use the full set of attributes that can be mapped between the two rows to develop a level of confidence that the two rows are the same. The attributes used to match are referred to as Quasi-Identifiers (QIDs). Each QID contributes a specific weight to the overall match probability that is proportional to the amount of information that the QID contributes. For example, a matching street address contributes a larger weight than a matching marital status because the street address has a higher cardinality / lower match probability then marital status.\n",
    "\n",
    "The seminal work on record matching, **A Theory for Record Linkage**. was published in 1969 by Fellegi and Sunter. In the paper, the authors lay out a statistical theoretical basis for optimal record matching. It was later shown that this statistical basis is effectively the same as a Naive Baisian Classifer with the conditional independence assumption relaxed (<ins>Winkler, 2012</ins>). These statistical models remain mainstream today but are being challenged by newer models that use other types of classifiers.\n",
    "\n",
    "In his 2012 book **Data Matching**, Peter Christen lays out the basic process that has historically been followed. The process contains the following steps (<ins>Christen, 2012, pp. 24-35</ins>):\n",
    "\n",
    "1. Preprocessing - scrub and format record sets to be compared\n",
    "2. Indexing - match each record from one data to records in the comparison data set\n",
    "3. Comparison - compute similarity between a record and all possible comparators\n",
    "4. Classification - classify records as matches or non-matches (or possible matches in some cases)\n",
    "5. Evaluation - review the performance of the classification\n",
    "\n",
    "Before delving into these steps in more detail, we will first review the Python library we will be using both for test data and for the execution of many of the above steps."
   ],
   "id": "301ce835310565cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Using the Python Record Linkage Toolkit (PRLT)\n",
    "The [Python Record Linkage Toolkit](https://recordlinkage.readthedocs.io/en/latest/index.html) is a PyPi-hosted library that implements a standard set of record linkage activities. It includes tools for preprocessing data, indexing, comparison, classification and evaluation. The toolkit also contains several datasets that can be used to train and test algorithms.\n",
    "\n",
    "First, we'll import all the modules that we'll be using in this workbook, including PRLT.\n",
    "\n",
    "> NOTE: Some modules used in this project are not compatible with Python versions 3.12 and higher. It's required that we use a Python 3.11 Virtual Enviroment for this project."
   ],
   "id": "78c1b677b3530447"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:09.208864Z",
     "start_time": "2025-05-14T02:59:06.594837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import re\n",
    "import recordlinkage\n",
    "import swifter\n",
    "import time\n",
    "import us\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from datasketch import MinHash, LeanMinHash, MinHashLSH\n",
    "from nameparser import HumanName\n",
    "from nameparser.config import Constants\n",
    "from recordlinkage.datasets import load_febrl4\n",
    "from recordlinkage.base import BaseIndexAlgorithm\n",
    "from recordlinkage.preprocessing import phonetic"
   ],
   "id": "9a6d0e5cd8defe6e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that the modules have been imported, we will load data from the Freely Extensible Biomedical Record Linkage (febrl) package which is included in PRLT. Calling the `load_febrl4` method returns two datasets - one which contains all original records and a second that contains copies of the records from the first dataset, with duplicates included. A third output, a Pandas MultiIndex, can optionally be returned that contains the actual map from rows in the first dataframe to rows in the second (<ins>de Bruin, 2023</ins>). We'll retrieve all three objects and display them.",
   "id": "a7c4c485b02c032b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:09.269899Z",
     "start_time": "2025-05-14T02:59:09.218872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfA, dfB, miTrueLinks = load_febrl4(return_links=True)\n",
    "dfA"
   ],
   "id": "16efdac8b049f85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             given_name    surname street_number            address_1  \\\n",
       "rec_id                                                                  \n",
       "rec-1070-org   michaela    neumann             8       stanley street   \n",
       "rec-1016-org   courtney    painter            12    pinkerton circuit   \n",
       "rec-4405-org    charles      green            38  salkauskas crescent   \n",
       "rec-1288-org    vanessa       parr           905       macquoid place   \n",
       "rec-3585-org    mikayla   malloney            37        randwick road   \n",
       "...                 ...        ...           ...                  ...   \n",
       "rec-2153-org    annabel   grierson            97   mclachlan crescent   \n",
       "rec-1604-org     sienna   musolino            22      smeaton circuit   \n",
       "rec-1003-org    bradley   matthews             2         jondol place   \n",
       "rec-4883-org     brodee       egan            88          axon street   \n",
       "rec-66-org        koula  houweling             3       mileham street   \n",
       "\n",
       "                        address_2            suburb postcode state  \\\n",
       "rec_id                                                               \n",
       "rec-1070-org                miami     winston hills     4223   nsw   \n",
       "rec-1016-org           bega flats         richlands     4560   vic   \n",
       "rec-4405-org                 kela             dapto     4566   nsw   \n",
       "rec-1288-org    broadbridge manor     south grafton     2135    sa   \n",
       "rec-3585-org              avalind  hoppers crossing     4552   vic   \n",
       "...                           ...               ...      ...   ...   \n",
       "rec-2153-org        lantana lodge            broome     2480   nsw   \n",
       "rec-1604-org              pangani          mckinnon     2700   nsw   \n",
       "rec-1003-org         horseshoe ck       jacobs well     7018    sa   \n",
       "rec-4883-org          greenslopes          wamberal     2067   qld   \n",
       "rec-66-org    old airdmillan road      williamstown     2350   nsw   \n",
       "\n",
       "             date_of_birth soc_sec_id  \n",
       "rec_id                                 \n",
       "rec-1070-org      19151111    5304218  \n",
       "rec-1016-org      19161214    4066625  \n",
       "rec-4405-org      19480930    4365168  \n",
       "rec-1288-org      19951119    9239102  \n",
       "rec-3585-org      19860208    7207688  \n",
       "...                    ...        ...  \n",
       "rec-2153-org      19840224    7676186  \n",
       "rec-1604-org      19890525    4971506  \n",
       "rec-1003-org      19481122    8927667  \n",
       "rec-4883-org      19121113    6039042  \n",
       "rec-66-org        19440718    6375537  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-1070-org</th>\n",
       "      <td>michaela</td>\n",
       "      <td>neumann</td>\n",
       "      <td>8</td>\n",
       "      <td>stanley street</td>\n",
       "      <td>miami</td>\n",
       "      <td>winston hills</td>\n",
       "      <td>4223</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19151111</td>\n",
       "      <td>5304218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1016-org</th>\n",
       "      <td>courtney</td>\n",
       "      <td>painter</td>\n",
       "      <td>12</td>\n",
       "      <td>pinkerton circuit</td>\n",
       "      <td>bega flats</td>\n",
       "      <td>richlands</td>\n",
       "      <td>4560</td>\n",
       "      <td>vic</td>\n",
       "      <td>19161214</td>\n",
       "      <td>4066625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4405-org</th>\n",
       "      <td>charles</td>\n",
       "      <td>green</td>\n",
       "      <td>38</td>\n",
       "      <td>salkauskas crescent</td>\n",
       "      <td>kela</td>\n",
       "      <td>dapto</td>\n",
       "      <td>4566</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19480930</td>\n",
       "      <td>4365168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1288-org</th>\n",
       "      <td>vanessa</td>\n",
       "      <td>parr</td>\n",
       "      <td>905</td>\n",
       "      <td>macquoid place</td>\n",
       "      <td>broadbridge manor</td>\n",
       "      <td>south grafton</td>\n",
       "      <td>2135</td>\n",
       "      <td>sa</td>\n",
       "      <td>19951119</td>\n",
       "      <td>9239102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3585-org</th>\n",
       "      <td>mikayla</td>\n",
       "      <td>malloney</td>\n",
       "      <td>37</td>\n",
       "      <td>randwick road</td>\n",
       "      <td>avalind</td>\n",
       "      <td>hoppers crossing</td>\n",
       "      <td>4552</td>\n",
       "      <td>vic</td>\n",
       "      <td>19860208</td>\n",
       "      <td>7207688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2153-org</th>\n",
       "      <td>annabel</td>\n",
       "      <td>grierson</td>\n",
       "      <td>97</td>\n",
       "      <td>mclachlan crescent</td>\n",
       "      <td>lantana lodge</td>\n",
       "      <td>broome</td>\n",
       "      <td>2480</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19840224</td>\n",
       "      <td>7676186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1604-org</th>\n",
       "      <td>sienna</td>\n",
       "      <td>musolino</td>\n",
       "      <td>22</td>\n",
       "      <td>smeaton circuit</td>\n",
       "      <td>pangani</td>\n",
       "      <td>mckinnon</td>\n",
       "      <td>2700</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19890525</td>\n",
       "      <td>4971506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1003-org</th>\n",
       "      <td>bradley</td>\n",
       "      <td>matthews</td>\n",
       "      <td>2</td>\n",
       "      <td>jondol place</td>\n",
       "      <td>horseshoe ck</td>\n",
       "      <td>jacobs well</td>\n",
       "      <td>7018</td>\n",
       "      <td>sa</td>\n",
       "      <td>19481122</td>\n",
       "      <td>8927667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4883-org</th>\n",
       "      <td>brodee</td>\n",
       "      <td>egan</td>\n",
       "      <td>88</td>\n",
       "      <td>axon street</td>\n",
       "      <td>greenslopes</td>\n",
       "      <td>wamberal</td>\n",
       "      <td>2067</td>\n",
       "      <td>qld</td>\n",
       "      <td>19121113</td>\n",
       "      <td>6039042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-66-org</th>\n",
       "      <td>koula</td>\n",
       "      <td>houweling</td>\n",
       "      <td>3</td>\n",
       "      <td>mileham street</td>\n",
       "      <td>old airdmillan road</td>\n",
       "      <td>williamstown</td>\n",
       "      <td>2350</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19440718</td>\n",
       "      <td>6375537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:09.631740Z",
     "start_time": "2025-05-14T02:59:09.628309Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Length of dataframe dfA: {len(dfA)}')",
   "id": "8e805bf0ce509ea8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe dfA: 5000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:09.690647Z",
     "start_time": "2025-05-14T02:59:09.680760Z"
    }
   },
   "cell_type": "code",
   "source": "dfB",
   "id": "b0e2e1c4de4ee593",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               given_name    surname street_number             address_1  \\\n",
       "rec_id                                                                     \n",
       "rec-561-dup-0       elton        NaN             3         light setreet   \n",
       "rec-2642-dup-0   mitchell      maxon            47         edkins street   \n",
       "rec-608-dup-0         NaN      white            72       lambrigg street   \n",
       "rec-3239-dup-0      elk i    menzies             1          lyster place   \n",
       "rec-2886-dup-0        NaN  garanggar           NaN  may maxwell crescent   \n",
       "...                   ...        ...           ...                   ...   \n",
       "rec-4495-dup-0     connor   belperio            15                   NaN   \n",
       "rec-4211-dup-0     daniel      maspn             9   derrington crescent   \n",
       "rec-3131-dup-0     samuel      crofs           613        banjine street   \n",
       "rec-3815-dup-0       saah    beattih            60           kay's place   \n",
       "rec-493-dup-0         NaN  blackwell           127         ferrier place   \n",
       "\n",
       "                            address_2             suburb postcode state  \\\n",
       "rec_id                                                                    \n",
       "rec-561-dup-0                pinehill         windermere     3212   vic   \n",
       "rec-2642-dup-0              lochaoair         north ryde     3355   nsw   \n",
       "rec-608-dup-0                kelgoola  broadbeach waters     3159   vic   \n",
       "rec-3239-dup-0                    NaN          northwood     2585   vic   \n",
       "rec-2886-dup-0     springettst arcade        forest hill     2342   vic   \n",
       "...                               ...                ...      ...   ...   \n",
       "rec-4495-dup-0                    NaN               ryde     2570   nsw   \n",
       "rec-4211-dup-0  el pedro caravan park          sunnybank     4350   vic   \n",
       "rec-3131-dup-0         kurrajong vlge            pengzin     2230   qld   \n",
       "rec-3815-dup-0        oldershaw court           ashfield     2047   vic   \n",
       "rec-493-dup-0         northwood npark    chelsea heights     4211   qld   \n",
       "\n",
       "               date_of_birth soc_sec_id  \n",
       "rec_id                                   \n",
       "rec-561-dup-0       19651013    1551941  \n",
       "rec-2642-dup-0      19390212    8859999  \n",
       "rec-608-dup-0       19620216    9731855  \n",
       "rec-3239-dup-0      19980624    4970481  \n",
       "rec-2886-dup-0      19921016    1366884  \n",
       "...                      ...        ...  \n",
       "rec-4495-dup-0      19170518    5394641  \n",
       "rec-4211-dup-0      19500705    5525378  \n",
       "rec-3131-dup-0      19410531    4467228  \n",
       "rec-3815-dup-0      19500712    9435148  \n",
       "rec-493-dup-0       19570409    8541055  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-561-dup-0</th>\n",
       "      <td>elton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>light setreet</td>\n",
       "      <td>pinehill</td>\n",
       "      <td>windermere</td>\n",
       "      <td>3212</td>\n",
       "      <td>vic</td>\n",
       "      <td>19651013</td>\n",
       "      <td>1551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2642-dup-0</th>\n",
       "      <td>mitchell</td>\n",
       "      <td>maxon</td>\n",
       "      <td>47</td>\n",
       "      <td>edkins street</td>\n",
       "      <td>lochaoair</td>\n",
       "      <td>north ryde</td>\n",
       "      <td>3355</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19390212</td>\n",
       "      <td>8859999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-608-dup-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>72</td>\n",
       "      <td>lambrigg street</td>\n",
       "      <td>kelgoola</td>\n",
       "      <td>broadbeach waters</td>\n",
       "      <td>3159</td>\n",
       "      <td>vic</td>\n",
       "      <td>19620216</td>\n",
       "      <td>9731855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3239-dup-0</th>\n",
       "      <td>elk i</td>\n",
       "      <td>menzies</td>\n",
       "      <td>1</td>\n",
       "      <td>lyster place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>northwood</td>\n",
       "      <td>2585</td>\n",
       "      <td>vic</td>\n",
       "      <td>19980624</td>\n",
       "      <td>4970481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2886-dup-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>garanggar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>may maxwell crescent</td>\n",
       "      <td>springettst arcade</td>\n",
       "      <td>forest hill</td>\n",
       "      <td>2342</td>\n",
       "      <td>vic</td>\n",
       "      <td>19921016</td>\n",
       "      <td>1366884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4495-dup-0</th>\n",
       "      <td>connor</td>\n",
       "      <td>belperio</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ryde</td>\n",
       "      <td>2570</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19170518</td>\n",
       "      <td>5394641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4211-dup-0</th>\n",
       "      <td>daniel</td>\n",
       "      <td>maspn</td>\n",
       "      <td>9</td>\n",
       "      <td>derrington crescent</td>\n",
       "      <td>el pedro caravan park</td>\n",
       "      <td>sunnybank</td>\n",
       "      <td>4350</td>\n",
       "      <td>vic</td>\n",
       "      <td>19500705</td>\n",
       "      <td>5525378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3131-dup-0</th>\n",
       "      <td>samuel</td>\n",
       "      <td>crofs</td>\n",
       "      <td>613</td>\n",
       "      <td>banjine street</td>\n",
       "      <td>kurrajong vlge</td>\n",
       "      <td>pengzin</td>\n",
       "      <td>2230</td>\n",
       "      <td>qld</td>\n",
       "      <td>19410531</td>\n",
       "      <td>4467228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3815-dup-0</th>\n",
       "      <td>saah</td>\n",
       "      <td>beattih</td>\n",
       "      <td>60</td>\n",
       "      <td>kay's place</td>\n",
       "      <td>oldershaw court</td>\n",
       "      <td>ashfield</td>\n",
       "      <td>2047</td>\n",
       "      <td>vic</td>\n",
       "      <td>19500712</td>\n",
       "      <td>9435148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-493-dup-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>blackwell</td>\n",
       "      <td>127</td>\n",
       "      <td>ferrier place</td>\n",
       "      <td>northwood npark</td>\n",
       "      <td>chelsea heights</td>\n",
       "      <td>4211</td>\n",
       "      <td>qld</td>\n",
       "      <td>19570409</td>\n",
       "      <td>8541055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:09.827084Z",
     "start_time": "2025-05-14T02:59:09.822685Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Length of dataframe dfB: {len(dfB)}')",
   "id": "d4e8cf3111f53877",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe dfB: 5000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:09.910937Z",
     "start_time": "2025-05-14T02:59:09.905945Z"
    }
   },
   "cell_type": "code",
   "source": "miTrueLinks",
   "id": "383dd0b1c6759687",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(   'rec-0-org',    'rec-0-dup-0'),\n",
       "            (   'rec-1-org',    'rec-1-dup-0'),\n",
       "            (   'rec-2-org',    'rec-2-dup-0'),\n",
       "            (   'rec-3-org',    'rec-3-dup-0'),\n",
       "            (   'rec-4-org',    'rec-4-dup-0'),\n",
       "            (   'rec-5-org',    'rec-5-dup-0'),\n",
       "            (   'rec-6-org',    'rec-6-dup-0'),\n",
       "            (   'rec-7-org',    'rec-7-dup-0'),\n",
       "            (   'rec-8-org',    'rec-8-dup-0'),\n",
       "            (   'rec-9-org',    'rec-9-dup-0'),\n",
       "            ...\n",
       "            ('rec-4990-org', 'rec-4990-dup-0'),\n",
       "            ('rec-4991-org', 'rec-4991-dup-0'),\n",
       "            ('rec-4992-org', 'rec-4992-dup-0'),\n",
       "            ('rec-4993-org', 'rec-4993-dup-0'),\n",
       "            ('rec-4994-org', 'rec-4994-dup-0'),\n",
       "            ('rec-4995-org', 'rec-4995-dup-0'),\n",
       "            ('rec-4996-org', 'rec-4996-dup-0'),\n",
       "            ('rec-4997-org', 'rec-4997-dup-0'),\n",
       "            ('rec-4998-org', 'rec-4998-dup-0'),\n",
       "            ('rec-4999-org', 'rec-4999-dup-0')],\n",
       "           length=5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Preprocessing\n",
    "Because we are using a synthetic dataset, the amount of scrubbing we need to do is minor relative to real-wold use cases (as we'll see later). In fact, much of the scrubbing we'll do on this dataset is done to align it with our real-world data. However, along with scrubbing we need to enable efficient comparison of data. This means that we want to be able to do phonetic comparisons of strings rather than relying on exact matching, strongly type dates for more efficient comparison, etc. As with most data science efforts, determining optimal preprocessing is usually a trial-and-error process."
   ],
   "id": "4514a4af49f49b14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:10.146983Z",
     "start_time": "2025-05-14T02:59:10.024455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# preprocess fields: given_name, surname, street_number, address_1, address_2, suburb, state, postcode, soc_sec_id, date_of_birth\n",
    "\n",
    "# force all strings to upper case\n",
    "dfA = dfA.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "dfB = dfB.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "# convert city abbreviations to names\n",
    "def convert_au_state(short_name):\n",
    "    if short_name == 'ACT':\n",
    "        return 'AUSTRALIAN CAPITAL TERRITORY'\n",
    "    elif short_name == 'NSW':\n",
    "        return 'NEW SOUTH WALES'\n",
    "    elif short_name == 'NT':\n",
    "        return 'NORTHERN TERRITORY'\n",
    "    elif short_name == 'QLD':\n",
    "        return 'QUEENSLAND'\n",
    "    elif short_name == 'SA':\n",
    "        return 'SOUTH AUSTRALIA'\n",
    "    elif short_name == 'TAS':\n",
    "        return 'TANZANIA'\n",
    "    elif short_name == 'VIC':\n",
    "        return 'VICTORIA'\n",
    "    else:\n",
    "        return short_name\n",
    "dfA['state'] = dfA['state'].apply(convert_au_state)\n",
    "dfB['state'] = dfB['state'].apply(convert_au_state)\n",
    "\n",
    "# process name fields phonetically\n",
    "dfA[['given_name', 'surname']] = dfA[['given_name', 'surname']].fillna('')\n",
    "dfB[['given_name', 'surname']] = dfB[['given_name', 'surname']].fillna('')\n",
    "dfA['given_name_ph'] = phonetic(dfA['given_name'],method='metaphone',decode_error='replace')\n",
    "dfB['given_name_ph'] = phonetic(dfB['given_name'],method='metaphone',decode_error='replace')\n",
    "dfA['surname_ph'] = phonetic(dfA['surname'],method='metaphone',decode_error='replace')\n",
    "dfB['surname_ph'] = phonetic(dfB['surname'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# create a full name field\n",
    "dfA['full_name'] = dfA['given_name'] + ' ' + dfA['surname']\n",
    "dfA['full_name'] = dfA['full_name'].str.strip()\n",
    "dfB['full_name'] = dfB['given_name'] + ' ' + dfB['surname']\n",
    "dfB['full_name'] = dfB['full_name'].str.strip()\n",
    "\n",
    "# process suburb phonetically\n",
    "dfA[['suburb', 'state']] = dfA[['suburb', 'state']].fillna('')\n",
    "dfB[['suburb', 'state']] = dfB[['suburb', 'state']].fillna('')\n",
    "dfA['suburb_ph'] = phonetic(dfA['suburb'],method='metaphone',decode_error='replace')\n",
    "dfB['suburb_ph'] = phonetic(dfA['suburb'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# replace nans in postcode and convert to int\n",
    "dfA['postcode'] = dfA['postcode'].fillna('0')\n",
    "dfB['postcode'] = dfB['postcode'].fillna('0')\n",
    "dfA['postcode_int'] = pd.to_numeric(dfA['postcode'])\n",
    "dfB['postcode_int'] = pd.to_numeric(dfB['postcode'])\n",
    "\n",
    "# replace nans in soc_sec_id and convert to int\n",
    "dfA['soc_sec_id'] = dfA['soc_sec_id'].fillna('0')\n",
    "dfB['soc_sec_id'] = dfB['soc_sec_id'].fillna('0')\n",
    "dfA['soc_sec_id_int'] = dfA['soc_sec_id'].apply(int)\n",
    "dfB['soc_sec_id_int'] = dfB['soc_sec_id'].apply(int)\n",
    "\n",
    "# cast date_of_birth as datetime64 in a new column\n",
    "dfA['dob_typed'] = pd.to_datetime(dfA['date_of_birth'],format='%Y%m%d',errors='coerce')\n",
    "dfB['dob_typed'] = pd.to_datetime(dfB['date_of_birth'],format='%Y%m%d',errors='coerce')\n",
    "\n",
    "# build an all-text column\n",
    "dfA['text'] = dfA['full_name'] + ' ' + dfA['suburb'] + ' ' + dfA[ 'state']\n",
    "dfB['text'] = dfB['full_name'] + ' ' + dfB['suburb'] + ' ' + dfB[ 'state']\n",
    "\n",
    "dfA\n"
   ],
   "id": "41b47ae6bfcab85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             given_name    surname street_number            address_1  \\\n",
       "rec_id                                                                  \n",
       "rec-1070-org   MICHAELA    NEUMANN             8       STANLEY STREET   \n",
       "rec-1016-org   COURTNEY    PAINTER            12    PINKERTON CIRCUIT   \n",
       "rec-4405-org    CHARLES      GREEN            38  SALKAUSKAS CRESCENT   \n",
       "rec-1288-org    VANESSA       PARR           905       MACQUOID PLACE   \n",
       "rec-3585-org    MIKAYLA   MALLONEY            37        RANDWICK ROAD   \n",
       "...                 ...        ...           ...                  ...   \n",
       "rec-2153-org    ANNABEL   GRIERSON            97   MCLACHLAN CRESCENT   \n",
       "rec-1604-org     SIENNA   MUSOLINO            22      SMEATON CIRCUIT   \n",
       "rec-1003-org    BRADLEY   MATTHEWS             2         JONDOL PLACE   \n",
       "rec-4883-org     BRODEE       EGAN            88          AXON STREET   \n",
       "rec-66-org        KOULA  HOUWELING             3       MILEHAM STREET   \n",
       "\n",
       "                        address_2            suburb postcode            state  \\\n",
       "rec_id                                                                          \n",
       "rec-1070-org                MIAMI     WINSTON HILLS     4223  NEW SOUTH WALES   \n",
       "rec-1016-org           BEGA FLATS         RICHLANDS     4560         VICTORIA   \n",
       "rec-4405-org                 KELA             DAPTO     4566  NEW SOUTH WALES   \n",
       "rec-1288-org    BROADBRIDGE MANOR     SOUTH GRAFTON     2135  SOUTH AUSTRALIA   \n",
       "rec-3585-org              AVALIND  HOPPERS CROSSING     4552         VICTORIA   \n",
       "...                           ...               ...      ...              ...   \n",
       "rec-2153-org        LANTANA LODGE            BROOME     2480  NEW SOUTH WALES   \n",
       "rec-1604-org              PANGANI          MCKINNON     2700  NEW SOUTH WALES   \n",
       "rec-1003-org         HORSESHOE CK       JACOBS WELL     7018  SOUTH AUSTRALIA   \n",
       "rec-4883-org          GREENSLOPES          WAMBERAL     2067       QUEENSLAND   \n",
       "rec-66-org    OLD AIRDMILLAN ROAD      WILLIAMSTOWN     2350  NEW SOUTH WALES   \n",
       "\n",
       "             date_of_birth soc_sec_id given_name_ph surname_ph  \\\n",
       "rec_id                                                           \n",
       "rec-1070-org      19151111    5304218           MXL        NMN   \n",
       "rec-1016-org      19161214    4066625          KRTN       PNTR   \n",
       "rec-4405-org      19480930    4365168          XRLS        KRN   \n",
       "rec-1288-org      19951119    9239102           FNS         PR   \n",
       "rec-3585-org      19860208    7207688           MKL        MLN   \n",
       "...                    ...        ...           ...        ...   \n",
       "rec-2153-org      19840224    7676186          ANBL      KRRSN   \n",
       "rec-1604-org      19890525    4971506            SN       MSLN   \n",
       "rec-1003-org      19481122    8927667          BRTL        M0S   \n",
       "rec-4883-org      19121113    6039042           BRT        EKN   \n",
       "rec-66-org        19440718    6375537            KL      HWLNK   \n",
       "\n",
       "                     full_name  suburb_ph  postcode_int  soc_sec_id_int  \\\n",
       "rec_id                                                                    \n",
       "rec-1070-org  MICHAELA NEUMANN   WNSTNHLS          4223         5304218   \n",
       "rec-1016-org  COURTNEY PAINTER     RXLNTS          4560         4066625   \n",
       "rec-4405-org     CHARLES GREEN        TPT          4566         4365168   \n",
       "rec-1288-org      VANESSA PARR    S0KRFTN          2135         9239102   \n",
       "rec-3585-org  MIKAYLA MALLONEY  HPRSKRSNK          4552         7207688   \n",
       "...                        ...        ...           ...             ...   \n",
       "rec-2153-org  ANNABEL GRIERSON        BRM          2480         7676186   \n",
       "rec-1604-org   SIENNA MUSOLINO       MKNN          2700         4971506   \n",
       "rec-1003-org  BRADLEY MATTHEWS     JKBSWL          7018         8927667   \n",
       "rec-4883-org       BRODEE EGAN      WMBRL          2067         6039042   \n",
       "rec-66-org     KOULA HOUWELING     WLMSTN          2350         6375537   \n",
       "\n",
       "              dob_typed                                            text  \n",
       "rec_id                                                                   \n",
       "rec-1070-org 1915-11-11  MICHAELA NEUMANN WINSTON HILLS NEW SOUTH WALES  \n",
       "rec-1016-org 1916-12-14             COURTNEY PAINTER RICHLANDS VICTORIA  \n",
       "rec-4405-org 1948-09-30             CHARLES GREEN DAPTO NEW SOUTH WALES  \n",
       "rec-1288-org 1995-11-19      VANESSA PARR SOUTH GRAFTON SOUTH AUSTRALIA  \n",
       "rec-3585-org 1986-02-08      MIKAYLA MALLONEY HOPPERS CROSSING VICTORIA  \n",
       "...                 ...                                             ...  \n",
       "rec-2153-org 1984-02-24         ANNABEL GRIERSON BROOME NEW SOUTH WALES  \n",
       "rec-1604-org 1989-05-25        SIENNA MUSOLINO MCKINNON NEW SOUTH WALES  \n",
       "rec-1003-org 1948-11-22    BRADLEY MATTHEWS JACOBS WELL SOUTH AUSTRALIA  \n",
       "rec-4883-org 1912-11-13                 BRODEE EGAN WAMBERAL QUEENSLAND  \n",
       "rec-66-org   1944-07-18    KOULA HOUWELING WILLIAMSTOWN NEW SOUTH WALES  \n",
       "\n",
       "[5000 rows x 18 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>full_name</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>postcode_int</th>\n",
       "      <th>soc_sec_id_int</th>\n",
       "      <th>dob_typed</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-1070-org</th>\n",
       "      <td>MICHAELA</td>\n",
       "      <td>NEUMANN</td>\n",
       "      <td>8</td>\n",
       "      <td>STANLEY STREET</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>WINSTON HILLS</td>\n",
       "      <td>4223</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19151111</td>\n",
       "      <td>5304218</td>\n",
       "      <td>MXL</td>\n",
       "      <td>NMN</td>\n",
       "      <td>MICHAELA NEUMANN</td>\n",
       "      <td>WNSTNHLS</td>\n",
       "      <td>4223</td>\n",
       "      <td>5304218</td>\n",
       "      <td>1915-11-11</td>\n",
       "      <td>MICHAELA NEUMANN WINSTON HILLS NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1016-org</th>\n",
       "      <td>COURTNEY</td>\n",
       "      <td>PAINTER</td>\n",
       "      <td>12</td>\n",
       "      <td>PINKERTON CIRCUIT</td>\n",
       "      <td>BEGA FLATS</td>\n",
       "      <td>RICHLANDS</td>\n",
       "      <td>4560</td>\n",
       "      <td>VICTORIA</td>\n",
       "      <td>19161214</td>\n",
       "      <td>4066625</td>\n",
       "      <td>KRTN</td>\n",
       "      <td>PNTR</td>\n",
       "      <td>COURTNEY PAINTER</td>\n",
       "      <td>RXLNTS</td>\n",
       "      <td>4560</td>\n",
       "      <td>4066625</td>\n",
       "      <td>1916-12-14</td>\n",
       "      <td>COURTNEY PAINTER RICHLANDS VICTORIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4405-org</th>\n",
       "      <td>CHARLES</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>38</td>\n",
       "      <td>SALKAUSKAS CRESCENT</td>\n",
       "      <td>KELA</td>\n",
       "      <td>DAPTO</td>\n",
       "      <td>4566</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19480930</td>\n",
       "      <td>4365168</td>\n",
       "      <td>XRLS</td>\n",
       "      <td>KRN</td>\n",
       "      <td>CHARLES GREEN</td>\n",
       "      <td>TPT</td>\n",
       "      <td>4566</td>\n",
       "      <td>4365168</td>\n",
       "      <td>1948-09-30</td>\n",
       "      <td>CHARLES GREEN DAPTO NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1288-org</th>\n",
       "      <td>VANESSA</td>\n",
       "      <td>PARR</td>\n",
       "      <td>905</td>\n",
       "      <td>MACQUOID PLACE</td>\n",
       "      <td>BROADBRIDGE MANOR</td>\n",
       "      <td>SOUTH GRAFTON</td>\n",
       "      <td>2135</td>\n",
       "      <td>SOUTH AUSTRALIA</td>\n",
       "      <td>19951119</td>\n",
       "      <td>9239102</td>\n",
       "      <td>FNS</td>\n",
       "      <td>PR</td>\n",
       "      <td>VANESSA PARR</td>\n",
       "      <td>S0KRFTN</td>\n",
       "      <td>2135</td>\n",
       "      <td>9239102</td>\n",
       "      <td>1995-11-19</td>\n",
       "      <td>VANESSA PARR SOUTH GRAFTON SOUTH AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3585-org</th>\n",
       "      <td>MIKAYLA</td>\n",
       "      <td>MALLONEY</td>\n",
       "      <td>37</td>\n",
       "      <td>RANDWICK ROAD</td>\n",
       "      <td>AVALIND</td>\n",
       "      <td>HOPPERS CROSSING</td>\n",
       "      <td>4552</td>\n",
       "      <td>VICTORIA</td>\n",
       "      <td>19860208</td>\n",
       "      <td>7207688</td>\n",
       "      <td>MKL</td>\n",
       "      <td>MLN</td>\n",
       "      <td>MIKAYLA MALLONEY</td>\n",
       "      <td>HPRSKRSNK</td>\n",
       "      <td>4552</td>\n",
       "      <td>7207688</td>\n",
       "      <td>1986-02-08</td>\n",
       "      <td>MIKAYLA MALLONEY HOPPERS CROSSING VICTORIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2153-org</th>\n",
       "      <td>ANNABEL</td>\n",
       "      <td>GRIERSON</td>\n",
       "      <td>97</td>\n",
       "      <td>MCLACHLAN CRESCENT</td>\n",
       "      <td>LANTANA LODGE</td>\n",
       "      <td>BROOME</td>\n",
       "      <td>2480</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19840224</td>\n",
       "      <td>7676186</td>\n",
       "      <td>ANBL</td>\n",
       "      <td>KRRSN</td>\n",
       "      <td>ANNABEL GRIERSON</td>\n",
       "      <td>BRM</td>\n",
       "      <td>2480</td>\n",
       "      <td>7676186</td>\n",
       "      <td>1984-02-24</td>\n",
       "      <td>ANNABEL GRIERSON BROOME NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1604-org</th>\n",
       "      <td>SIENNA</td>\n",
       "      <td>MUSOLINO</td>\n",
       "      <td>22</td>\n",
       "      <td>SMEATON CIRCUIT</td>\n",
       "      <td>PANGANI</td>\n",
       "      <td>MCKINNON</td>\n",
       "      <td>2700</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19890525</td>\n",
       "      <td>4971506</td>\n",
       "      <td>SN</td>\n",
       "      <td>MSLN</td>\n",
       "      <td>SIENNA MUSOLINO</td>\n",
       "      <td>MKNN</td>\n",
       "      <td>2700</td>\n",
       "      <td>4971506</td>\n",
       "      <td>1989-05-25</td>\n",
       "      <td>SIENNA MUSOLINO MCKINNON NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1003-org</th>\n",
       "      <td>BRADLEY</td>\n",
       "      <td>MATTHEWS</td>\n",
       "      <td>2</td>\n",
       "      <td>JONDOL PLACE</td>\n",
       "      <td>HORSESHOE CK</td>\n",
       "      <td>JACOBS WELL</td>\n",
       "      <td>7018</td>\n",
       "      <td>SOUTH AUSTRALIA</td>\n",
       "      <td>19481122</td>\n",
       "      <td>8927667</td>\n",
       "      <td>BRTL</td>\n",
       "      <td>M0S</td>\n",
       "      <td>BRADLEY MATTHEWS</td>\n",
       "      <td>JKBSWL</td>\n",
       "      <td>7018</td>\n",
       "      <td>8927667</td>\n",
       "      <td>1948-11-22</td>\n",
       "      <td>BRADLEY MATTHEWS JACOBS WELL SOUTH AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4883-org</th>\n",
       "      <td>BRODEE</td>\n",
       "      <td>EGAN</td>\n",
       "      <td>88</td>\n",
       "      <td>AXON STREET</td>\n",
       "      <td>GREENSLOPES</td>\n",
       "      <td>WAMBERAL</td>\n",
       "      <td>2067</td>\n",
       "      <td>QUEENSLAND</td>\n",
       "      <td>19121113</td>\n",
       "      <td>6039042</td>\n",
       "      <td>BRT</td>\n",
       "      <td>EKN</td>\n",
       "      <td>BRODEE EGAN</td>\n",
       "      <td>WMBRL</td>\n",
       "      <td>2067</td>\n",
       "      <td>6039042</td>\n",
       "      <td>1912-11-13</td>\n",
       "      <td>BRODEE EGAN WAMBERAL QUEENSLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-66-org</th>\n",
       "      <td>KOULA</td>\n",
       "      <td>HOUWELING</td>\n",
       "      <td>3</td>\n",
       "      <td>MILEHAM STREET</td>\n",
       "      <td>OLD AIRDMILLAN ROAD</td>\n",
       "      <td>WILLIAMSTOWN</td>\n",
       "      <td>2350</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19440718</td>\n",
       "      <td>6375537</td>\n",
       "      <td>KL</td>\n",
       "      <td>HWLNK</td>\n",
       "      <td>KOULA HOUWELING</td>\n",
       "      <td>WLMSTN</td>\n",
       "      <td>2350</td>\n",
       "      <td>6375537</td>\n",
       "      <td>1944-07-18</td>\n",
       "      <td>KOULA HOUWELING WILLIAMSTOWN NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 18 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Indexing\n",
    "The next step in the process is to link each row in the source to each row in the target so that we can check for matches based on weighted scores. In it's simplest form, this results in a full cartesian product of `dfA X dfB`. Clearly this does not scale well so most often a technique called Blocking is applied in which obvious non-matches are not included in the indexes. Simpler techniques block based on exact matches on one or more attributes (columns) while more complex and interesting techniques relax the matching criteria using techniques such as clustering, fuzzy hashing, and bloom filter grouping.\n",
    "\n",
    "The PRLT library includes fairly simple Indexing methods that include Full (no Blocking), Block which uses exact matches on specified attributes, and SortedNeighborhood which sorts data from both datasets together and groups data from two different sets according a window size (<ins>de Bruin, 2023</ins>). Interestingly, this concept is similar in functionality to convolution."
   ],
   "id": "6fcd0d04e80280d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:10.317285Z",
     "start_time": "2025-05-14T02:59:10.195257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# full indexing --> far too many rows to process\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.full()\n",
    "pairs = indexer.index(dfA, dfB)\n",
    "pairs"
   ],
   "id": "726ba00d246af6b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('rec-1070-org',  'rec-561-dup-0'),\n",
       "            ('rec-1070-org', 'rec-2642-dup-0'),\n",
       "            ('rec-1070-org',  'rec-608-dup-0'),\n",
       "            ('rec-1070-org', 'rec-3239-dup-0'),\n",
       "            ('rec-1070-org', 'rec-2886-dup-0'),\n",
       "            ('rec-1070-org', 'rec-4285-dup-0'),\n",
       "            ('rec-1070-org',  'rec-929-dup-0'),\n",
       "            ('rec-1070-org', 'rec-4833-dup-0'),\n",
       "            ('rec-1070-org',  'rec-717-dup-0'),\n",
       "            ('rec-1070-org', 'rec-3984-dup-0'),\n",
       "            ...\n",
       "            (  'rec-66-org',  'rec-670-dup-0'),\n",
       "            (  'rec-66-org', 'rec-4134-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3866-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3152-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3363-dup-0'),\n",
       "            (  'rec-66-org', 'rec-4495-dup-0'),\n",
       "            (  'rec-66-org', 'rec-4211-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3131-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3815-dup-0'),\n",
       "            (  'rec-66-org',  'rec-493-dup-0')],\n",
       "           names=['rec_id_1', 'rec_id_2'], length=25000000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:10.367546Z",
     "start_time": "2025-05-14T02:59:10.351335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# exact match on phonetic surname --> not ideal based on the types of errors we expect to encounter\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block(left_on='surname_ph', right_on='surname_ph')\n",
    "pairs = indexer.index(dfA, dfB)\n",
    "pairs"
   ],
   "id": "640f8814ae7b3dcb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('rec-1070-org', 'rec-2672-dup-0'),\n",
       "            ('rec-1070-org', 'rec-4387-dup-0'),\n",
       "            ('rec-1070-org',  'rec-787-dup-0'),\n",
       "            ('rec-1070-org', 'rec-2158-dup-0'),\n",
       "            ('rec-1016-org', 'rec-3267-dup-0'),\n",
       "            ('rec-1016-org', 'rec-2136-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1948-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1016-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1032-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1321-dup-0'),\n",
       "            ...\n",
       "            ('rec-1003-org', 'rec-3462-dup-0'),\n",
       "            ('rec-1003-org', 'rec-1014-dup-0'),\n",
       "            ('rec-4883-org', 'rec-1662-dup-0'),\n",
       "            ('rec-4883-org',  'rec-835-dup-0'),\n",
       "            ('rec-4883-org', 'rec-4883-dup-0'),\n",
       "            ('rec-4883-org', 'rec-1884-dup-0'),\n",
       "            ('rec-4883-org',  'rec-785-dup-0'),\n",
       "            ('rec-4883-org', 'rec-3923-dup-0'),\n",
       "            ('rec-4883-org', 'rec-2609-dup-0'),\n",
       "            ('rec-4883-org', 'rec-4459-dup-0')],\n",
       "           names=['rec_id_1', 'rec_id_2'], length=105304)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Custom LSH Indexing Algorithm\n",
    "\n",
    "The PRLT library also allows the Index class to be extended to enable other blocking algorithms. One newer blocking algorithm found in the literature uses Locality Sensitive Hashing (LSH). The LSH algorithm has gained popularity for two reasons. First, it is less strict than standard blocking but still effectively reduces the comparison size relative to full indexing. Second, because the algorithm hashes values before indexing using LSH, it can be used to preserve the privacy of the original data sets (<ins>Dutt, 2023</ins>). In the code below, we extend the PRLT BaseIndexAlgorithm class using the [datasketch library](https://ekzhu.com/datasketch/index.html)'s MinHash and MinHashLSH algorithms. MinHash estimates the Jaccard Similarity Index for two inputs. These are then loaded into the MinHashed LSH index and matches are queried (<ins>Zhu, 2024</ins>). The resulting matches are output as Pandas MultiArray so that they work seamlessly within the PRLT libary. Note that two tokenizers are enabled. The first tokenizes text bigrams and the second tokenizes words. Both will be experimented with.\n",
    "\n",
    "In order to optimize performance, the following techniques were applied to the code below:\n",
    "\n",
    "1. Static tokenizer methods were moved out of the class so that they would be precompiled\n",
    "2. All MinHash and LSH processing was done in-place using dataframes\n",
    "3. The [swifter library](https://github.com/jmcarpenter2/swifter/blob/master/docs/documentation.md) was used to parallelize the dataframe.apply method for generating MinHashes\n"
   ],
   "id": "135d655eb4da1131"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:10.474223Z",
     "start_time": "2025-05-14T02:59:10.465070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _tokenize_bigram(string):\n",
    "    # Clean and create character bigrams\n",
    "    string = re.sub(r'\\W+', '', string.lower())\n",
    "    tokens = set(string[i:i+2] for i in range(len(string)-1))\n",
    "    return tokens\n",
    "\n",
    "def _tokenize_words(string):\n",
    "    # Clean and create character bigrams\n",
    "    tokens = string.split()\n",
    "    return tokens\n",
    "\n",
    "class LSHIndex(BaseIndexAlgorithm):\n",
    "\n",
    "    def __init__(self, column, threshold=0.3, num_perm=128, tokenizer='words'):\n",
    "        super().__init__()\n",
    "        self.column = column\n",
    "        self.threshold = threshold\n",
    "        self.num_perm = num_perm\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def _tokenize(self, string):\n",
    "        if self.tokenizer == 'words':\n",
    "            return _tokenize_words(string)\n",
    "        elif self.tokenizer == 'bigrams':\n",
    "            return _tokenize_bigram(string)\n",
    "\n",
    "    def _create_minhash(self, row):\n",
    "        string = row[self.column]\n",
    "        tokens = self._tokenize(string)\n",
    "        m = MinHash(num_perm=self.num_perm)\n",
    "        for token in tokens:\n",
    "            m.update(token.encode('utf8'))\n",
    "        return LeanMinHash(m)\n",
    "\n",
    "    def _link_index(self, dfA, dfB):\n",
    "        is_deduplication = dfA.equals(dfB)\n",
    "\n",
    "        # MinHash computation\n",
    "        start = time.perf_counter()\n",
    "        #dfA['minhash'] = dfA.apply(func=self._create_minhash, axis=1)\n",
    "        dfA['minhash'] = dfA.swifter.apply(func=self._create_minhash, axis=1)\n",
    "        end = time.perf_counter()\n",
    "        print(f'Seconds to compute minhash dfA: {end - start}')\n",
    "        if is_deduplication:\n",
    "            dfB = dfA\n",
    "        else:\n",
    "            start = time.perf_counter()\n",
    "            dfB['minhash'] = dfB.swifter.apply(func=self._create_minhash, axis=1)\n",
    "            end = time.perf_counter()\n",
    "            print(f'Seconds to compute minhash dfB: {end - start}')\n",
    "\n",
    "        # Insert into LSH\n",
    "        lsh = MinHashLSH(threshold=self.threshold, num_perm=self.num_perm)\n",
    "        start = time.perf_counter()\n",
    "        for index, row in dfB.iterrows():\n",
    "            lsh.insert(index, row['minhash'])\n",
    "        end = time.perf_counter()\n",
    "        print(f'Seconds to build LSH of dfB: {end - start}')\n",
    "\n",
    "        # Query LSH for candidate pairs\n",
    "        l_rows = []\n",
    "        start = time.perf_counter()\n",
    "        for index, row in dfA.iterrows():\n",
    "            result = lsh.query(row['minhash'])\n",
    "            for idx_b in result:\n",
    "                if is_deduplication and index >= idx_b:\n",
    "                    continue\n",
    "                l_rows.append({'dfA_idx': index, 'dfB_idx': idx_b})\n",
    "        df_out = pd.DataFrame(l_rows)\n",
    "        end = time.perf_counter()\n",
    "        print(f'Seconds to query dfB for each row of dfA: {end - start}')\n",
    "\n",
    "        # Convert result to MultiIndex\n",
    "        start = time.perf_counter()\n",
    "        output = pd.MultiIndex.from_frame(df_out)\n",
    "        end = time.perf_counter()\n",
    "        print(f'Seconds to convert df to MultiIndex: {end - start}')\n",
    "        return output"
   ],
   "id": "eca6d004795c7aa5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Indexing Results Using LSHIndex\n",
    "\n",
    "Below we index our dataset using the custom LSHIndex Blocking algorithm. Two different tokenization methods were attempted - a `bigram` tokenizer to compare the `full_name` column and a word-based tokenizer to tokenize the `text` column. While the word tokenizer is more sensitive, the bigram tokenizer yielded better results in the comparison tests performed later. We found that the default settings for Jaccard Similarity threshold and number of MinHash permutations worked well with bigram, but needed to be adjusted for word comparison. More information on this can be found in the DataSketch documentation (<ins>Zhu, 2024</ins>) and in a reference implementation by Martin Boyanov (<ins>Boyanov, 2020</ins>)."
   ],
   "id": "acdda033f1df27f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:23.465339Z",
     "start_time": "2025-05-14T02:59:10.507271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indexer = LSHIndex(column='full_name', threshold=0.5, num_perm=128, tokenizer='bigrams')\n",
    "pairs_lsh = indexer.index(dfA, dfB)\n",
    "pairs_lsh"
   ],
   "id": "5f85f83d6d3da2d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 5000/5000 [00:05<00:00, 934.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfA: 6.009883600054309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 5000/5000 [00:05<00:00, 944.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfB: 5.930727800005116\n",
      "Seconds to build LSH of dfB: 0.5911461000796407\n",
      "Seconds to query dfB for each row of dfA: 0.3874913000036031\n",
      "Seconds to convert df to MultiIndex: 0.009221100015565753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('rec-1070-org', 'rec-2754-dup-0'),\n",
       "            ('rec-1070-org', 'rec-2797-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1948-dup-0'),\n",
       "            ('rec-1016-org',  'rec-865-dup-0'),\n",
       "            ('rec-1016-org', 'rec-3267-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1151-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1321-dup-0'),\n",
       "            ('rec-1016-org',  'rec-355-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1016-dup-0'),\n",
       "            ('rec-4405-org', 'rec-2078-dup-0'),\n",
       "            ...\n",
       "            ('rec-1003-org', 'rec-3078-dup-0'),\n",
       "            ('rec-1003-org', 'rec-3226-dup-0'),\n",
       "            ('rec-1003-org', 'rec-1771-dup-0'),\n",
       "            ('rec-1003-org',  'rec-942-dup-0'),\n",
       "            ('rec-1003-org', 'rec-4118-dup-0'),\n",
       "            ('rec-1003-org', 'rec-4433-dup-0'),\n",
       "            ('rec-4883-org', 'rec-1194-dup-0'),\n",
       "            ('rec-4883-org', 'rec-4883-dup-0'),\n",
       "            ('rec-4883-org', 'rec-1099-dup-0'),\n",
       "            (  'rec-66-org',   'rec-66-dup-0')],\n",
       "           names=['rec_id_1', 'rec_id_2'], length=38048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Index Runtime Benchmarks:\n",
    "\n",
    "Time to generate the Pandas MultiIndex for two 5000 row datasets (see Appendix 1 for system info):\n",
    "\n",
    "- *Full Index Generation*: 118ms / 25M rows\n",
    "- *Exact-Match Blocking Index Generation*: 25ms / 89727 rows\n",
    "- *LSH Blocking Index Generation*: 13.5s / 507726 rows\n"
   ],
   "id": "5a6789d6389f044e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparison\n",
    "\n",
    "When comparing the candidate records generated by the Indexing steps above in order to generate comparison scores, there are a number of algorithms that can be applied. The PRLT library includes several methods that compare data based on it's type. These comparisons, run alone, all return scores. When a Pandas dataframe is provided with a set of records, the library can be used to compute scores for each row in the dataframe. Each matching column between the two datasets can be assigned it's own comparison algorithm. The result in this case is a vector that includes the row keys of the two rows being compared and columns for each compared variable that includes their match score.\n",
    "\n",
    "#### Algorithms by Data Type\n",
    "\n",
    "##### General\n",
    "\n",
    "  - Exact --> straight equivalence that returns a score of 1 or 0\n",
    "  - Custom --> As with Indexers above, the library offers the BaseCompareFeature from which custom algorithms can be implemented\n",
    "\n",
    "##### String\n",
    "\n",
    "String comparisons are implemented in the PRLT library by wrapping the Python [jellyfish](https://jamesturk.github.io/jellyfish/) library for approximate and phonetic string matching. PRLT implements the following string comparison methods from the jellyfish library:\n",
    "\n",
    "   - Jaro\n",
    "   - Jaro-Winkler\n",
    "   - Levenshtein\n",
    "   - Damerau-Levenshtein\n",
    "\n",
    "Interestingly, it excludes Hamming Distance and Match Rating Approach algorithms. The PRLT library also excludes the phonetic encoding tools provided in the jellyfish library. These tools are interesting in that they address phonetic misspellings that might fail edit distance algorithms like the ones above. For example, the spellings Clumps and Klumpz sound the same but would have a low edit distance score. Applying a phonetic encoding tool early can improve match scores (<ins>Zhu, 2024</ins>).\n",
    "\n",
    "##### Numeric\n",
    "\n",
    "The PRLT library can compare numeric values using a variety of nearness measures all of which are based on a distance from a comparison point. The following diagram, referenced from the PRLT documentation, well illustrates how the comparisons work (<ins>Elastic, 2025</ins>):\n",
    "\n",
    "<br><center>\n",
    "![numeric matching algorithms](images/elas_1705.png)\n",
    "</center>\n",
    "\n",
    "As the diagram shows, two values are compared as a distance using one of several decay algorithms (step, linear, exponential, gaussian or squared), returning a float value between 0 and 1.\n",
    "\n",
    "##### Geospatial\n",
    "\n",
    "For locations that include lattidue and longitude, the toolkit can compute the haversine distance between coordinates and then compute the numeric similarity between the distances as described for numeric values above.\n",
    "\n",
    "##### Date\n",
    "\n",
    "Again, the numeric distance between dates is computed with a few date-specific scoring optimizations applied.\n",
    "\n",
    "- score when month and day are swapped: allows for a set score to be applied if the only difference between two dates is that day and month are transposed\n",
    "- score for common month swapping errors: allows for a set score to be applied if the only difference between two dates is that a common string to numeric date conversion error occurred\n",
    "\n",
    "##### Precomputed Variable\n",
    "\n",
    "In addition to row-specific values, the toolkit allows for precomputed scores already contained in the dataset to be passed in as variables. By default, these variables are normalized to a score range from 0-1.\n",
    "\n",
    "#### Comparison Algorithm Applied by Column\n",
    "\n",
    "- *given_name_ph*: exact\n",
    "- *surname_ph*: exact\n",
    "- *suburb_ph*: exact\n",
    "- *postcode*: numeric (exponential)\n",
    "- *state*: Jaro-Winkler distance\n",
    "- *date_of_birth*: date with default scoring for month/day and text to numeric month errors\n",
    "- *soc_sec_id*: numeric (exponential)"
   ],
   "id": "80de2d58c1966bd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:24.562392Z",
     "start_time": "2025-05-14T02:59:23.480345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comparison = recordlinkage.Compare()\n",
    "comparison.exact(left_on=\"given_name_ph\", right_on=\"given_name_ph\", label=\"given_name_ph\")\n",
    "comparison.exact(left_on=\"surname_ph\", right_on=\"surname_ph\", label=\"surname_ph\")\n",
    "comparison.string(left_on=\"given_name\", right_on=\"given_name\", method='jarowinkler', label='given_name')\n",
    "comparison.string(left_on=\"surname\", right_on=\"state\", method='jarowinkler', label='surname')\n",
    "# comparison.string(left_on=\"street_number\", right_on=\"street_number\", method='damerau_levenshtein', label='street_number')\n",
    "# comparison.string(left_on=\"address_1\", right_on=\"address_1\", method='damerau_levenshtein', label='address_1')\n",
    "# comparison.string(left_on=\"address_2\", right_on=\"address_2\", method='damerau_levenshtein', label='address_2')\n",
    "comparison.exact(left_on=\"suburb_ph\", right_on=\"suburb_ph\", label='suburb_ph')\n",
    "comparison.string(left_on=\"suburb\", right_on=\"suburb\", label='suburb')\n",
    "comparison.numeric (left_on=\"postcode_int\", right_on=\"postcode_int\", method='exp', label='postcode')\n",
    "comparison.exact(left_on=\"state\", right_on=\"state\", label='state')\n",
    "comparison.numeric(left_on=\"soc_sec_id_int\", right_on=\"soc_sec_id_int\", method=\"exp\", label='soc_sec_id')\n",
    "comparison.date(left_on=\"dob_typed\", right_on=\"dob_typed\", label='dob')\n",
    "print(len(pairs))\n",
    "features = comparison.compute(pairs=pairs, x=dfA, x_link=dfB)\n",
    "features"
   ],
   "id": "83feb348a41636a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\recordlinkage\\algorithms\\string.py:56: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - levenshtein_distance(x[0], x[1]) / np.max([len(x[0]), len(x[1])])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                             given_name_ph  surname_ph  given_name   surname  \\\n",
       "rec_id_1     rec_id_2                                                          \n",
       "rec-1070-org rec-2672-dup-0              0           1    0.638889  0.000000   \n",
       "             rec-4387-dup-0              0           1    0.550000  0.671429   \n",
       "             rec-787-dup-0               0           1    0.430556  0.422619   \n",
       "             rec-2158-dup-0              0           1    0.441667  0.671429   \n",
       "rec-1016-org rec-3267-dup-0              0           1    0.000000  0.431746   \n",
       "...                                    ...         ...         ...       ...   \n",
       "rec-4883-org rec-1884-dup-0              0           1    0.444444  0.377778   \n",
       "             rec-785-dup-0               0           1    0.000000  0.438889   \n",
       "             rec-3923-dup-0              0           1    0.000000  0.000000   \n",
       "             rec-2609-dup-0              0           1    0.844444  0.000000   \n",
       "             rec-4459-dup-0              0           1    0.577778  0.377778   \n",
       "\n",
       "                             suburb_ph    suburb       postcode  state  \\\n",
       "rec_id_1     rec_id_2                                                    \n",
       "rec-1070-org rec-2672-dup-0          0  0.307692   0.000000e+00      0   \n",
       "             rec-4387-dup-0          0  0.000000   0.000000e+00      0   \n",
       "             rec-787-dup-0           0  0.076923   0.000000e+00      0   \n",
       "             rec-2158-dup-0          0  0.307692  1.430222e-247      0   \n",
       "rec-1016-org rec-3267-dup-0          0  0.222222   0.000000e+00      0   \n",
       "...                                ...       ...            ...    ...   \n",
       "rec-4883-org rec-1884-dup-0          0  0.125000  3.131513e-294      0   \n",
       "             rec-785-dup-0           0  0.111111   0.000000e+00      0   \n",
       "             rec-3923-dup-0          0  0.111111   7.812500e-03      0   \n",
       "             rec-2609-dup-0          0  0.222222   0.000000e+00      0   \n",
       "             rec-4459-dup-0          0  0.181818   0.000000e+00      0   \n",
       "\n",
       "                             soc_sec_id  dob  \n",
       "rec_id_1     rec_id_2                         \n",
       "rec-1070-org rec-2672-dup-0         0.0  0.0  \n",
       "             rec-4387-dup-0         0.0  0.0  \n",
       "             rec-787-dup-0          0.0  0.0  \n",
       "             rec-2158-dup-0         0.0  0.0  \n",
       "rec-1016-org rec-3267-dup-0         0.0  0.0  \n",
       "...                                 ...  ...  \n",
       "rec-4883-org rec-1884-dup-0         0.0  0.0  \n",
       "             rec-785-dup-0          0.0  0.0  \n",
       "             rec-3923-dup-0         0.0  0.0  \n",
       "             rec-2609-dup-0         0.0  0.0  \n",
       "             rec-4459-dup-0         0.0  0.0  \n",
       "\n",
       "[105304 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rec-1070-org</th>\n",
       "      <th>rec-2672-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4387-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-787-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.422619</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2158-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.430222e-247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1016-org</th>\n",
       "      <th>rec-3267-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rec-4883-org</th>\n",
       "      <th>rec-1884-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.131513e-294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-785-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3923-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7.812500e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2609-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4459-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105304 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:24.656236Z",
     "start_time": "2025-05-14T02:59:24.612843Z"
    }
   },
   "cell_type": "code",
   "source": "features.describe()",
   "id": "75397fba54ee8f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       given_name_ph  surname_ph     given_name        surname  suburb_ph  \\\n",
       "count  105304.000000    105304.0  105304.000000  105304.000000   105304.0   \n",
       "mean        0.033361         1.0       0.401377       0.379457        0.0   \n",
       "std         0.179577         0.0       0.258514       0.192889        0.0   \n",
       "min         0.000000         1.0       0.000000       0.000000        0.0   \n",
       "25%         0.000000         1.0       0.000000       0.344444        0.0   \n",
       "50%         0.000000         1.0       0.464286       0.438889        0.0   \n",
       "75%         0.000000         1.0       0.555556       0.488889        0.0   \n",
       "max         1.000000         1.0       1.000000       0.822222        0.0   \n",
       "\n",
       "              suburb       postcode          state     soc_sec_id  \\\n",
       "count  105304.000000   1.053040e+05  105304.000000  105304.000000   \n",
       "mean        0.164120   3.214702e-02       0.245252       0.031903   \n",
       "std         0.181727   1.738743e-01       0.430238       0.175736   \n",
       "min         0.000000   0.000000e+00       0.000000       0.000000   \n",
       "25%         0.076923   0.000000e+00       0.000000       0.000000   \n",
       "50%         0.125000   0.000000e+00       0.000000       0.000000   \n",
       "75%         0.200000  2.002083e-146       0.000000       0.000000   \n",
       "max         1.000000   1.000000e+00       1.000000       1.000000   \n",
       "\n",
       "                 dob  \n",
       "count  105304.000000  \n",
       "mean        0.031542  \n",
       "std         0.174771  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.0</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.0</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>1.053040e+05</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.033361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401377</td>\n",
       "      <td>0.379457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164120</td>\n",
       "      <td>3.214702e-02</td>\n",
       "      <td>0.245252</td>\n",
       "      <td>0.031903</td>\n",
       "      <td>0.031542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.179577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258514</td>\n",
       "      <td>0.192889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181727</td>\n",
       "      <td>1.738743e-01</td>\n",
       "      <td>0.430238</td>\n",
       "      <td>0.175736</td>\n",
       "      <td>0.174771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.438889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.002083e-146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:25.129125Z",
     "start_time": "2025-05-14T02:59:24.694015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_lsh = comparison.compute(pairs=pairs_lsh, x=dfA, x_link=dfB)\n",
    "features_lsh"
   ],
   "id": "d72d8c17a87bb30",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\recordlinkage\\algorithms\\string.py:56: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - levenshtein_distance(x[0], x[1]) / np.max([len(x[0]), len(x[1])])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                             given_name_ph  surname_ph  given_name   surname  \\\n",
       "rec_id_1     rec_id_2                                                          \n",
       "rec-1070-org rec-2754-dup-0              0           0    0.441667  0.671429   \n",
       "             rec-2797-dup-0              0           0    0.511905  0.671429   \n",
       "rec-1016-org rec-1948-dup-0              0           1    0.441667  0.601190   \n",
       "             rec-865-dup-0               0           0    0.550000  0.328571   \n",
       "             rec-3267-dup-0              0           1    0.000000  0.431746   \n",
       "...                                    ...         ...         ...       ...   \n",
       "rec-1003-org rec-4433-dup-0              0           1    0.447619  0.416667   \n",
       "rec-4883-org rec-1194-dup-0              0           0    0.577778  0.566667   \n",
       "             rec-4883-dup-0              1           1    1.000000  0.566667   \n",
       "             rec-1099-dup-0              0           0    0.472222  0.377778   \n",
       "rec-66-org   rec-66-dup-0                1           0    1.000000  0.403704   \n",
       "\n",
       "                             suburb_ph    suburb       postcode  state  \\\n",
       "rec_id_1     rec_id_2                                                    \n",
       "rec-1070-org rec-2754-dup-0          0  0.153846   1.274474e-57      0   \n",
       "             rec-2797-dup-0          0  0.153846   0.000000e+00      0   \n",
       "rec-1016-org rec-1948-dup-0          0  0.111111   0.000000e+00      1   \n",
       "             rec-865-dup-0           0  0.153846   6.681912e-52      0   \n",
       "             rec-3267-dup-0          0  0.222222   0.000000e+00      0   \n",
       "...                                ...       ...            ...    ...   \n",
       "rec-1003-org rec-4433-dup-0          0  0.181818   0.000000e+00      0   \n",
       "rec-4883-org rec-1194-dup-0          0  0.000000   0.000000e+00      1   \n",
       "             rec-4883-dup-0          0  1.000000   1.000000e+00      1   \n",
       "             rec-1099-dup-0          0  0.111111  5.180654e-318      0   \n",
       "rec-66-org   rec-66-dup-0            0  1.000000   1.000000e+00      1   \n",
       "\n",
       "                             soc_sec_id  dob  \n",
       "rec_id_1     rec_id_2                         \n",
       "rec-1070-org rec-2754-dup-0         0.0  0.0  \n",
       "             rec-2797-dup-0         0.0  0.0  \n",
       "rec-1016-org rec-1948-dup-0         0.0  0.0  \n",
       "             rec-865-dup-0          0.0  0.0  \n",
       "             rec-3267-dup-0         0.0  0.0  \n",
       "...                                 ...  ...  \n",
       "rec-1003-org rec-4433-dup-0         0.0  0.0  \n",
       "rec-4883-org rec-1194-dup-0         0.0  0.0  \n",
       "             rec-4883-dup-0         1.0  1.0  \n",
       "             rec-1099-dup-0         0.0  0.0  \n",
       "rec-66-org   rec-66-dup-0           1.0  1.0  \n",
       "\n",
       "[38048 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rec-1070-org</th>\n",
       "      <th>rec-2754-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.274474e-57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2797-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rec-1016-org</th>\n",
       "      <th>rec-1948-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-865-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>6.681912e-52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3267-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1003-org</th>\n",
       "      <th>rec-4433-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rec-4883-org</th>\n",
       "      <th>rec-1194-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4883-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1099-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>5.180654e-318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-66-org</th>\n",
       "      <th>rec-66-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38048 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:25.192001Z",
     "start_time": "2025-05-14T02:59:25.163773Z"
    }
   },
   "cell_type": "code",
   "source": "features_lsh.describe()",
   "id": "b11711dd76eb9c1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       given_name_ph    surname_ph    given_name       surname  suburb_ph  \\\n",
       "count   38048.000000  38048.000000  38048.000000  38048.000000    38048.0   \n",
       "mean        0.356760      0.442967      0.621522      0.397308        0.0   \n",
       "std         0.479049      0.496743      0.356339      0.179041        0.0   \n",
       "min         0.000000      0.000000      0.000000      0.000000        0.0   \n",
       "25%         0.000000      0.000000      0.447619      0.408333        0.0   \n",
       "50%         0.000000      0.000000      0.611111      0.441667        0.0   \n",
       "75%         1.000000      1.000000      1.000000      0.505556        0.0   \n",
       "max         1.000000      1.000000      1.000000      0.866667        0.0   \n",
       "\n",
       "             suburb       postcode         state    soc_sec_id           dob  \n",
       "count  38048.000000   3.804800e+04  38048.000000  38048.000000  38048.000000  \n",
       "mean       0.222854   9.551145e-02      0.296783      0.099974      0.098363  \n",
       "std        0.272287   2.919576e-01      0.456846      0.299948      0.297797  \n",
       "min        0.000000   0.000000e+00      0.000000      0.000000      0.000000  \n",
       "25%        0.083333   0.000000e+00      0.000000      0.000000      0.000000  \n",
       "50%        0.142857  4.144523e-317      0.000000      0.000000      0.000000  \n",
       "75%        0.230769   2.996273e-95      1.000000      0.000000      0.000000  \n",
       "max        1.000000   1.000000e+00      1.000000      1.000000      1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38048.000000</td>\n",
       "      <td>38048.000000</td>\n",
       "      <td>38048.000000</td>\n",
       "      <td>38048.000000</td>\n",
       "      <td>38048.0</td>\n",
       "      <td>38048.000000</td>\n",
       "      <td>3.804800e+04</td>\n",
       "      <td>38048.000000</td>\n",
       "      <td>38048.000000</td>\n",
       "      <td>38048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.356760</td>\n",
       "      <td>0.442967</td>\n",
       "      <td>0.621522</td>\n",
       "      <td>0.397308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222854</td>\n",
       "      <td>9.551145e-02</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>0.099974</td>\n",
       "      <td>0.098363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.479049</td>\n",
       "      <td>0.496743</td>\n",
       "      <td>0.356339</td>\n",
       "      <td>0.179041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272287</td>\n",
       "      <td>2.919576e-01</td>\n",
       "      <td>0.456846</td>\n",
       "      <td>0.299948</td>\n",
       "      <td>0.297797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4.144523e-317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2.996273e-95</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Comparison Runtime Benchmarks:\n",
    "\n",
    "Time to run a comparison of two 5000 row datasets (see Appendix 1 for system info):\n",
    "\n",
    "- *Full Index*: 27m, 18s\n",
    "- *Exact-Match Blocking Index*: 5.5s\n",
    "- *LSH Blocking Index*: 25.1s\n",
    "\n"
   ],
   "id": "de7a68de3d4a84ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Classification\n",
    "\n",
    "The PRLT library includes the following classifiers that can be used to classify matches based on the features generated above:\n",
    "\n",
    "Supervised:\n",
    "\n",
    "- Logistic Regression Classifier\n",
    "- Naive Bayesian Classifier\n",
    "- Support Vector Machine (SVM) Classifier\n",
    "\n",
    "Unsupervised:\n",
    "\n",
    "- Expectation/Conditional Maximization (ECM) Classifier\n",
    "- KMeans Classifier\n",
    "\n",
    "### Unsupervised Classifiers"
   ],
   "id": "e45f5da9d7fdc7ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:27.260566Z",
     "start_time": "2025-05-14T02:59:25.390166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# k-means clustering using exact match blocking\n",
    "kmeans = recordlinkage.KMeansClassifier()\n",
    "result_kmeans = kmeans.fit_predict(features)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_kmeans, total=len(dfA.index))"
   ],
   "id": "59dc322633392bb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3693, 1307],\n",
       "       [   1,   -1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:27.391824Z",
     "start_time": "2025-05-14T02:59:27.380273Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_kmeans)",
   "id": "ef7f6c4b844712cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849551414768806"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:27.535470Z",
     "start_time": "2025-05-14T02:59:27.503934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# k-means clustering using LSH blocking\n",
    "kmeans = recordlinkage.KMeansClassifier()\n",
    "result_kmeans = kmeans.fit_predict(features_lsh)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_kmeans, total=len(dfA.index))"
   ],
   "id": "fc9919a9cbede0f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4156,  844],\n",
       "       [   0,    0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:27.760186Z",
     "start_time": "2025-05-14T02:59:27.748031Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_kmeans)",
   "id": "2d9bf6e3572486ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9078200087374401"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:28.873823Z",
     "start_time": "2025-05-14T02:59:27.969791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ECM using exact blocking\n",
    "ecm = recordlinkage.ECMClassifier(binarize=0.8)\n",
    "result_ecm = ecm.fit_predict(features)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_ecm, total=len(dfA.index))"
   ],
   "id": "e2489b0db8512857",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3712, 1288],\n",
       "       [   5,   -5]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:28.924554Z",
     "start_time": "2025-05-14T02:59:28.913555Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_ecm)",
   "id": "53dfe0da77612d55",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516691522312723"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:29.284418Z",
     "start_time": "2025-05-14T02:59:28.971321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ECM using LSH blocking\n",
    "ecm = recordlinkage.ECMClassifier(binarize=0.8)\n",
    "result_ecm = ecm.fit_predict(features_lsh)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_ecm, total=len(dfA.index))"
   ],
   "id": "dff10a7ed5e4cfec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4171,  829],\n",
       "       [   4,   -4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:29.337232Z",
     "start_time": "2025-05-14T02:59:29.326211Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_ecm)",
   "id": "d0e22621fba512b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9092098092643053"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The results above demonstrate that LSH provides better results than exact-match blocking when dealing with dirty data in the blocking set. However, classification performance is not great.\n",
    "\n",
    "### Supervised Classifiers\n"
   ],
   "id": "5252849d62ec40c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:30.827214Z",
     "start_time": "2025-05-14T02:59:29.430244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a training set by splitting data\n",
    "training_dfA = dfA[0:500]\n",
    "training_dfB = dfB[0:500]\n",
    "training_match_idx = miTrueLinks[miTrueLinks.get_level_values(0).isin(training_dfA.index)]\n",
    "\n",
    "# index training set using LSH\n",
    "training_pairs_lsh = indexer.index(training_dfA, training_dfB)\n",
    "\n",
    "# compare training data\n",
    "training_features_lsh = comparison.compute(pairs=training_pairs_lsh, x=training_dfA, x_link=training_dfB)\n",
    "\n",
    "#classify using Naive Bayes Classifier\n",
    "nbc = recordlinkage.NaiveBayesClassifier(binarize=0.8)\n",
    "nbc.fit(training_features_lsh, training_match_idx)\n",
    "result_nbc = nbc.predict(features_lsh)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_nbc, total=len(dfA.index))\n"
   ],
   "id": "e6fceaae5905eb4f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 500/500 [00:00<00:00, 931.29it/s]\n",
      "C:\\Users\\v_mar\\AppData\\Local\\Temp\\ipykernel_49300\\246946091.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfA['minhash'] = dfA.swifter.apply(func=self._create_minhash, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfA: 0.6090634000720456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 500/500 [00:00<00:00, 919.03it/s]\n",
      "C:\\Users\\v_mar\\AppData\\Local\\Temp\\ipykernel_49300\\246946091.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfB['minhash'] = dfB.swifter.apply(func=self._create_minhash, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfB: 0.6167102999752387\n",
      "Seconds to build LSH of dfB: 0.04140750004444271\n",
      "Seconds to query dfB for each row of dfA: 0.037738599930889904\n",
      "Seconds to convert df to MultiIndex: 0.000710100051946938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4174,  826],\n",
       "       [  38,  -38]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:30.882850Z",
     "start_time": "2025-05-14T02:59:30.871335Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_nbc)",
   "id": "409d1a35a5b9be7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9062092922275292"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:30.986636Z",
     "start_time": "2025-05-14T02:59:30.976124Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.precision(links_true=miTrueLinks, links_pred=result_nbc)",
   "id": "497226046bcab9e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9909781576448243"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:31.051563Z",
     "start_time": "2025-05-14T02:59:31.041626Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.recall(links_true=miTrueLinks, links_pred=result_nbc)",
   "id": "9f30b04290b4ced5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:31.120828Z",
     "start_time": "2025-05-14T02:59:31.097676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#classify using SVM\n",
    "svc = recordlinkage.SVMClassifier() # options --> ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’\n",
    "svc.fit(training_features_lsh, training_match_idx)\n",
    "result_svc = svc.predict(features_lsh)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_svc, total=len(dfA.index))"
   ],
   "id": "2ebc732bcb41e33d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4160,  840],\n",
       "       [   0,    0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:31.201010Z",
     "start_time": "2025-05-14T02:59:31.188495Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_svc)",
   "id": "9e353bfae1e64047",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9082969432314411"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Real World Case\n",
    "\n",
    "Identifying personnel involved in clinical trials is a real-world challenge. For companies that sell software to organizations that perform clinical trials, having consistent and correct information about the physicians involved in clinical trials provides real value to customers. Often the same investigators participate in many clinical trials across many trial sponsors, each of whom have their own record of the investigator. Matching and deduplicating these records represents a challenge that all vendors have.\n",
    "\n",
    "The United States government requires providers that participate in electronic transactions specified in HIPAA to register with the National Plan & Provider Enumeration System (NPPES). When they register, they are supplied with National Provider Identifier (NPI) number. The NPPES database is available for download as text files.\n",
    "\n",
    "The government also requires that clinical trials run in the United States be registered online at the ClinicalTrials.gov website. This registry contains information about trials once they are registered with the FDA. The database includes information about investigators that are currently enrolling patients in clinical trials. Snapshots of the database are available for download.\n",
    "\n",
    "Using the PRLT library, we will attempt to match investigators between these two databases.\n",
    "\n",
    "The ClinicalTrials.gov investigators list was generated by downloading a snapshot of a PostgreSQL database from the [Clinical Trials Transformation Initiative](https://aact.ctti-clinicaltrials.org/download)'s website. The snapshot downloaded was from 2025-04-30. Once downloaded, the database was restored to a local PostgreSQL 17 instance and was analyzed. The following query was used to generate a csv file used for this analysis.\n",
    "\n",
    "    select\n",
    "        b.name as full_name,\n",
    "        a.city as city,\n",
    "        a.state as state,\n",
    "        a.zip as postal_code,\n",
    "        a.country as country,\n",
    "        a.nct_id\n",
    "    from\n",
    "        ctgov.facilities a\n",
    "    inner join\n",
    "        ctgov.facility_investigators b\n",
    "            on a.id = b.facility_id;\n",
    "\n"
   ],
   "id": "72d64065953048f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:31.617062Z",
     "start_time": "2025-05-14T02:59:31.330571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfCTGov = pd.read_csv('data/ctgov_investigators.zip', dtype='str')\n",
    "dfCTGov = dfCTGov.drop(columns=['country'])\n",
    "dfCTGov.rename(columns={\"full_name\": \"long_name\", \"postal_code\": \"postcode\"},inplace=True)\n",
    "dfCTGov.index.name = 'rec_id'\n",
    "dfCTGov"
   ],
   "id": "42cd3ee5ce360eb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     long_name         city       state postcode       nct_id\n",
       "rec_id                                                                       \n",
       "0              André BASCH, MD         Lyon         NaN      NaN  NCT03227419\n",
       "1              George Philteos         Ajax     Ontario  L1S 2J5  NCT06317285\n",
       "2                  James S. Hu  Los Angeles  California    90020  NCT06422806\n",
       "3              Bryan A. Faller    Centralia    Illinois    62801  NCT06422806\n",
       "4                Janet O. Chin  Orland Park    Illinois    60462  NCT06422806\n",
       "...                        ...          ...         ...      ...          ...\n",
       "196585        Adam J. Goldrich       Easton    Maryland    21601  NCT05334069\n",
       "196586    Aprinda I Queen, PhD  Gainesville     Florida    32610  NCT05998031\n",
       "196587      Klaus Arbeiter, MD       Vienna         NaN     1090  NCT01893710\n",
       "196588     Andrew A. Muskovitz     Dearborn    Michigan    48124  NCT05334069\n",
       "196589  Mahmoud Alalfy, master         Giza         NaN      NaN  NCT03829592\n",
       "\n",
       "[196590 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>nct_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>André BASCH, MD</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCT03227419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George Philteos</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>L1S 2J5</td>\n",
       "      <td>NCT06317285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James S. Hu</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90020</td>\n",
       "      <td>NCT06422806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bryan A. Faller</td>\n",
       "      <td>Centralia</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>62801</td>\n",
       "      <td>NCT06422806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Janet O. Chin</td>\n",
       "      <td>Orland Park</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>60462</td>\n",
       "      <td>NCT06422806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196585</th>\n",
       "      <td>Adam J. Goldrich</td>\n",
       "      <td>Easton</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>21601</td>\n",
       "      <td>NCT05334069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196586</th>\n",
       "      <td>Aprinda I Queen, PhD</td>\n",
       "      <td>Gainesville</td>\n",
       "      <td>Florida</td>\n",
       "      <td>32610</td>\n",
       "      <td>NCT05998031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196587</th>\n",
       "      <td>Klaus Arbeiter, MD</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1090</td>\n",
       "      <td>NCT01893710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196588</th>\n",
       "      <td>Andrew A. Muskovitz</td>\n",
       "      <td>Dearborn</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48124</td>\n",
       "      <td>NCT05334069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196589</th>\n",
       "      <td>Mahmoud Alalfy, master</td>\n",
       "      <td>Giza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCT03829592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196590 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The list of NPI investigators was generated by downloading NPI files from the [Centers fo Medicare & Medicaid Services website](https://download.cms.gov/nppes/NPI_Files.html). The file downloaded was the [Monthly NPPES Downloadable File Version 2 (April 14.2025)](https://download.cms.gov/nppes/NPPES_Data_Dissemination_April_2025_V2.zip). It was a very large file (~10GB), so the first 1000 rows was loaded as a Pandas Dataframe in order to understand it better.\n",
    "\n",
    "    dfNPI = pd.read_csv(\"npidata_pfile_20050523-20250413.csv\",nrows=1000)\n",
    "    cols = dfNPI.columns.tolist()\n",
    "\n",
    "This yielded 330 columns, of which the following were selected for use in further filtering and/or matching:\n",
    "\n",
    "    cols = ['NPI', 'Entity Type Code', 'Replacement NPI', 'Employer Identification Number (EIN)', 'Provider Organization Name (Legal Business Name)', 'Provider Last Name (Legal Name)', 'Provider First Name', 'Provider Middle Name', 'Provider Name Prefix Text', 'Provider Name Suffix Text', 'Provider Credential Text', 'Provider First Line Business Mailing Address', 'Provider Second Line Business Mailing Address', 'Provider Business Mailing Address City Name', 'Provider Business Mailing Address State Name', 'Provider Business Mailing Address Postal Code', 'Provider Business Mailing Address Country Code (If outside U.S.)', 'Provider Enumeration Date', 'Last Update Date', 'NPI Deactivation Reason Code', 'NPI Deactivation Date', 'NPI Reactivation Date']\n",
    "\n",
    "Using this list, all data was loaded:\n",
    "\n",
    "    dfNPI = pd.read_csv(\"npidata_pfile_20050523-20250413.csv\",usecols=cols)\n",
    "\n",
    "This yielded an 8.8M row dataset. To further reduce the size of the dataset, the following processing steps were applied:\n",
    "\n",
    "    # removed deactived entries\n",
    "    dfNPI = dfNPI[dfNPI['NPI Deactivation Date'].isna()]\n",
    "\n",
    "    # remove orgnization entries by restricting to type code 1\n",
    "    dfNPI = dfNPI[dfNPI['Entity Type Code'] == 1]\n",
    "\n",
    "    # process credentials to restrict to only physians (MD or DO)\n",
    "    dfNPI['creds'] = dfNPI['Provider Credential Text'].str.replace('.','')\n",
    "    dfNPI = dfNPI[(dfNPI['creds'].str.contains('md', case=False, na=False) | dfNPI['creds'].str.contains('do', case=False, na=False))\n",
    "                                               & ~dfNPI['creds'].str.contains('pharmd', case=False, na=False)]\n",
    "\n",
    "This reduced the file down to 1.3M rows. Column names that were to be used for processing were aligned with the column names used through this project and the dataset was trimmed further so that only the columns that matched the columns available from the CTGov sight were extracted and saved into a new CSV file.\n",
    "\n",
    "    dfNPI = dfNPI.rename(columns={'Provider Last Name (Legal Name)': 'surname', 'Provider First Name':'given_name', 'Provider Business Mailing Address City Name': 'city', 'Provider Business Mailing Address State Name': 'state', 'Provider Business Mailing Address Postal Code': 'postcode', 'NPI': 'npi' })\n",
    "\n",
    "    dfNPI.to_csv('data/npi_investigators.csv', columns=['given_name', 'surname', 'city', 'state', 'postcode', 'npi'], index=False, header=True)\n",
    "\n",
    "*NOTE: Code is included for completeness but files were too large to include as part of notebook*\n",
    "\n"
   ],
   "id": "e7522aee9f60f4be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:33.607896Z",
     "start_time": "2025-05-14T02:59:31.658595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfNPI = pd.read_csv('data/npi_investigators.zip', dtype='str')\n",
    "dfNPI['postcode'] = dfNPI['postcode'].str.replace('.0','',regex=False)\n",
    "dfNPI.index.name = 'rec_id'\n",
    "dfNPI"
   ],
   "id": "4b66f98dbafb3ff2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        given_name     surname          city state   postcode         npi\n",
       "rec_id                                                                   \n",
       "0            DAVID       WIEBE       KEARNEY    NE  688482168  1679576722\n",
       "1          WILLIAM     PILCHER  JACKSONVILLE    FL  322044736  1588667638\n",
       "2          LAURENT     GRESSOT       HOUSTON    TX  770901243  1215930367\n",
       "3             RAVI  ADUSUMILLI        TOLEDO    OH  436151753  1932102084\n",
       "4           ROBERT      BISBEE       LUBBOCK    TX  794073537  1750384806\n",
       "...            ...         ...           ...   ...        ...         ...\n",
       "1319114     ARMEND   BALIDEMAJ         BRONX    NY  104611197  1952196685\n",
       "1319115  ALEXANDER          LE    SUGAR LAND    TX  774786156  1770378408\n",
       "1319116       JAKE    HUNSAKER   GAINESVILLE    FL  326100254  1689469314\n",
       "1319117       ZAIN      MAJEED    SCOTTSDALE    AZ  852554866  1124813852\n",
       "1319118   SAMANTHA      BOEVER       GILBERT    AZ  852954874  1396530028\n",
       "\n",
       "[1319119 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>npi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>WIEBE</td>\n",
       "      <td>KEARNEY</td>\n",
       "      <td>NE</td>\n",
       "      <td>688482168</td>\n",
       "      <td>1679576722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>PILCHER</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "      <td>FL</td>\n",
       "      <td>322044736</td>\n",
       "      <td>1588667638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAURENT</td>\n",
       "      <td>GRESSOT</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TX</td>\n",
       "      <td>770901243</td>\n",
       "      <td>1215930367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAVI</td>\n",
       "      <td>ADUSUMILLI</td>\n",
       "      <td>TOLEDO</td>\n",
       "      <td>OH</td>\n",
       "      <td>436151753</td>\n",
       "      <td>1932102084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>BISBEE</td>\n",
       "      <td>LUBBOCK</td>\n",
       "      <td>TX</td>\n",
       "      <td>794073537</td>\n",
       "      <td>1750384806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319114</th>\n",
       "      <td>ARMEND</td>\n",
       "      <td>BALIDEMAJ</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NY</td>\n",
       "      <td>104611197</td>\n",
       "      <td>1952196685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319115</th>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>LE</td>\n",
       "      <td>SUGAR LAND</td>\n",
       "      <td>TX</td>\n",
       "      <td>774786156</td>\n",
       "      <td>1770378408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319116</th>\n",
       "      <td>JAKE</td>\n",
       "      <td>HUNSAKER</td>\n",
       "      <td>GAINESVILLE</td>\n",
       "      <td>FL</td>\n",
       "      <td>326100254</td>\n",
       "      <td>1689469314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319117</th>\n",
       "      <td>ZAIN</td>\n",
       "      <td>MAJEED</td>\n",
       "      <td>SCOTTSDALE</td>\n",
       "      <td>AZ</td>\n",
       "      <td>852554866</td>\n",
       "      <td>1124813852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319118</th>\n",
       "      <td>SAMANTHA</td>\n",
       "      <td>BOEVER</td>\n",
       "      <td>GILBERT</td>\n",
       "      <td>AZ</td>\n",
       "      <td>852954874</td>\n",
       "      <td>1396530028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319119 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will use the two 5000 record FEBRL datasets as training datasets and will use the CTGov and NPI datasets as our unknowns and will follow the same steps (Preprocessing, Indexing, Comparison, Classification).\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Since the ClinicalTrials.gov name field only stores a full name with middle initials and titles at the beginning and end of the name, we needed to use bespoke library called [Nameparser](https://nameparser.readthedocs.io/en/latest/index.html) for name parsing. This was necessary in order to properly split the names into first last and full, which is just first and last."
   ],
   "id": "d1ad259df08ddb9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:59:57.597266Z",
     "start_time": "2025-05-14T02:59:33.642420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# force strings to upper case\n",
    "dfCTGov = dfCTGov.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "# create given_name and surname fields from full_name\n",
    "dfCTGov['long_name'] = dfCTGov['long_name'].fillna('')\n",
    "\n",
    "constants = Constants()\n",
    "constants.titles.add(\"MD-PhD\",'pr','msc','otd','msci','b.a.')\n",
    "constants.suffix_acronyms.add(\"MD-PhD\",'pr','msc','otd','msci','b.a.')\n",
    "\n",
    "def parse_full_name(long_name):\n",
    "    name_obj = HumanName(long_name,constants=constants)\n",
    "    if len(name_obj.first) > 0 and len(name_obj.last) > 0:\n",
    "        full_name = name_obj.first + ' ' + name_obj.last\n",
    "    elif len(name_obj.first) == 0 and len(name_obj.last) > 0:\n",
    "        full_name = name_obj.last\n",
    "    else:\n",
    "        full_name = name_obj.first\n",
    "    return name_obj.first, name_obj.last, full_name\n",
    "\n",
    "dfCTGov[['given_name','surname', 'full_name']] = dfCTGov['long_name'].apply(lambda x: pd.Series(parse_full_name(x)))\n",
    "\n",
    "# collapse duplicates\n",
    "print(f'Size before removing dups: {len(dfCTGov)}')\n",
    "dfCTGov = dfCTGov.groupby(['given_name','surname','full_name','city','state', 'postcode'], as_index=False).agg({'nct_id': ' '.join})\n",
    "print(f'Size after removing dups: {len(dfCTGov)}')\n",
    "\n",
    "# process name fields phonetically\n",
    "dfCTGov['given_name_ph'] = phonetic(dfCTGov['given_name'],method='metaphone',decode_error='replace')\n",
    "dfCTGov['surname_ph'] = phonetic(dfCTGov['surname'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# process city phonetically\n",
    "dfCTGov[['city', 'state']] = dfCTGov[['city', 'state']].fillna('')\n",
    "dfCTGov['city_ph'] = phonetic(dfCTGov['city'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# replace nans in postcode and convert to int\n",
    "dfCTGov['postcode'] = dfCTGov['postcode'].fillna('0')\n",
    "dfCTGov['postcode_int'] = pd.to_numeric(dfCTGov['postcode'],errors='coerce')\n",
    "dfCTGov['postcode_int'] = dfCTGov['postcode_int'].fillna(0)\n",
    "\n",
    "# build text column\n",
    "dfCTGov['text'] = dfCTGov['full_name'] + ' ' + dfCTGov['city'] + ' ' + dfCTGov['state']\n",
    "\n",
    "dfCTGov"
   ],
   "id": "3a71eabde6a5d33a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before removing dups: 196590\n",
      "Size after removing dups: 77820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      given_name         surname        full_name         city  \\\n",
       "0                                                      HOUSTON   \n",
       "1                                                       NAPLES   \n",
       "2                      ABDELNOUR        ABDELNOUR  LOS ANGELES   \n",
       "3                 ADAM KRETOWSKI   ADAM KRETOWSKI    BIALYSTOK   \n",
       "4                 AFONSO NAZÁRIO   AFONSO NAZÁRIO    SÃO PAULO   \n",
       "...          ...             ...              ...          ...   \n",
       "77815     ŠTEFAN           PISTI     ŠTEFAN PISTI      OSTRAVA   \n",
       "77816     ŠTEFAN          REGULI    ŠTEFAN REGULI      OSTRAVA   \n",
       "77817      ŠÁRKA        BANÍKOVÁ   ŠÁRKA BANÍKOVÁ      OSTRAVA   \n",
       "77818      ŠÁRKA       BLAHUTOVÁ  ŠÁRKA BLAHUTOVÁ      OSTRAVA   \n",
       "77819      ŠÁRKA         ČECHOVÁ    ŠÁRKA ČECHOVÁ      OSTRAVA   \n",
       "\n",
       "                          state   postcode                   nct_id  \\\n",
       "0                         TEXAS      77030              NCT05238116   \n",
       "1                       FLORIDA      35105              NCT06564311   \n",
       "2                    CALIFORNIA      90095  NCT05268289 NCT05755386   \n",
       "3                     PODLASKIE     15-276              NCT04634591   \n",
       "4                            SP  04004-030  NCT05559528 NCT05398497   \n",
       "...                         ...        ...                      ...   \n",
       "77815  MORAVIAN-SILESIAN REGION     728 80              NCT05860387   \n",
       "77816  MORAVIAN-SILESIAN REGION      70852              NCT06933199   \n",
       "77817  MORAVIAN-SILESIAN REGION      70852              NCT05743413   \n",
       "77818  MORAVIAN-SILESIAN REGION     708 52              NCT06457438   \n",
       "77819  MORAVIAN-SILESIAN REGION      70852              NCT05743413   \n",
       "\n",
       "      given_name_ph surname_ph city_ph  postcode_int  \\\n",
       "0                                 HSTN       77030.0   \n",
       "1                                 NPLS       35105.0   \n",
       "2                       ABTLNR  LSNJLS       90095.0   \n",
       "3                     ATMKRTSK   BLSTK           0.0   \n",
       "4                      AFNSNSR     SPL           0.0   \n",
       "...             ...        ...     ...           ...   \n",
       "77815          STFN        PST   OSTRF           0.0   \n",
       "77816          STFN        RKL   OSTRF       70852.0   \n",
       "77817           SRK       BNKF   OSTRF       70852.0   \n",
       "77818           SRK      BLHTF   OSTRF           0.0   \n",
       "77819           SRK        KXF   OSTRF       70852.0   \n",
       "\n",
       "                                                   text  \n",
       "0                                         HOUSTON TEXAS  \n",
       "1                                        NAPLES FLORIDA  \n",
       "2                      ABDELNOUR LOS ANGELES CALIFORNIA  \n",
       "3                    ADAM KRETOWSKI BIALYSTOK PODLASKIE  \n",
       "4                           AFONSO NAZÁRIO SÃO PAULO SP  \n",
       "...                                                 ...  \n",
       "77815     ŠTEFAN PISTI OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "77816    ŠTEFAN REGULI OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "77817   ŠÁRKA BANÍKOVÁ OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "77818  ŠÁRKA BLAHUTOVÁ OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "77819    ŠÁRKA ČECHOVÁ OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "\n",
       "[77820 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>full_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>postcode_int</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td>NCT05238116</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HSTN</td>\n",
       "      <td>77030.0</td>\n",
       "      <td>HOUSTON TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NAPLES</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>35105</td>\n",
       "      <td>NCT06564311</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NPLS</td>\n",
       "      <td>35105.0</td>\n",
       "      <td>NAPLES FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>ABDELNOUR</td>\n",
       "      <td>ABDELNOUR</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>90095</td>\n",
       "      <td>NCT05268289 NCT05755386</td>\n",
       "      <td></td>\n",
       "      <td>ABTLNR</td>\n",
       "      <td>LSNJLS</td>\n",
       "      <td>90095.0</td>\n",
       "      <td>ABDELNOUR LOS ANGELES CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>ADAM KRETOWSKI</td>\n",
       "      <td>ADAM KRETOWSKI</td>\n",
       "      <td>BIALYSTOK</td>\n",
       "      <td>PODLASKIE</td>\n",
       "      <td>15-276</td>\n",
       "      <td>NCT04634591</td>\n",
       "      <td></td>\n",
       "      <td>ATMKRTSK</td>\n",
       "      <td>BLSTK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADAM KRETOWSKI BIALYSTOK PODLASKIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>AFONSO NAZÁRIO</td>\n",
       "      <td>AFONSO NAZÁRIO</td>\n",
       "      <td>SÃO PAULO</td>\n",
       "      <td>SP</td>\n",
       "      <td>04004-030</td>\n",
       "      <td>NCT05559528 NCT05398497</td>\n",
       "      <td></td>\n",
       "      <td>AFNSNSR</td>\n",
       "      <td>SPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFONSO NAZÁRIO SÃO PAULO SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77815</th>\n",
       "      <td>ŠTEFAN</td>\n",
       "      <td>PISTI</td>\n",
       "      <td>ŠTEFAN PISTI</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>728 80</td>\n",
       "      <td>NCT05860387</td>\n",
       "      <td>STFN</td>\n",
       "      <td>PST</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ŠTEFAN PISTI OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77816</th>\n",
       "      <td>ŠTEFAN</td>\n",
       "      <td>REGULI</td>\n",
       "      <td>ŠTEFAN REGULI</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>70852</td>\n",
       "      <td>NCT06933199</td>\n",
       "      <td>STFN</td>\n",
       "      <td>RKL</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>70852.0</td>\n",
       "      <td>ŠTEFAN REGULI OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77817</th>\n",
       "      <td>ŠÁRKA</td>\n",
       "      <td>BANÍKOVÁ</td>\n",
       "      <td>ŠÁRKA BANÍKOVÁ</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>70852</td>\n",
       "      <td>NCT05743413</td>\n",
       "      <td>SRK</td>\n",
       "      <td>BNKF</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>70852.0</td>\n",
       "      <td>ŠÁRKA BANÍKOVÁ OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77818</th>\n",
       "      <td>ŠÁRKA</td>\n",
       "      <td>BLAHUTOVÁ</td>\n",
       "      <td>ŠÁRKA BLAHUTOVÁ</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>708 52</td>\n",
       "      <td>NCT06457438</td>\n",
       "      <td>SRK</td>\n",
       "      <td>BLHTF</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ŠÁRKA BLAHUTOVÁ OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77819</th>\n",
       "      <td>ŠÁRKA</td>\n",
       "      <td>ČECHOVÁ</td>\n",
       "      <td>ŠÁRKA ČECHOVÁ</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>70852</td>\n",
       "      <td>NCT05743413</td>\n",
       "      <td>SRK</td>\n",
       "      <td>KXF</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>70852.0</td>\n",
       "      <td>ŠÁRKA ČECHOVÁ OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77820 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Processing of the NPI dataset is very similar to the processing of the FEBRL datasets used for training.",
   "id": "6967bde84e5a7bbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:00:10.079414Z",
     "start_time": "2025-05-14T02:59:57.629793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create given_name and surname fields from full_name\n",
    "dfNPI['full_name'] = dfNPI['given_name'] + ' ' + dfNPI['surname']\n",
    "dfNPI['full_name'] = dfNPI['full_name'].str.strip()\n",
    "dfNPI['full_name'] = dfNPI['full_name'].fillna('')\n",
    "\n",
    "# process name fields phonetically\n",
    "dfNPI[['given_name', 'surname']] = dfNPI[['given_name', 'surname']].fillna('')\n",
    "dfNPI['given_name_ph'] = phonetic(dfNPI['given_name'],method='metaphone',decode_error='replace')\n",
    "dfNPI['surname_ph'] = phonetic(dfNPI['surname'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# process city phonetically\n",
    "dfNPI[['city', 'state']] = dfNPI[['city', 'state']].fillna('')\n",
    "dfNPI['city_ph'] = phonetic(dfNPI['city'],method='metaphone',decode_error='replace')\n",
    "def convert_abbr_to_name(input):\n",
    "    state = us.states.lookup(input)\n",
    "    return state.name.upper() if state else input\n",
    "dfNPI['state'] = dfNPI['state'].apply(convert_abbr_to_name)\n",
    "\n",
    "# replace nans in postcode and convert to int\n",
    "dfNPI['postcode'] = dfNPI['postcode'].fillna('0')\n",
    "dfNPI['postcode'] = dfNPI['postcode'].str[:5]  # take the first 5 for US matches\n",
    "dfNPI['postcode_int'] = pd.to_numeric(dfNPI['postcode'],errors='coerce')\n",
    "dfNPI['postcode_int'] = dfNPI['postcode_int'].fillna(0)\n",
    "\n",
    "# build text column\n",
    "dfNPI['text'] = dfNPI['full_name'] + ' ' + dfNPI['city'] + ' ' + dfNPI['state']\n",
    "\n",
    "dfNPI"
   ],
   "id": "5ddebab67961d23b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        given_name     surname          city     state postcode         npi  \\\n",
       "rec_id                                                                        \n",
       "0            DAVID       WIEBE       KEARNEY  NEBRASKA    68848  1679576722   \n",
       "1          WILLIAM     PILCHER  JACKSONVILLE   FLORIDA    32204  1588667638   \n",
       "2          LAURENT     GRESSOT       HOUSTON     TEXAS    77090  1215930367   \n",
       "3             RAVI  ADUSUMILLI        TOLEDO      OHIO    43615  1932102084   \n",
       "4           ROBERT      BISBEE       LUBBOCK     TEXAS    79407  1750384806   \n",
       "...            ...         ...           ...       ...      ...         ...   \n",
       "1319114     ARMEND   BALIDEMAJ         BRONX  NEW YORK    10461  1952196685   \n",
       "1319115  ALEXANDER          LE    SUGAR LAND     TEXAS    77478  1770378408   \n",
       "1319116       JAKE    HUNSAKER   GAINESVILLE   FLORIDA    32610  1689469314   \n",
       "1319117       ZAIN      MAJEED    SCOTTSDALE   ARIZONA    85255  1124813852   \n",
       "1319118   SAMANTHA      BOEVER       GILBERT   ARIZONA    85295  1396530028   \n",
       "\n",
       "                full_name given_name_ph surname_ph city_ph  postcode_int  \\\n",
       "rec_id                                                                     \n",
       "0             DAVID WIEBE           TFT         WB     KRN       68848.0   \n",
       "1         WILLIAM PILCHER           WLM       PLXR  JKSNFL       32204.0   \n",
       "2         LAURENT GRESSOT          LRNT       KRST    HSTN       77090.0   \n",
       "3         RAVI ADUSUMILLI            RF      ATSML     TLT       43615.0   \n",
       "4           ROBERT BISBEE          RBRT        BSB     LBK       79407.0   \n",
       "...                   ...           ...        ...     ...           ...   \n",
       "1319114  ARMEND BALIDEMAJ         ARMNT      BLTMJ   BRNKS       10461.0   \n",
       "1319115      ALEXANDER LE       ALKSNTR          L  SKRLNT       77478.0   \n",
       "1319116     JAKE HUNSAKER            JK      HNSKR   KNSFL       32610.0   \n",
       "1319117       ZAIN MAJEED            SN        MJT  SKTSTL       85255.0   \n",
       "1319118   SAMANTHA BOEVER          SMN0        BFR   JLBRT       85295.0   \n",
       "\n",
       "                                         text  \n",
       "rec_id                                         \n",
       "0                DAVID WIEBE KEARNEY NEBRASKA  \n",
       "1        WILLIAM PILCHER JACKSONVILLE FLORIDA  \n",
       "2               LAURENT GRESSOT HOUSTON TEXAS  \n",
       "3                 RAVI ADUSUMILLI TOLEDO OHIO  \n",
       "4                 ROBERT BISBEE LUBBOCK TEXAS  \n",
       "...                                       ...  \n",
       "1319114       ARMEND BALIDEMAJ BRONX NEW YORK  \n",
       "1319115         ALEXANDER LE SUGAR LAND TEXAS  \n",
       "1319116     JAKE HUNSAKER GAINESVILLE FLORIDA  \n",
       "1319117        ZAIN MAJEED SCOTTSDALE ARIZONA  \n",
       "1319118       SAMANTHA BOEVER GILBERT ARIZONA  \n",
       "\n",
       "[1319119 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>npi</th>\n",
       "      <th>full_name</th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>postcode_int</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>WIEBE</td>\n",
       "      <td>KEARNEY</td>\n",
       "      <td>NEBRASKA</td>\n",
       "      <td>68848</td>\n",
       "      <td>1679576722</td>\n",
       "      <td>DAVID WIEBE</td>\n",
       "      <td>TFT</td>\n",
       "      <td>WB</td>\n",
       "      <td>KRN</td>\n",
       "      <td>68848.0</td>\n",
       "      <td>DAVID WIEBE KEARNEY NEBRASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>PILCHER</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>32204</td>\n",
       "      <td>1588667638</td>\n",
       "      <td>WILLIAM PILCHER</td>\n",
       "      <td>WLM</td>\n",
       "      <td>PLXR</td>\n",
       "      <td>JKSNFL</td>\n",
       "      <td>32204.0</td>\n",
       "      <td>WILLIAM PILCHER JACKSONVILLE FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAURENT</td>\n",
       "      <td>GRESSOT</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77090</td>\n",
       "      <td>1215930367</td>\n",
       "      <td>LAURENT GRESSOT</td>\n",
       "      <td>LRNT</td>\n",
       "      <td>KRST</td>\n",
       "      <td>HSTN</td>\n",
       "      <td>77090.0</td>\n",
       "      <td>LAURENT GRESSOT HOUSTON TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAVI</td>\n",
       "      <td>ADUSUMILLI</td>\n",
       "      <td>TOLEDO</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>43615</td>\n",
       "      <td>1932102084</td>\n",
       "      <td>RAVI ADUSUMILLI</td>\n",
       "      <td>RF</td>\n",
       "      <td>ATSML</td>\n",
       "      <td>TLT</td>\n",
       "      <td>43615.0</td>\n",
       "      <td>RAVI ADUSUMILLI TOLEDO OHIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>BISBEE</td>\n",
       "      <td>LUBBOCK</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>79407</td>\n",
       "      <td>1750384806</td>\n",
       "      <td>ROBERT BISBEE</td>\n",
       "      <td>RBRT</td>\n",
       "      <td>BSB</td>\n",
       "      <td>LBK</td>\n",
       "      <td>79407.0</td>\n",
       "      <td>ROBERT BISBEE LUBBOCK TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319114</th>\n",
       "      <td>ARMEND</td>\n",
       "      <td>BALIDEMAJ</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>10461</td>\n",
       "      <td>1952196685</td>\n",
       "      <td>ARMEND BALIDEMAJ</td>\n",
       "      <td>ARMNT</td>\n",
       "      <td>BLTMJ</td>\n",
       "      <td>BRNKS</td>\n",
       "      <td>10461.0</td>\n",
       "      <td>ARMEND BALIDEMAJ BRONX NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319115</th>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>LE</td>\n",
       "      <td>SUGAR LAND</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77478</td>\n",
       "      <td>1770378408</td>\n",
       "      <td>ALEXANDER LE</td>\n",
       "      <td>ALKSNTR</td>\n",
       "      <td>L</td>\n",
       "      <td>SKRLNT</td>\n",
       "      <td>77478.0</td>\n",
       "      <td>ALEXANDER LE SUGAR LAND TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319116</th>\n",
       "      <td>JAKE</td>\n",
       "      <td>HUNSAKER</td>\n",
       "      <td>GAINESVILLE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>32610</td>\n",
       "      <td>1689469314</td>\n",
       "      <td>JAKE HUNSAKER</td>\n",
       "      <td>JK</td>\n",
       "      <td>HNSKR</td>\n",
       "      <td>KNSFL</td>\n",
       "      <td>32610.0</td>\n",
       "      <td>JAKE HUNSAKER GAINESVILLE FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319117</th>\n",
       "      <td>ZAIN</td>\n",
       "      <td>MAJEED</td>\n",
       "      <td>SCOTTSDALE</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>85255</td>\n",
       "      <td>1124813852</td>\n",
       "      <td>ZAIN MAJEED</td>\n",
       "      <td>SN</td>\n",
       "      <td>MJT</td>\n",
       "      <td>SKTSTL</td>\n",
       "      <td>85255.0</td>\n",
       "      <td>ZAIN MAJEED SCOTTSDALE ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319118</th>\n",
       "      <td>SAMANTHA</td>\n",
       "      <td>BOEVER</td>\n",
       "      <td>GILBERT</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>85295</td>\n",
       "      <td>1396530028</td>\n",
       "      <td>SAMANTHA BOEVER</td>\n",
       "      <td>SMN0</td>\n",
       "      <td>BFR</td>\n",
       "      <td>JLBRT</td>\n",
       "      <td>85295.0</td>\n",
       "      <td>SAMANTHA BOEVER GILBERT ARIZONA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319119 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:00:20.114764Z",
     "start_time": "2025-05-14T03:00:10.115443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge to identify exact matches\n",
    "merged_df = pd.merge(dfCTGov, dfNPI, on=['given_name', 'surname', 'city', 'state', 'postcode'], how='outer', indicator=True)\n",
    "\n",
    "# Extract exact matches\n",
    "dfMatches = merged_df[merged_df['_merge'] == 'both'].drop('_merge', axis=1)\n",
    "dfMatches = dfMatches[['given_name', 'surname', 'city', 'state', 'postcode', 'npi', 'nct_id']]\n",
    "\n",
    "# Remove matched records from dfCTGov and dfNPI\n",
    "dfCTGov = dfCTGov[~dfCTGov.set_index(['given_name', 'surname', 'city', 'state', 'postcode'])\n",
    "                .index.isin(dfMatches.set_index(['given_name', 'surname', 'city', 'state', 'postcode']).index)].reset_index(drop=True)\n",
    "\n",
    "dfNPI = dfNPI[~dfNPI.set_index(['given_name', 'surname', 'city', 'state', 'postcode'])\n",
    "                .index.isin(dfMatches.set_index(['given_name', 'surname', 'city', 'state', 'postcode']).index)].reset_index(drop=True)\n",
    "\n",
    "# Show exact matches\n",
    "dfMatches"
   ],
   "id": "7124d23583adeada",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        given_name    surname          city          state postcode  \\\n",
       "875          AADEL  CHAUDHURI     ROCHESTER      MINNESOTA    55905   \n",
       "957         AAKASH      BATRA   LOS ANGELES     CALIFORNIA    90027   \n",
       "1027       AAKRITI     SHUKLA  PHILADELPHIA   PENNSYLVANIA    19107   \n",
       "1140         AAMIR  BADRUDDIN        JOLIET       ILLINOIS    60435   \n",
       "1164         AAMIR      JAMAL     SAN DIMAS     CALIFORNIA    91773   \n",
       "...            ...        ...           ...            ...      ...   \n",
       "1388077        ZOE  WEINSTEIN        BOSTON  MASSACHUSETTS    02118   \n",
       "1388293     ZOLTAN       MARI     LAS VEGAS         NEVADA    89106   \n",
       "1388581     ZUBAID    RAFIQUE       HOUSTON          TEXAS    77030   \n",
       "1388635     ZUBAIR       SHAH   KANSAS CITY         KANSAS    66160   \n",
       "1388932     ZUNERA      TARIQ  INDIANAPOLIS        INDIANA    46202   \n",
       "\n",
       "                npi  \\\n",
       "875      1487097572   \n",
       "957      1578050597   \n",
       "1027     1578976973   \n",
       "1140     1871769331   \n",
       "1164     1558377523   \n",
       "...             ...   \n",
       "1388077  1851682306   \n",
       "1388293  1366480048   \n",
       "1388581  1730386343   \n",
       "1388635  1386942126   \n",
       "1388932  1285017020   \n",
       "\n",
       "                                                                                      nct_id  \n",
       "875                                                                              NCT06817408  \n",
       "957      NCT03488693 NCT04852887 NCT06500455 NCT03180268 NCT04804644 NCT05438212 NCT04671667  \n",
       "1027                                                                             NCT04784234  \n",
       "1140                                                                             NCT01748903  \n",
       "1164                                                                 NCT04557462 NCT06383390  \n",
       "...                                                                                      ...  \n",
       "1388077                                                                          NCT06323824  \n",
       "1388293                                                              NCT06680830 NCT04477785  \n",
       "1388581                                                  NCT04423198 NCT04423198 NCT05090319  \n",
       "1388635                                                                          NCT06526195  \n",
       "1388932                                                                          NCT06449677  \n",
       "\n",
       "[7806 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>npi</th>\n",
       "      <th>nct_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>AADEL</td>\n",
       "      <td>CHAUDHURI</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>55905</td>\n",
       "      <td>1487097572</td>\n",
       "      <td>NCT06817408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>AAKASH</td>\n",
       "      <td>BATRA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>90027</td>\n",
       "      <td>1578050597</td>\n",
       "      <td>NCT03488693 NCT04852887 NCT06500455 NCT03180268 NCT04804644 NCT05438212 NCT04671667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>AAKRITI</td>\n",
       "      <td>SHUKLA</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>19107</td>\n",
       "      <td>1578976973</td>\n",
       "      <td>NCT04784234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>AAMIR</td>\n",
       "      <td>BADRUDDIN</td>\n",
       "      <td>JOLIET</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>60435</td>\n",
       "      <td>1871769331</td>\n",
       "      <td>NCT01748903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>AAMIR</td>\n",
       "      <td>JAMAL</td>\n",
       "      <td>SAN DIMAS</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>91773</td>\n",
       "      <td>1558377523</td>\n",
       "      <td>NCT04557462 NCT06383390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388077</th>\n",
       "      <td>ZOE</td>\n",
       "      <td>WEINSTEIN</td>\n",
       "      <td>BOSTON</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>02118</td>\n",
       "      <td>1851682306</td>\n",
       "      <td>NCT06323824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388293</th>\n",
       "      <td>ZOLTAN</td>\n",
       "      <td>MARI</td>\n",
       "      <td>LAS VEGAS</td>\n",
       "      <td>NEVADA</td>\n",
       "      <td>89106</td>\n",
       "      <td>1366480048</td>\n",
       "      <td>NCT06680830 NCT04477785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388581</th>\n",
       "      <td>ZUBAID</td>\n",
       "      <td>RAFIQUE</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td>1730386343</td>\n",
       "      <td>NCT04423198 NCT04423198 NCT05090319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388635</th>\n",
       "      <td>ZUBAIR</td>\n",
       "      <td>SHAH</td>\n",
       "      <td>KANSAS CITY</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>66160</td>\n",
       "      <td>1386942126</td>\n",
       "      <td>NCT06526195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388932</th>\n",
       "      <td>ZUNERA</td>\n",
       "      <td>TARIQ</td>\n",
       "      <td>INDIANAPOLIS</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>46202</td>\n",
       "      <td>1285017020</td>\n",
       "      <td>NCT06449677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7806 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:00:20.238918Z",
     "start_time": "2025-05-14T03:00:20.228650Z"
    }
   },
   "cell_type": "code",
   "source": "dfCTGov",
   "id": "ea97deb2b3cc2823",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      given_name         surname        full_name         city  \\\n",
       "0                                                      HOUSTON   \n",
       "1                                                       NAPLES   \n",
       "2                      ABDELNOUR        ABDELNOUR  LOS ANGELES   \n",
       "3                 ADAM KRETOWSKI   ADAM KRETOWSKI    BIALYSTOK   \n",
       "4                 AFONSO NAZÁRIO   AFONSO NAZÁRIO    SÃO PAULO   \n",
       "...          ...             ...              ...          ...   \n",
       "70035     ŠTEFAN           PISTI     ŠTEFAN PISTI      OSTRAVA   \n",
       "70036     ŠTEFAN          REGULI    ŠTEFAN REGULI      OSTRAVA   \n",
       "70037      ŠÁRKA        BANÍKOVÁ   ŠÁRKA BANÍKOVÁ      OSTRAVA   \n",
       "70038      ŠÁRKA       BLAHUTOVÁ  ŠÁRKA BLAHUTOVÁ      OSTRAVA   \n",
       "70039      ŠÁRKA         ČECHOVÁ    ŠÁRKA ČECHOVÁ      OSTRAVA   \n",
       "\n",
       "                          state   postcode                   nct_id  \\\n",
       "0                         TEXAS      77030              NCT05238116   \n",
       "1                       FLORIDA      35105              NCT06564311   \n",
       "2                    CALIFORNIA      90095  NCT05268289 NCT05755386   \n",
       "3                     PODLASKIE     15-276              NCT04634591   \n",
       "4                            SP  04004-030  NCT05559528 NCT05398497   \n",
       "...                         ...        ...                      ...   \n",
       "70035  MORAVIAN-SILESIAN REGION     728 80              NCT05860387   \n",
       "70036  MORAVIAN-SILESIAN REGION      70852              NCT06933199   \n",
       "70037  MORAVIAN-SILESIAN REGION      70852              NCT05743413   \n",
       "70038  MORAVIAN-SILESIAN REGION     708 52              NCT06457438   \n",
       "70039  MORAVIAN-SILESIAN REGION      70852              NCT05743413   \n",
       "\n",
       "      given_name_ph surname_ph city_ph  postcode_int  \\\n",
       "0                                 HSTN       77030.0   \n",
       "1                                 NPLS       35105.0   \n",
       "2                       ABTLNR  LSNJLS       90095.0   \n",
       "3                     ATMKRTSK   BLSTK           0.0   \n",
       "4                      AFNSNSR     SPL           0.0   \n",
       "...             ...        ...     ...           ...   \n",
       "70035          STFN        PST   OSTRF           0.0   \n",
       "70036          STFN        RKL   OSTRF       70852.0   \n",
       "70037           SRK       BNKF   OSTRF       70852.0   \n",
       "70038           SRK      BLHTF   OSTRF           0.0   \n",
       "70039           SRK        KXF   OSTRF       70852.0   \n",
       "\n",
       "                                                   text  \n",
       "0                                         HOUSTON TEXAS  \n",
       "1                                        NAPLES FLORIDA  \n",
       "2                      ABDELNOUR LOS ANGELES CALIFORNIA  \n",
       "3                    ADAM KRETOWSKI BIALYSTOK PODLASKIE  \n",
       "4                           AFONSO NAZÁRIO SÃO PAULO SP  \n",
       "...                                                 ...  \n",
       "70035     ŠTEFAN PISTI OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "70036    ŠTEFAN REGULI OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "70037   ŠÁRKA BANÍKOVÁ OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "70038  ŠÁRKA BLAHUTOVÁ OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "70039    ŠÁRKA ČECHOVÁ OSTRAVA MORAVIAN-SILESIAN REGION  \n",
       "\n",
       "[70040 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>full_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>postcode_int</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td>NCT05238116</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HSTN</td>\n",
       "      <td>77030.0</td>\n",
       "      <td>HOUSTON TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NAPLES</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>35105</td>\n",
       "      <td>NCT06564311</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NPLS</td>\n",
       "      <td>35105.0</td>\n",
       "      <td>NAPLES FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>ABDELNOUR</td>\n",
       "      <td>ABDELNOUR</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>90095</td>\n",
       "      <td>NCT05268289 NCT05755386</td>\n",
       "      <td></td>\n",
       "      <td>ABTLNR</td>\n",
       "      <td>LSNJLS</td>\n",
       "      <td>90095.0</td>\n",
       "      <td>ABDELNOUR LOS ANGELES CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>ADAM KRETOWSKI</td>\n",
       "      <td>ADAM KRETOWSKI</td>\n",
       "      <td>BIALYSTOK</td>\n",
       "      <td>PODLASKIE</td>\n",
       "      <td>15-276</td>\n",
       "      <td>NCT04634591</td>\n",
       "      <td></td>\n",
       "      <td>ATMKRTSK</td>\n",
       "      <td>BLSTK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADAM KRETOWSKI BIALYSTOK PODLASKIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>AFONSO NAZÁRIO</td>\n",
       "      <td>AFONSO NAZÁRIO</td>\n",
       "      <td>SÃO PAULO</td>\n",
       "      <td>SP</td>\n",
       "      <td>04004-030</td>\n",
       "      <td>NCT05559528 NCT05398497</td>\n",
       "      <td></td>\n",
       "      <td>AFNSNSR</td>\n",
       "      <td>SPL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFONSO NAZÁRIO SÃO PAULO SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70035</th>\n",
       "      <td>ŠTEFAN</td>\n",
       "      <td>PISTI</td>\n",
       "      <td>ŠTEFAN PISTI</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>728 80</td>\n",
       "      <td>NCT05860387</td>\n",
       "      <td>STFN</td>\n",
       "      <td>PST</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ŠTEFAN PISTI OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70036</th>\n",
       "      <td>ŠTEFAN</td>\n",
       "      <td>REGULI</td>\n",
       "      <td>ŠTEFAN REGULI</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>70852</td>\n",
       "      <td>NCT06933199</td>\n",
       "      <td>STFN</td>\n",
       "      <td>RKL</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>70852.0</td>\n",
       "      <td>ŠTEFAN REGULI OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70037</th>\n",
       "      <td>ŠÁRKA</td>\n",
       "      <td>BANÍKOVÁ</td>\n",
       "      <td>ŠÁRKA BANÍKOVÁ</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>70852</td>\n",
       "      <td>NCT05743413</td>\n",
       "      <td>SRK</td>\n",
       "      <td>BNKF</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>70852.0</td>\n",
       "      <td>ŠÁRKA BANÍKOVÁ OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70038</th>\n",
       "      <td>ŠÁRKA</td>\n",
       "      <td>BLAHUTOVÁ</td>\n",
       "      <td>ŠÁRKA BLAHUTOVÁ</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>708 52</td>\n",
       "      <td>NCT06457438</td>\n",
       "      <td>SRK</td>\n",
       "      <td>BLHTF</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ŠÁRKA BLAHUTOVÁ OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70039</th>\n",
       "      <td>ŠÁRKA</td>\n",
       "      <td>ČECHOVÁ</td>\n",
       "      <td>ŠÁRKA ČECHOVÁ</td>\n",
       "      <td>OSTRAVA</td>\n",
       "      <td>MORAVIAN-SILESIAN REGION</td>\n",
       "      <td>70852</td>\n",
       "      <td>NCT05743413</td>\n",
       "      <td>SRK</td>\n",
       "      <td>KXF</td>\n",
       "      <td>OSTRF</td>\n",
       "      <td>70852.0</td>\n",
       "      <td>ŠÁRKA ČECHOVÁ OSTRAVA MORAVIAN-SILESIAN REGION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70040 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:00:20.374149Z",
     "start_time": "2025-05-14T03:00:20.363994Z"
    }
   },
   "cell_type": "code",
   "source": "dfNPI",
   "id": "677f8008d7424344",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        given_name     surname          city     state postcode         npi  \\\n",
       "0            DAVID       WIEBE       KEARNEY  NEBRASKA    68848  1679576722   \n",
       "1          WILLIAM     PILCHER  JACKSONVILLE   FLORIDA    32204  1588667638   \n",
       "2          LAURENT     GRESSOT       HOUSTON     TEXAS    77090  1215930367   \n",
       "3             RAVI  ADUSUMILLI        TOLEDO      OHIO    43615  1932102084   \n",
       "4           ROBERT      BISBEE       LUBBOCK     TEXAS    79407  1750384806   \n",
       "...            ...         ...           ...       ...      ...         ...   \n",
       "1311308     ARMEND   BALIDEMAJ         BRONX  NEW YORK    10461  1952196685   \n",
       "1311309  ALEXANDER          LE    SUGAR LAND     TEXAS    77478  1770378408   \n",
       "1311310       JAKE    HUNSAKER   GAINESVILLE   FLORIDA    32610  1689469314   \n",
       "1311311       ZAIN      MAJEED    SCOTTSDALE   ARIZONA    85255  1124813852   \n",
       "1311312   SAMANTHA      BOEVER       GILBERT   ARIZONA    85295  1396530028   \n",
       "\n",
       "                full_name given_name_ph surname_ph city_ph  postcode_int  \\\n",
       "0             DAVID WIEBE           TFT         WB     KRN       68848.0   \n",
       "1         WILLIAM PILCHER           WLM       PLXR  JKSNFL       32204.0   \n",
       "2         LAURENT GRESSOT          LRNT       KRST    HSTN       77090.0   \n",
       "3         RAVI ADUSUMILLI            RF      ATSML     TLT       43615.0   \n",
       "4           ROBERT BISBEE          RBRT        BSB     LBK       79407.0   \n",
       "...                   ...           ...        ...     ...           ...   \n",
       "1311308  ARMEND BALIDEMAJ         ARMNT      BLTMJ   BRNKS       10461.0   \n",
       "1311309      ALEXANDER LE       ALKSNTR          L  SKRLNT       77478.0   \n",
       "1311310     JAKE HUNSAKER            JK      HNSKR   KNSFL       32610.0   \n",
       "1311311       ZAIN MAJEED            SN        MJT  SKTSTL       85255.0   \n",
       "1311312   SAMANTHA BOEVER          SMN0        BFR   JLBRT       85295.0   \n",
       "\n",
       "                                         text  \n",
       "0                DAVID WIEBE KEARNEY NEBRASKA  \n",
       "1        WILLIAM PILCHER JACKSONVILLE FLORIDA  \n",
       "2               LAURENT GRESSOT HOUSTON TEXAS  \n",
       "3                 RAVI ADUSUMILLI TOLEDO OHIO  \n",
       "4                 ROBERT BISBEE LUBBOCK TEXAS  \n",
       "...                                       ...  \n",
       "1311308       ARMEND BALIDEMAJ BRONX NEW YORK  \n",
       "1311309         ALEXANDER LE SUGAR LAND TEXAS  \n",
       "1311310     JAKE HUNSAKER GAINESVILLE FLORIDA  \n",
       "1311311        ZAIN MAJEED SCOTTSDALE ARIZONA  \n",
       "1311312       SAMANTHA BOEVER GILBERT ARIZONA  \n",
       "\n",
       "[1311313 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>npi</th>\n",
       "      <th>full_name</th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>postcode_int</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>WIEBE</td>\n",
       "      <td>KEARNEY</td>\n",
       "      <td>NEBRASKA</td>\n",
       "      <td>68848</td>\n",
       "      <td>1679576722</td>\n",
       "      <td>DAVID WIEBE</td>\n",
       "      <td>TFT</td>\n",
       "      <td>WB</td>\n",
       "      <td>KRN</td>\n",
       "      <td>68848.0</td>\n",
       "      <td>DAVID WIEBE KEARNEY NEBRASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>PILCHER</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>32204</td>\n",
       "      <td>1588667638</td>\n",
       "      <td>WILLIAM PILCHER</td>\n",
       "      <td>WLM</td>\n",
       "      <td>PLXR</td>\n",
       "      <td>JKSNFL</td>\n",
       "      <td>32204.0</td>\n",
       "      <td>WILLIAM PILCHER JACKSONVILLE FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAURENT</td>\n",
       "      <td>GRESSOT</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77090</td>\n",
       "      <td>1215930367</td>\n",
       "      <td>LAURENT GRESSOT</td>\n",
       "      <td>LRNT</td>\n",
       "      <td>KRST</td>\n",
       "      <td>HSTN</td>\n",
       "      <td>77090.0</td>\n",
       "      <td>LAURENT GRESSOT HOUSTON TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAVI</td>\n",
       "      <td>ADUSUMILLI</td>\n",
       "      <td>TOLEDO</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>43615</td>\n",
       "      <td>1932102084</td>\n",
       "      <td>RAVI ADUSUMILLI</td>\n",
       "      <td>RF</td>\n",
       "      <td>ATSML</td>\n",
       "      <td>TLT</td>\n",
       "      <td>43615.0</td>\n",
       "      <td>RAVI ADUSUMILLI TOLEDO OHIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>BISBEE</td>\n",
       "      <td>LUBBOCK</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>79407</td>\n",
       "      <td>1750384806</td>\n",
       "      <td>ROBERT BISBEE</td>\n",
       "      <td>RBRT</td>\n",
       "      <td>BSB</td>\n",
       "      <td>LBK</td>\n",
       "      <td>79407.0</td>\n",
       "      <td>ROBERT BISBEE LUBBOCK TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311308</th>\n",
       "      <td>ARMEND</td>\n",
       "      <td>BALIDEMAJ</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>10461</td>\n",
       "      <td>1952196685</td>\n",
       "      <td>ARMEND BALIDEMAJ</td>\n",
       "      <td>ARMNT</td>\n",
       "      <td>BLTMJ</td>\n",
       "      <td>BRNKS</td>\n",
       "      <td>10461.0</td>\n",
       "      <td>ARMEND BALIDEMAJ BRONX NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311309</th>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>LE</td>\n",
       "      <td>SUGAR LAND</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77478</td>\n",
       "      <td>1770378408</td>\n",
       "      <td>ALEXANDER LE</td>\n",
       "      <td>ALKSNTR</td>\n",
       "      <td>L</td>\n",
       "      <td>SKRLNT</td>\n",
       "      <td>77478.0</td>\n",
       "      <td>ALEXANDER LE SUGAR LAND TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311310</th>\n",
       "      <td>JAKE</td>\n",
       "      <td>HUNSAKER</td>\n",
       "      <td>GAINESVILLE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>32610</td>\n",
       "      <td>1689469314</td>\n",
       "      <td>JAKE HUNSAKER</td>\n",
       "      <td>JK</td>\n",
       "      <td>HNSKR</td>\n",
       "      <td>KNSFL</td>\n",
       "      <td>32610.0</td>\n",
       "      <td>JAKE HUNSAKER GAINESVILLE FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311311</th>\n",
       "      <td>ZAIN</td>\n",
       "      <td>MAJEED</td>\n",
       "      <td>SCOTTSDALE</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>85255</td>\n",
       "      <td>1124813852</td>\n",
       "      <td>ZAIN MAJEED</td>\n",
       "      <td>SN</td>\n",
       "      <td>MJT</td>\n",
       "      <td>SKTSTL</td>\n",
       "      <td>85255.0</td>\n",
       "      <td>ZAIN MAJEED SCOTTSDALE ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311312</th>\n",
       "      <td>SAMANTHA</td>\n",
       "      <td>BOEVER</td>\n",
       "      <td>GILBERT</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>85295</td>\n",
       "      <td>1396530028</td>\n",
       "      <td>SAMANTHA BOEVER</td>\n",
       "      <td>SMN0</td>\n",
       "      <td>BFR</td>\n",
       "      <td>JLBRT</td>\n",
       "      <td>85295.0</td>\n",
       "      <td>SAMANTHA BOEVER GILBERT ARIZONA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1311313 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Indexing\n",
    "\n",
    "In this step, we will rely on LSH Blocking of the `full_name` field as it has consistently delivered better performance than exact match"
   ],
   "id": "a00919e9ea18da95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:28:51.818321Z",
     "start_time": "2025-05-14T03:00:20.665585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indexer = LSHIndex(column='full_name', threshold=0.6, num_perm=128, tokenizer='bigrams')\n",
    "pairs_lsh_unknowns = indexer.index(dfCTGov, dfNPI)\n",
    "pairs_lsh_unknowns\n",
    "# indexer = recordlinkage.Index()\n",
    "# indexer.block(left_on='surname_ph', right_on='surname_ph')\n",
    "# pairs_lsh_unknowns = indexer.index(dfCTGov, dfNPI)\n",
    "# pairs_lsh_unknowns"
   ],
   "id": "882013987cff31c8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 70040/70040 [01:15<00:00, 928.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfA: 78.60770729999058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1311313/1311313 [24:46<00:00, 882.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfB: 1489.6861969999736\n",
      "Seconds to build LSH of dfB: 131.04019839991815\n",
      "Seconds to query dfB for each row of dfA: 10.861098899971694\n",
      "Seconds to convert df to MultiIndex: 0.3883300001034513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([(    0,  463491),\n",
       "            (    0,  725635),\n",
       "            (    0,  787843),\n",
       "            (    0, 1218822),\n",
       "            (    0,  216967),\n",
       "            (    0, 1247109),\n",
       "            (    0,  993161),\n",
       "            (    0, 1176332),\n",
       "            (    0, 1075469),\n",
       "            (    0,   70417),\n",
       "            ...\n",
       "            (70037, 1018314),\n",
       "            (70037,  166445),\n",
       "            (70037,  811757),\n",
       "            (70037,  233487),\n",
       "            (70037,   29456),\n",
       "            (70037,  670515),\n",
       "            (70037,  428181),\n",
       "            (70037,  920309),\n",
       "            (70037,   91262),\n",
       "            (70037,  531870)],\n",
       "           length=5120298)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:28:51.995173Z",
     "start_time": "2025-05-14T03:28:51.987834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pairs_lsh_unknowns.rename(['dfA_rec_id', 'dfB_rec_id'], inplace=True)\n",
    "pairs_lsh_unknowns"
   ],
   "id": "392ecdea3187f42e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(    0,  463491),\n",
       "            (    0,  725635),\n",
       "            (    0,  787843),\n",
       "            (    0, 1218822),\n",
       "            (    0,  216967),\n",
       "            (    0, 1247109),\n",
       "            (    0,  993161),\n",
       "            (    0, 1176332),\n",
       "            (    0, 1075469),\n",
       "            (    0,   70417),\n",
       "            ...\n",
       "            (70037, 1018314),\n",
       "            (70037,  166445),\n",
       "            (70037,  811757),\n",
       "            (70037,  233487),\n",
       "            (70037,   29456),\n",
       "            (70037,  670515),\n",
       "            (70037,  428181),\n",
       "            (70037,  920309),\n",
       "            (70037,   91262),\n",
       "            (70037,  531870)],\n",
       "           names=['dfA_rec_id', 'dfB_rec_id'], length=5120298)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The generation of the above MultiIndex takes about 25m on the reference system described in Appendix 1, so we'll persist it to disk so that we have the option of skipping this step if we choose to on subsequent runs.",
   "id": "ec14e82173072c90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:29:25.298039Z",
     "start_time": "2025-05-14T03:28:52.044180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_multiindex = pairs_lsh_unknowns.to_frame()\n",
    "df_multiindex.to_csv('data/pairs_lsh_unknowns.zip')\n",
    "# df_multiindex = pd.read_csv('data/pairs_lsh_unknowns.zip')\n",
    "# pairs_lsh_unknowns = pd.MultiIndex.from_frame(df_multiindex)"
   ],
   "id": "9fe491d82ba4e91f",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparison\n",
    "\n",
    "Here, we will use the same comparison algorithms but will need to eliminate a few columns that we do not have data for."
   ],
   "id": "e2144e1337943c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:29:36.065505Z",
     "start_time": "2025-05-14T03:29:25.337062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comp_ctgov_npi = recordlinkage.Compare()\n",
    "comp_ctgov_npi.exact(left_on=\"given_name_ph\", right_on=\"given_name_ph\", label=\"given_name_ph\")\n",
    "comp_ctgov_npi.exact(left_on=\"surname_ph\", right_on=\"surname_ph\", label=\"surname_ph\")\n",
    "#comp_ctgov_npi.string(left_on=\"given_name\", right_on=\"given_name\", method='jarowinkler', label='given_name')\n",
    "comp_ctgov_npi.string(left_on=\"surname\", right_on=\"state\", method='jarowinkler', label='surname')\n",
    "comp_ctgov_npi.exact(left_on=\"city_ph\", right_on=\"city_ph\", label='city_ph')\n",
    "#comp_ctgov_npi.string(left_on=\"city\", right_on=\"city\", label='city')\n",
    "comp_ctgov_npi.numeric (left_on=\"postcode_int\", right_on=\"postcode_int\", method='exp', label='postcode')\n",
    "comp_ctgov_npi.exact(left_on=\"state\", right_on=\"state\", label='state')\n",
    "f_unknown = comp_ctgov_npi.compute(pairs=pairs_lsh_unknowns, x=dfCTGov, x_link=dfNPI)\n",
    "f_unknown"
   ],
   "id": "e782a69b3ab91da6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       given_name_ph  surname_ph   surname  city_ph  postcode  \\\n",
       "dfA_rec_id dfB_rec_id                                                           \n",
       "0          463491                  1           0  0.000000        0       0.0   \n",
       "           725635                  1           0  0.000000        0       0.0   \n",
       "           787843                  0           1  0.000000        0       0.0   \n",
       "           1218822                 0           1  0.000000        0       0.0   \n",
       "           216967                  0           1  0.000000        0       0.0   \n",
       "...                              ...         ...       ...      ...       ...   \n",
       "70037      670515                  0           0  0.472222        0       0.0   \n",
       "           428181                  0           0  0.310606        0       0.0   \n",
       "           920309                  0           0  0.345238        0       0.0   \n",
       "           91262                   0           0  0.500000        0       0.0   \n",
       "           531870                  0           0  0.483333        0       0.0   \n",
       "\n",
       "                       state  \n",
       "dfA_rec_id dfB_rec_id         \n",
       "0          463491          0  \n",
       "           725635          0  \n",
       "           787843          0  \n",
       "           1218822         0  \n",
       "           216967          0  \n",
       "...                      ...  \n",
       "70037      670515          0  \n",
       "           428181          0  \n",
       "           920309          0  \n",
       "           91262           0  \n",
       "           531870          0  \n",
       "\n",
       "[5120298 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>surname</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfA_rec_id</th>\n",
       "      <th>dfB_rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>463491</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725635</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787843</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218822</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216967</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">70037</th>\n",
       "      <th>670515</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428181</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310606</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120298 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will be using the FEBRL data generated at the beginning of this workbook as our training data. We will slightly alter `dfA` and `dfB` to align column names to our unknowns data and reprocess comparisons.",
   "id": "4de5b91ca0751533"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:29:36.265875Z",
     "start_time": "2025-05-14T03:29:36.149093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfA_train = dfA.rename(columns={'suburb':'city', 'suburb_ph':'city_ph'})\n",
    "dfB_train = dfB.rename(columns={'suburb':'city', 'suburb_ph':'city_ph'})\n",
    "f_train = comp_ctgov_npi.compute(pairs=pairs_lsh, x=dfA_train, x_link=dfB_train)\n",
    "f_train"
   ],
   "id": "663b8ac396b2dd92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             given_name_ph  surname_ph   surname  city_ph  \\\n",
       "rec_id_1     rec_id_2                                                       \n",
       "rec-1070-org rec-2754-dup-0              0           0  0.671429        0   \n",
       "             rec-2797-dup-0              0           0  0.671429        0   \n",
       "rec-1016-org rec-1948-dup-0              0           1  0.601190        0   \n",
       "             rec-865-dup-0               0           0  0.328571        0   \n",
       "             rec-3267-dup-0              0           1  0.431746        0   \n",
       "...                                    ...         ...       ...      ...   \n",
       "rec-1003-org rec-4433-dup-0              0           1  0.416667        0   \n",
       "rec-4883-org rec-1194-dup-0              0           0  0.566667        0   \n",
       "             rec-4883-dup-0              1           1  0.566667        0   \n",
       "             rec-1099-dup-0              0           0  0.377778        0   \n",
       "rec-66-org   rec-66-dup-0                1           0  0.403704        0   \n",
       "\n",
       "                                  postcode  state  \n",
       "rec_id_1     rec_id_2                              \n",
       "rec-1070-org rec-2754-dup-0   1.274474e-57      0  \n",
       "             rec-2797-dup-0   0.000000e+00      0  \n",
       "rec-1016-org rec-1948-dup-0   0.000000e+00      1  \n",
       "             rec-865-dup-0    6.681912e-52      0  \n",
       "             rec-3267-dup-0   0.000000e+00      0  \n",
       "...                                    ...    ...  \n",
       "rec-1003-org rec-4433-dup-0   0.000000e+00      0  \n",
       "rec-4883-org rec-1194-dup-0   0.000000e+00      1  \n",
       "             rec-4883-dup-0   1.000000e+00      1  \n",
       "             rec-1099-dup-0  5.180654e-318      0  \n",
       "rec-66-org   rec-66-dup-0     1.000000e+00      1  \n",
       "\n",
       "[38048 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>surname</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rec-1070-org</th>\n",
       "      <th>rec-2754-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>1.274474e-57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2797-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rec-1016-org</th>\n",
       "      <th>rec-1948-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-865-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0</td>\n",
       "      <td>6.681912e-52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3267-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.431746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1003-org</th>\n",
       "      <th>rec-4433-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rec-4883-org</th>\n",
       "      <th>rec-1194-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4883-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1099-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>5.180654e-318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-66-org</th>\n",
       "      <th>rec-66-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38048 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparison\n",
    "\n",
    "For our real-world test, we will compare one unsupervised (ECM) and one supeverised (Naive Bayesian Clssifier) learning algorithm with the goal being to match as many of the physicians listed in dfCTGov to physicians in dfNPI.\n",
    "\n",
    "#### Unsupervised Learning\n",
    "\n",
    "Since it is not necessary to train ECM, we will simply execute the `fit_predict` method and look at the resulting list of matches."
   ],
   "id": "e0e76ee7ea30b60b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:29:59.339560Z",
     "start_time": "2025-05-14T03:29:36.315441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ECM using LSH blocking\n",
    "rw_ecm = recordlinkage.ECMClassifier(binarize=0.97)\n",
    "rw_result_ecm = rw_ecm.fit_predict(f_unknown)\n",
    "rw_result_ecm\n"
   ],
   "id": "e313e890f52795ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(    0,  991469),\n",
       "            (    2, 1301380),\n",
       "            (    2,  916911),\n",
       "            (   22,  495348),\n",
       "            (   30,  130060),\n",
       "            (   33,   72524),\n",
       "            (   65, 1182005),\n",
       "            (   65, 1165845),\n",
       "            (   65, 1130272),\n",
       "            (   65,  968593),\n",
       "            ...\n",
       "            (69902,  750146),\n",
       "            (69902,  103787),\n",
       "            (69902,  710198),\n",
       "            (69902,  735543),\n",
       "            (69920,  743792),\n",
       "            (69922,  430961),\n",
       "            (69954,  279034),\n",
       "            (69960, 1079459),\n",
       "            (69982,  185368),\n",
       "            (69983,  185368)],\n",
       "           names=['dfA_rec_id', 'dfB_rec_id'], length=26063)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:29:59.671141Z",
     "start_time": "2025-05-14T03:29:59.386646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfMatches = rw_result_ecm.to_frame(index=False)\n",
    "dfCTGov.index.name = 'rec_id'\n",
    "dfNPI.index.name = 'rec_id'\n",
    "dfMergeLeft = dfMatches.merge(dfCTGov, left_on='dfA_rec_id', right_on='rec_id', how='inner')\n",
    "dfMergeRight = dfMatches.merge(dfNPI, left_on='dfB_rec_id', right_on='rec_id', how='inner')\n",
    "dfFinal = dfMergeLeft.merge(dfMergeRight, on=['dfA_rec_id','dfB_rec_id'], how='inner')\n",
    "dfFinal.set_index(['dfA_rec_id','dfB_rec_id'], inplace=True)\n",
    "dfFinal = dfFinal[['npi', 'nct_id', 'given_name_x','surname_x', 'city_x', 'state_x', 'postcode_x', 'given_name_y','surname_y', 'city_y', 'state_y', 'postcode_y']]\n",
    "dfFinal"
   ],
   "id": "36ddcce4f200c064",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              npi                   nct_id given_name_x  \\\n",
       "dfA_rec_id dfB_rec_id                                                     \n",
       "0          991469      1356732119              NCT05238116                \n",
       "2          1301380     1194527812  NCT05268289 NCT05755386                \n",
       "           916911      1477817542  NCT05268289 NCT05755386                \n",
       "22         495348      1437244522              NCT04683653                \n",
       "30         130060      1730167263              NCT06249555                \n",
       "...                           ...                      ...          ...   \n",
       "69922      430961      1437264744              NCT04073563        ZOHER   \n",
       "69954      279034      1568409662              NCT02012699      ZUBEENA   \n",
       "69960      1079459     1225559149  NCT05886036 NCT06311227        ZULFA   \n",
       "69982      185368      1528036779  NCT06331299 NCT04452591          ZVI   \n",
       "69983      185368      1528036779              NCT06111235          ZVI   \n",
       "\n",
       "                            surname_x       city_x        state_x postcode_x  \\\n",
       "dfA_rec_id dfB_rec_id                                                          \n",
       "0          991469                          HOUSTON          TEXAS      77030   \n",
       "2          1301380          ABDELNOUR  LOS ANGELES     CALIFORNIA      90095   \n",
       "           916911           ABDELNOUR  LOS ANGELES     CALIFORNIA      90095   \n",
       "22         495348      ANUJA JHINGRAN      HOUSTON          TEXAS      77030   \n",
       "30         130060         ATIQUZZAMAN    KISSIMMEE        FLORIDA      34741   \n",
       "...                               ...          ...            ...        ...   \n",
       "69922      430961           GHOGAWALA   BURLINGTON  MASSACHUSETTS      01805   \n",
       "69954      279034              MATEEN      HOLYOKE  MASSACHUSETTS      01040   \n",
       "69960      1079459               OMER   CINCINNATI           OHIO      45219   \n",
       "69982      185368           SCHIFFMAN      HOUSTON          TEXAS      77027   \n",
       "69983      185368           SCHIFFMAN      HOUSTON          TEXAS      77074   \n",
       "\n",
       "                      given_name_y    surname_y       city_y        state_y  \\\n",
       "dfA_rec_id dfB_rec_id                                                         \n",
       "0          991469                           LIU      HOUSTON          TEXAS   \n",
       "2          1301380            MARK    ABDELNOUR  LOS ANGELES     CALIFORNIA   \n",
       "           916911             LAMA    ABDELNOUR  LOS ANGELES     CALIFORNIA   \n",
       "22         495348            ANUJA     JHINGRAN      HOUSTON          TEXAS   \n",
       "30         130060          TAHSINA  ATIQUZZAMAN    KISSIMMEE        FLORIDA   \n",
       "...                            ...          ...          ...            ...   \n",
       "69922      430961            ZOHER    GHOGAWALA   BURLINGTON  MASSACHUSETTS   \n",
       "69954      279034          ZUBEENA       MATEEN      HOLYOKE  MASSACHUSETTS   \n",
       "69960      1079459           ZULFA         OMER   CINCINNATI           OHIO   \n",
       "69982      185368              ZVI    SCHIFFMAN      HOUSTON          TEXAS   \n",
       "69983      185368              ZVI    SCHIFFMAN      HOUSTON          TEXAS   \n",
       "\n",
       "                      postcode_y  \n",
       "dfA_rec_id dfB_rec_id             \n",
       "0          991469          77036  \n",
       "2          1301380         90036  \n",
       "           916911          90045  \n",
       "22         495348          77210  \n",
       "30         130060          34741  \n",
       "...                          ...  \n",
       "69922      430961          18050  \n",
       "69954      279034          10402  \n",
       "69960      1079459         45263  \n",
       "69982      185368          77251  \n",
       "69983      185368          77251  \n",
       "\n",
       "[26063 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>given_name_x</th>\n",
       "      <th>surname_x</th>\n",
       "      <th>city_x</th>\n",
       "      <th>state_x</th>\n",
       "      <th>postcode_x</th>\n",
       "      <th>given_name_y</th>\n",
       "      <th>surname_y</th>\n",
       "      <th>city_y</th>\n",
       "      <th>state_y</th>\n",
       "      <th>postcode_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfA_rec_id</th>\n",
       "      <th>dfB_rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>991469</th>\n",
       "      <td>1356732119</td>\n",
       "      <td>NCT05238116</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td></td>\n",
       "      <td>LIU</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1301380</th>\n",
       "      <td>1194527812</td>\n",
       "      <td>NCT05268289 NCT05755386</td>\n",
       "      <td></td>\n",
       "      <td>ABDELNOUR</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>90095</td>\n",
       "      <td>MARK</td>\n",
       "      <td>ABDELNOUR</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>90036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916911</th>\n",
       "      <td>1477817542</td>\n",
       "      <td>NCT05268289 NCT05755386</td>\n",
       "      <td></td>\n",
       "      <td>ABDELNOUR</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>90095</td>\n",
       "      <td>LAMA</td>\n",
       "      <td>ABDELNOUR</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>90045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>495348</th>\n",
       "      <td>1437244522</td>\n",
       "      <td>NCT04683653</td>\n",
       "      <td></td>\n",
       "      <td>ANUJA JHINGRAN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td>ANUJA</td>\n",
       "      <td>JHINGRAN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>130060</th>\n",
       "      <td>1730167263</td>\n",
       "      <td>NCT06249555</td>\n",
       "      <td></td>\n",
       "      <td>ATIQUZZAMAN</td>\n",
       "      <td>KISSIMMEE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>34741</td>\n",
       "      <td>TAHSINA</td>\n",
       "      <td>ATIQUZZAMAN</td>\n",
       "      <td>KISSIMMEE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>34741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69922</th>\n",
       "      <th>430961</th>\n",
       "      <td>1437264744</td>\n",
       "      <td>NCT04073563</td>\n",
       "      <td>ZOHER</td>\n",
       "      <td>GHOGAWALA</td>\n",
       "      <td>BURLINGTON</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>01805</td>\n",
       "      <td>ZOHER</td>\n",
       "      <td>GHOGAWALA</td>\n",
       "      <td>BURLINGTON</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>18050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69954</th>\n",
       "      <th>279034</th>\n",
       "      <td>1568409662</td>\n",
       "      <td>NCT02012699</td>\n",
       "      <td>ZUBEENA</td>\n",
       "      <td>MATEEN</td>\n",
       "      <td>HOLYOKE</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>01040</td>\n",
       "      <td>ZUBEENA</td>\n",
       "      <td>MATEEN</td>\n",
       "      <td>HOLYOKE</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>10402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69960</th>\n",
       "      <th>1079459</th>\n",
       "      <td>1225559149</td>\n",
       "      <td>NCT05886036 NCT06311227</td>\n",
       "      <td>ZULFA</td>\n",
       "      <td>OMER</td>\n",
       "      <td>CINCINNATI</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>45219</td>\n",
       "      <td>ZULFA</td>\n",
       "      <td>OMER</td>\n",
       "      <td>CINCINNATI</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>45263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69982</th>\n",
       "      <th>185368</th>\n",
       "      <td>1528036779</td>\n",
       "      <td>NCT06331299 NCT04452591</td>\n",
       "      <td>ZVI</td>\n",
       "      <td>SCHIFFMAN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77027</td>\n",
       "      <td>ZVI</td>\n",
       "      <td>SCHIFFMAN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69983</th>\n",
       "      <th>185368</th>\n",
       "      <td>1528036779</td>\n",
       "      <td>NCT06111235</td>\n",
       "      <td>ZVI</td>\n",
       "      <td>SCHIFFMAN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77074</td>\n",
       "      <td>ZVI</td>\n",
       "      <td>SCHIFFMAN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26063 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Supervised Learning\n",
    "\n",
    "Here we will train a Naive Bayesian Classifier using all 10k rows provided by the FEBRL dataset. Once the model is trained we will apply to our unknowns and again review results.\n"
   ],
   "id": "e341f73c1d9ed38c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:29:59.799114Z",
     "start_time": "2025-05-14T03:29:59.713183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#classify using Naive Bayes Classifier\n",
    "nbc_train = recordlinkage.NaiveBayesClassifier(binarize=0.97)\n",
    "nbc_train.fit(f_train, miTrueLinks)\n",
    "nbc_train_result = nbc_train.predict(f_train)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=nbc_train_result, total=len(dfA.index))"
   ],
   "id": "c284f47d509a80b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3510, 1490],\n",
       "       [  34,  -34]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:30:00.046888Z",
     "start_time": "2025-05-14T03:30:00.032927Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=nbc_train_result)",
   "id": "b1a8103c7767b7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.821629213483146"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T03:30:03.432726Z",
     "start_time": "2025-05-14T03:30:00.212026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rw_result_nbc = nbc_train.predict(f_unknown)\n",
    "dfMatches = rw_result_nbc.to_frame(index=False)\n",
    "dfMergeLeft = dfMatches.merge(dfCTGov, left_on='dfA_rec_id', right_on='rec_id', how='inner')\n",
    "dfMergeRight = dfMatches.merge(dfNPI, left_on='dfB_rec_id', right_on='rec_id', how='inner')\n",
    "dfFinal = dfMergeLeft.merge(dfMergeRight, on=['dfA_rec_id','dfB_rec_id'], how='inner')\n",
    "dfFinal.set_index(['dfA_rec_id','dfB_rec_id'], inplace=True)\n",
    "dfFinal = dfFinal[['npi', 'nct_id', 'given_name_x','surname_x', 'city_x', 'state_x', 'postcode_x', 'given_name_y','surname_y', 'city_y', 'state_y', 'postcode_y']]\n",
    "dfFinal"
   ],
   "id": "727196d28135a723",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              npi                               nct_id  \\\n",
       "dfA_rec_id dfB_rec_id                                                    \n",
       "30         130060      1730167263                          NCT06249555   \n",
       "253        611275      1609910900                          NCT01955148   \n",
       "307        846282      1073826467                          NCT06065449   \n",
       "           936100      1154764702                          NCT06065449   \n",
       "           501153      1700974508                          NCT06065449   \n",
       "...                           ...                                  ...   \n",
       "69262      1071612     1326575499                          NCT06921707   \n",
       "69326      1031092     1730543497                          NCT02418442   \n",
       "69333      891461      1225300379                          NCT06404086   \n",
       "69804      885130      1932488368              NCT01629498 NCT05010109   \n",
       "69849      972154      1619387867  NCT04071457 NCT04759586 NCT04340141   \n",
       "\n",
       "                      given_name_x       surname_x        city_x  \\\n",
       "dfA_rec_id dfB_rec_id                                              \n",
       "30         130060                      ATIQUZZAMAN     KISSIMMEE   \n",
       "253        611275                   MICHAEL S RUMA   ALBUQUERQUE   \n",
       "307        846282                     QUYNH NGUYEN       HOUSTON   \n",
       "           936100                     QUYNH NGUYEN       HOUSTON   \n",
       "           501153                     QUYNH NGUYEN       HOUSTON   \n",
       "...                            ...             ...           ...   \n",
       "69262      1071612         ZACHARY          ROWARD       HOUSTON   \n",
       "69326      1031092           ZANAB            MIAN  LAKE SUCCESS   \n",
       "69333      891461             ZARA     MARTIROSYAN    WASHINGTON   \n",
       "69804      885130        ZHONGXING            LIAO       HOUSTON   \n",
       "69849      972154          ZHUOYAN              LI     BALTIMORE   \n",
       "\n",
       "                                    state_x postcode_x given_name_y  \\\n",
       "dfA_rec_id dfB_rec_id                                                 \n",
       "30         130060                   FLORIDA      34741      TAHSINA   \n",
       "253        611275                NEW MEXICO      87106      MICHAEL   \n",
       "307        846282                     TEXAS      77030          ANH   \n",
       "           936100                     TEXAS      77030        QUYEN   \n",
       "           501153                     TEXAS      77030        PETER   \n",
       "...                                     ...        ...          ...   \n",
       "69262      1071612                    TEXAS      78234      ZACHARY   \n",
       "69326      1031092                 NEW YORK      11042        ZANAB   \n",
       "69333      891461      DISTRICT OF COLUMBIA      20060         ZARA   \n",
       "69804      885130                     TEXAS      77030         BING   \n",
       "69849      972154                  MARYLAND      21204      ZHUOYAN   \n",
       "\n",
       "                         surname_y               city_y     state_y postcode_y  \n",
       "dfA_rec_id dfB_rec_id                                                           \n",
       "30         130060      ATIQUZZAMAN            KISSIMMEE     FLORIDA      34741  \n",
       "253        611275             RUMA          ALBUQUERQUE  NEW MEXICO      87106  \n",
       "307        846282           NGUYEN              HOUSTON       TEXAS      77030  \n",
       "           936100            HUYNH              HOUSTON       TEXAS      77030  \n",
       "           501153           NGUYEN              HOUSTON       TEXAS      77030  \n",
       "...                            ...                  ...         ...        ...  \n",
       "69262      1071612          ROWARD  JBSA FT SAM HOUSTON       TEXAS      78234  \n",
       "69326      1031092            MIAN        NEW HYDE PARK    NEW YORK      11042  \n",
       "69333      891461      MARTIROSYAN           WASHINGTON          DC      20060  \n",
       "69804      885130             LIAO              HOUSTON       TEXAS      77030  \n",
       "69849      972154               LI               TOWSON    MARYLAND      21204  \n",
       "\n",
       "[3421 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>given_name_x</th>\n",
       "      <th>surname_x</th>\n",
       "      <th>city_x</th>\n",
       "      <th>state_x</th>\n",
       "      <th>postcode_x</th>\n",
       "      <th>given_name_y</th>\n",
       "      <th>surname_y</th>\n",
       "      <th>city_y</th>\n",
       "      <th>state_y</th>\n",
       "      <th>postcode_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfA_rec_id</th>\n",
       "      <th>dfB_rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>130060</th>\n",
       "      <td>1730167263</td>\n",
       "      <td>NCT06249555</td>\n",
       "      <td></td>\n",
       "      <td>ATIQUZZAMAN</td>\n",
       "      <td>KISSIMMEE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>34741</td>\n",
       "      <td>TAHSINA</td>\n",
       "      <td>ATIQUZZAMAN</td>\n",
       "      <td>KISSIMMEE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>34741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <th>611275</th>\n",
       "      <td>1609910900</td>\n",
       "      <td>NCT01955148</td>\n",
       "      <td></td>\n",
       "      <td>MICHAEL S RUMA</td>\n",
       "      <td>ALBUQUERQUE</td>\n",
       "      <td>NEW MEXICO</td>\n",
       "      <td>87106</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>RUMA</td>\n",
       "      <td>ALBUQUERQUE</td>\n",
       "      <td>NEW MEXICO</td>\n",
       "      <td>87106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">307</th>\n",
       "      <th>846282</th>\n",
       "      <td>1073826467</td>\n",
       "      <td>NCT06065449</td>\n",
       "      <td></td>\n",
       "      <td>QUYNH NGUYEN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td>ANH</td>\n",
       "      <td>NGUYEN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936100</th>\n",
       "      <td>1154764702</td>\n",
       "      <td>NCT06065449</td>\n",
       "      <td></td>\n",
       "      <td>QUYNH NGUYEN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td>QUYEN</td>\n",
       "      <td>HUYNH</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501153</th>\n",
       "      <td>1700974508</td>\n",
       "      <td>NCT06065449</td>\n",
       "      <td></td>\n",
       "      <td>QUYNH NGUYEN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td>PETER</td>\n",
       "      <td>NGUYEN</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69262</th>\n",
       "      <th>1071612</th>\n",
       "      <td>1326575499</td>\n",
       "      <td>NCT06921707</td>\n",
       "      <td>ZACHARY</td>\n",
       "      <td>ROWARD</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>78234</td>\n",
       "      <td>ZACHARY</td>\n",
       "      <td>ROWARD</td>\n",
       "      <td>JBSA FT SAM HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>78234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69326</th>\n",
       "      <th>1031092</th>\n",
       "      <td>1730543497</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>ZANAB</td>\n",
       "      <td>MIAN</td>\n",
       "      <td>LAKE SUCCESS</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>11042</td>\n",
       "      <td>ZANAB</td>\n",
       "      <td>MIAN</td>\n",
       "      <td>NEW HYDE PARK</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>11042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69333</th>\n",
       "      <th>891461</th>\n",
       "      <td>1225300379</td>\n",
       "      <td>NCT06404086</td>\n",
       "      <td>ZARA</td>\n",
       "      <td>MARTIROSYAN</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>DISTRICT OF COLUMBIA</td>\n",
       "      <td>20060</td>\n",
       "      <td>ZARA</td>\n",
       "      <td>MARTIROSYAN</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>DC</td>\n",
       "      <td>20060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69804</th>\n",
       "      <th>885130</th>\n",
       "      <td>1932488368</td>\n",
       "      <td>NCT01629498 NCT05010109</td>\n",
       "      <td>ZHONGXING</td>\n",
       "      <td>LIAO</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "      <td>BING</td>\n",
       "      <td>LIAO</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69849</th>\n",
       "      <th>972154</th>\n",
       "      <td>1619387867</td>\n",
       "      <td>NCT04071457 NCT04759586 NCT04340141</td>\n",
       "      <td>ZHUOYAN</td>\n",
       "      <td>LI</td>\n",
       "      <td>BALTIMORE</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>21204</td>\n",
       "      <td>ZHUOYAN</td>\n",
       "      <td>LI</td>\n",
       "      <td>TOWSON</td>\n",
       "      <td>MARYLAND</td>\n",
       "      <td>21204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3421 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Discussion\n",
    "\n",
    "The results we were able to achieve were promising but still in need of significant additional work. The output of both the ECM and Naive Bayes Classifier (NBC) did yield a significant number of matches, but it was clear that some of the matches identified would be ruled out by a human human reviewer. The most obvious examples of this are the cases where the first name, city and state all matched but the last names did not. Here, both classifiers did not weight the last name score higher than the other values and thus identified a number of matches that clearly are not the same person. As humans, we subconsciously weight last names as a better indicator of matching than other values. Underlying the issue is that both ECM and NBC make the Conditional Independence assumption, which in this case is not accurate.\n",
    "\n",
    "In examples that were presented with the framework, initial index blocking was done using exact matching of the metaphone of last name. This technique effectively hides/compensates for the weighting of last name at the expense of eliminating possible matches that included a misspelling of the last name that impacted the metaphone. We tried to improve on this by using LSH hashing / Jaccard Similarity of last names to allow for a slightly broader blocking window. In an effort to add weight to last name, we also added a comparison of last name metaphones in addition to string comparison.\n",
    "\n",
    "More recent work has focused on using LLMs for blocking and neural networks for classification to better compensate for the different weighting of values. Our future work on Record Linkage this will build out a codebase based on LLM and NN.\n",
    "\n",
    "Finally, it is suspected that better performance from NBS could be achieved if training data was developed from the two real-world datasets. The FEBRL dataset, while convenient, likely does not represent real-world matching problems. A manual matching effort that links a subset of these two datasets would likely have led to better outcomes as well."
   ],
   "id": "64206b6da320814e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "Christen, P. (2019). Data linkage: the big picture. Harvard Data Science Review, 1(2). https://doi.org/10.1162/99608f92.84deb5c4\n",
    "\n",
    "Christen, P (2012). *Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection*. Springer. DOI 10.1007/978-3-642-31164-2.\n",
    "\n",
    "Fellegi, I. P., & Sunter, A. B. (1969). A Theory for Record Linkage. Journal of the American Statistical Association, 64(328), 1183. https://doi.org/10.2307/2286061\n",
    "\n",
    "Winkler, W. (2002). Methods for Record Linkage and Bayesian Networks Methods for Record Linkage and Bayesian Networks. Retrieved May 5, 2025, from https://www.census.gov/content/dam/Census/library/working-papers/2002/adrm/rrs2002-05.pdf\n",
    "\n",
    "De Bruin, J. [J535D165]. (2023, July 20). Python Record Linkage Toolkit Documentation — Python Record Linkage Toolkit 0.15 documentation. Retrieved April 17, 2025, from https://recordlinkage.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Dutt, V. (2023, August 1). Understanding Locality-Sensitive hashing for entity matching. Medium. https://medium.com/@mailvdutt/understanding-locality-sensitive-hashing-for-entity-matching-ebed7998c64b\n",
    "\n",
    "Zhu, E. (Erik) \\[ekzhu\\]. (2024, June 3). datasketch: Big Data Looks Small — datasketch 1.6.5 documentation. Retrieved May 6, 2025, from https://ekzhu.com/datasketch/index.html\n",
    "\n",
    "Turk, J. (2023, November 17). Jellyfish. Retrieved May 6, 2025, from https://jamesturk.github.io/jellyfish/\n",
    "\n",
    "The closer, the better | ElasticSearch: The Definitive Guide [2.x] | Elastic. (n.d.). Elastic. Retrieved May 6, 2025, from https://www.elastic.co/guide/en/elasticsearch/guide/current/decay-functions.html#img-decay-functions\n",
    "\n",
    "AACT Database | Clinical Trials Transformation Initiative. (2025, April 30). Retrieved May 2, 2025, from https://aact.ctti-clinicaltrials.org/download\n",
    "\n",
    "NPI files. (2025, April 15). https://download.cms.gov/nppes/NPI_Files.html\n",
    "\n",
    "Boyanov, M. [mboyanov]. (2020, January 29). Google Colab. Retrieved May 7, 2025, from https://colab.research.google.com/github/mboyanov/minhash-demo/blob/master/Datasketch%20Demo.ipynb#scrollTo=wzZfQeLMeP3N"
   ],
   "id": "7442bf75306b9eb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Appendix 1: Computing Environment\n",
    "\n",
    "This is the computing environment used for metrics benchmarks reported in this workbook.\n",
    "\n",
    "![Computing Environment](images/ReferenceArchitecture.png)\n",
    "\n"
   ],
   "id": "9fc8f4d0350cc98d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
