{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# <center>Record Linkage</center>\n",
    "## <center>Vince Marinelli<br>CPSC548 Spring 2025</center>\n",
    "\n",
    "Record Linkage refers to the task of linking records using a matching set of attributes shared by the two records. For example, we often need to match a list customers with a list of payees, or a list of patients with a list of users of a specific medication, etc. Another common example is the identification and removal of duplicate entries within a dataset. Record Linkage has also been referred to as data linkage, entity resolution, and data matching (<ins>Christen. 2019</ins>).\n",
    "\n",
    "In the simplest case, we have a shared attribute that represents a unique identifier for the record (e.g. SSN, TIN, ISBN, etc). In this case we may assume that this identifier absolutely and completely identities the unique entity. Unfortunately, outside of the world of controlled schemas this is rarely true. More often, we need to use the full set of attributes that can be mapped between the two rows to develop a level of confidence that the two rows are the same. The attributes used to match are referred to as Quasi-Identifiers (QIDs). Each QID contributes a specific weight to the overall match probability that is proportional to the amount of information that the QID contributes. For example, a matching street address contributes a larger weight than a matching marital status because the street address has a higher cardinality / lower match probability then marital status.\n",
    "\n",
    "The seminal work on record matching, **A Theory for Record Linkage**. was published in 1969 by Fellegi and Sunter. In the paper, the authors lay out a statistical theoretical basis for optimal record matching. It was later shown that this statistical basis is effectively the same as a Naive Baisian Classifer with the conditional independence assumption relaxed (<ins>Winkler, 2012</ins>). These statistical models remain mainstream today but are being challenged by newer models that use other types of classifiers.\n",
    "\n",
    "In his 2012 book **Data Matching**, Peter Christen lays out the basic process that has historically been followed. The process contains the following steps (<ins>Christen, 2012, pp. 24-35</ins>):\n",
    "\n",
    "1. Preprocessing - scrub and format record sets to be compared\n",
    "2. Indexing - match each record from one data to records in the comparison data set\n",
    "3. Comparison - compute similarity between a record and all possible comparators\n",
    "4. Classification - classify records as matches or non-matches (or possible matches in some cases)\n",
    "5. Evaluation - review the performance of the classification\n",
    "\n",
    "Before delving into these steps in more detail, we will first review the Python library we will be using both for test data and for the execution of many of the above steps."
   ],
   "id": "301ce835310565cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Using the Python Record Linkage Toolkit (PRLT)\n",
    "The [Python Record Linkage Toolkit](https://recordlinkage.readthedocs.io/en/latest/index.html) is a PyPi-hosted library that implements a standard set of record linkage activities. It includes tools for preprocessing data, indexing, comparison, classification and evaluation. The toolkit also contains several datasets that can be used to train and test algorithms.\n",
    "\n",
    "First, we'll import all the modules that we'll be using in this workbook, including PRLT.\n",
    "\n",
    "> NOTE: Some modules used in this project are not compatible with Python versions 3.12 and higher. It's required that we use a Python 3.11 Virtual Enviroment for this project."
   ],
   "id": "78c1b677b3530447"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:52.476227Z",
     "start_time": "2025-05-13T04:07:50.760538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import re\n",
    "import recordlinkage\n",
    "import time\n",
    "import us\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from datasketch import MinHash, LeanMinHash, MinHashLSH\n",
    "from nameparser import HumanName\n",
    "from nameparser.config import Constants\n",
    "from recordlinkage.datasets import load_febrl4\n",
    "from recordlinkage.base import BaseIndexAlgorithm\n",
    "from recordlinkage.preprocessing import phonetic"
   ],
   "id": "9a6d0e5cd8defe6e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that the modules have been imported, we will load data from the Freely Extensible Biomedical Record Linkage (febrl) package which is included in PRLT. Calling the `load_febrl4` method returns two datasets - one which contains all original records and a second that contains copies of the records from the first dataset, with duplicates included. A third output, a Pandas MultiIndex, can optionally be returned that contains the actual map from rows in the first dataframe to rows in the second (<ins>de Bruin, 2023</ins>). We'll retrieve all three objects and display them.",
   "id": "a7c4c485b02c032b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:52.530736Z",
     "start_time": "2025-05-13T04:07:52.483736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfA, dfB, miTrueLinks = load_febrl4(return_links=True)\n",
    "dfA"
   ],
   "id": "16efdac8b049f85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             given_name    surname street_number            address_1  \\\n",
       "rec_id                                                                  \n",
       "rec-1070-org   michaela    neumann             8       stanley street   \n",
       "rec-1016-org   courtney    painter            12    pinkerton circuit   \n",
       "rec-4405-org    charles      green            38  salkauskas crescent   \n",
       "rec-1288-org    vanessa       parr           905       macquoid place   \n",
       "rec-3585-org    mikayla   malloney            37        randwick road   \n",
       "...                 ...        ...           ...                  ...   \n",
       "rec-2153-org    annabel   grierson            97   mclachlan crescent   \n",
       "rec-1604-org     sienna   musolino            22      smeaton circuit   \n",
       "rec-1003-org    bradley   matthews             2         jondol place   \n",
       "rec-4883-org     brodee       egan            88          axon street   \n",
       "rec-66-org        koula  houweling             3       mileham street   \n",
       "\n",
       "                        address_2            suburb postcode state  \\\n",
       "rec_id                                                               \n",
       "rec-1070-org                miami     winston hills     4223   nsw   \n",
       "rec-1016-org           bega flats         richlands     4560   vic   \n",
       "rec-4405-org                 kela             dapto     4566   nsw   \n",
       "rec-1288-org    broadbridge manor     south grafton     2135    sa   \n",
       "rec-3585-org              avalind  hoppers crossing     4552   vic   \n",
       "...                           ...               ...      ...   ...   \n",
       "rec-2153-org        lantana lodge            broome     2480   nsw   \n",
       "rec-1604-org              pangani          mckinnon     2700   nsw   \n",
       "rec-1003-org         horseshoe ck       jacobs well     7018    sa   \n",
       "rec-4883-org          greenslopes          wamberal     2067   qld   \n",
       "rec-66-org    old airdmillan road      williamstown     2350   nsw   \n",
       "\n",
       "             date_of_birth soc_sec_id  \n",
       "rec_id                                 \n",
       "rec-1070-org      19151111    5304218  \n",
       "rec-1016-org      19161214    4066625  \n",
       "rec-4405-org      19480930    4365168  \n",
       "rec-1288-org      19951119    9239102  \n",
       "rec-3585-org      19860208    7207688  \n",
       "...                    ...        ...  \n",
       "rec-2153-org      19840224    7676186  \n",
       "rec-1604-org      19890525    4971506  \n",
       "rec-1003-org      19481122    8927667  \n",
       "rec-4883-org      19121113    6039042  \n",
       "rec-66-org        19440718    6375537  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-1070-org</th>\n",
       "      <td>michaela</td>\n",
       "      <td>neumann</td>\n",
       "      <td>8</td>\n",
       "      <td>stanley street</td>\n",
       "      <td>miami</td>\n",
       "      <td>winston hills</td>\n",
       "      <td>4223</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19151111</td>\n",
       "      <td>5304218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1016-org</th>\n",
       "      <td>courtney</td>\n",
       "      <td>painter</td>\n",
       "      <td>12</td>\n",
       "      <td>pinkerton circuit</td>\n",
       "      <td>bega flats</td>\n",
       "      <td>richlands</td>\n",
       "      <td>4560</td>\n",
       "      <td>vic</td>\n",
       "      <td>19161214</td>\n",
       "      <td>4066625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4405-org</th>\n",
       "      <td>charles</td>\n",
       "      <td>green</td>\n",
       "      <td>38</td>\n",
       "      <td>salkauskas crescent</td>\n",
       "      <td>kela</td>\n",
       "      <td>dapto</td>\n",
       "      <td>4566</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19480930</td>\n",
       "      <td>4365168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1288-org</th>\n",
       "      <td>vanessa</td>\n",
       "      <td>parr</td>\n",
       "      <td>905</td>\n",
       "      <td>macquoid place</td>\n",
       "      <td>broadbridge manor</td>\n",
       "      <td>south grafton</td>\n",
       "      <td>2135</td>\n",
       "      <td>sa</td>\n",
       "      <td>19951119</td>\n",
       "      <td>9239102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3585-org</th>\n",
       "      <td>mikayla</td>\n",
       "      <td>malloney</td>\n",
       "      <td>37</td>\n",
       "      <td>randwick road</td>\n",
       "      <td>avalind</td>\n",
       "      <td>hoppers crossing</td>\n",
       "      <td>4552</td>\n",
       "      <td>vic</td>\n",
       "      <td>19860208</td>\n",
       "      <td>7207688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2153-org</th>\n",
       "      <td>annabel</td>\n",
       "      <td>grierson</td>\n",
       "      <td>97</td>\n",
       "      <td>mclachlan crescent</td>\n",
       "      <td>lantana lodge</td>\n",
       "      <td>broome</td>\n",
       "      <td>2480</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19840224</td>\n",
       "      <td>7676186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1604-org</th>\n",
       "      <td>sienna</td>\n",
       "      <td>musolino</td>\n",
       "      <td>22</td>\n",
       "      <td>smeaton circuit</td>\n",
       "      <td>pangani</td>\n",
       "      <td>mckinnon</td>\n",
       "      <td>2700</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19890525</td>\n",
       "      <td>4971506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1003-org</th>\n",
       "      <td>bradley</td>\n",
       "      <td>matthews</td>\n",
       "      <td>2</td>\n",
       "      <td>jondol place</td>\n",
       "      <td>horseshoe ck</td>\n",
       "      <td>jacobs well</td>\n",
       "      <td>7018</td>\n",
       "      <td>sa</td>\n",
       "      <td>19481122</td>\n",
       "      <td>8927667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4883-org</th>\n",
       "      <td>brodee</td>\n",
       "      <td>egan</td>\n",
       "      <td>88</td>\n",
       "      <td>axon street</td>\n",
       "      <td>greenslopes</td>\n",
       "      <td>wamberal</td>\n",
       "      <td>2067</td>\n",
       "      <td>qld</td>\n",
       "      <td>19121113</td>\n",
       "      <td>6039042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-66-org</th>\n",
       "      <td>koula</td>\n",
       "      <td>houweling</td>\n",
       "      <td>3</td>\n",
       "      <td>mileham street</td>\n",
       "      <td>old airdmillan road</td>\n",
       "      <td>williamstown</td>\n",
       "      <td>2350</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19440718</td>\n",
       "      <td>6375537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:52.868554Z",
     "start_time": "2025-05-13T04:07:52.864982Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Length of dataframe dfA: {len(dfA)}')",
   "id": "8e805bf0ce509ea8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe dfA: 5000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:52.923372Z",
     "start_time": "2025-05-13T04:07:52.914133Z"
    }
   },
   "cell_type": "code",
   "source": "dfB",
   "id": "b0e2e1c4de4ee593",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               given_name    surname street_number             address_1  \\\n",
       "rec_id                                                                     \n",
       "rec-561-dup-0       elton        NaN             3         light setreet   \n",
       "rec-2642-dup-0   mitchell      maxon            47         edkins street   \n",
       "rec-608-dup-0         NaN      white            72       lambrigg street   \n",
       "rec-3239-dup-0      elk i    menzies             1          lyster place   \n",
       "rec-2886-dup-0        NaN  garanggar           NaN  may maxwell crescent   \n",
       "...                   ...        ...           ...                   ...   \n",
       "rec-4495-dup-0     connor   belperio            15                   NaN   \n",
       "rec-4211-dup-0     daniel      maspn             9   derrington crescent   \n",
       "rec-3131-dup-0     samuel      crofs           613        banjine street   \n",
       "rec-3815-dup-0       saah    beattih            60           kay's place   \n",
       "rec-493-dup-0         NaN  blackwell           127         ferrier place   \n",
       "\n",
       "                            address_2             suburb postcode state  \\\n",
       "rec_id                                                                    \n",
       "rec-561-dup-0                pinehill         windermere     3212   vic   \n",
       "rec-2642-dup-0              lochaoair         north ryde     3355   nsw   \n",
       "rec-608-dup-0                kelgoola  broadbeach waters     3159   vic   \n",
       "rec-3239-dup-0                    NaN          northwood     2585   vic   \n",
       "rec-2886-dup-0     springettst arcade        forest hill     2342   vic   \n",
       "...                               ...                ...      ...   ...   \n",
       "rec-4495-dup-0                    NaN               ryde     2570   nsw   \n",
       "rec-4211-dup-0  el pedro caravan park          sunnybank     4350   vic   \n",
       "rec-3131-dup-0         kurrajong vlge            pengzin     2230   qld   \n",
       "rec-3815-dup-0        oldershaw court           ashfield     2047   vic   \n",
       "rec-493-dup-0         northwood npark    chelsea heights     4211   qld   \n",
       "\n",
       "               date_of_birth soc_sec_id  \n",
       "rec_id                                   \n",
       "rec-561-dup-0       19651013    1551941  \n",
       "rec-2642-dup-0      19390212    8859999  \n",
       "rec-608-dup-0       19620216    9731855  \n",
       "rec-3239-dup-0      19980624    4970481  \n",
       "rec-2886-dup-0      19921016    1366884  \n",
       "...                      ...        ...  \n",
       "rec-4495-dup-0      19170518    5394641  \n",
       "rec-4211-dup-0      19500705    5525378  \n",
       "rec-3131-dup-0      19410531    4467228  \n",
       "rec-3815-dup-0      19500712    9435148  \n",
       "rec-493-dup-0       19570409    8541055  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-561-dup-0</th>\n",
       "      <td>elton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>light setreet</td>\n",
       "      <td>pinehill</td>\n",
       "      <td>windermere</td>\n",
       "      <td>3212</td>\n",
       "      <td>vic</td>\n",
       "      <td>19651013</td>\n",
       "      <td>1551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2642-dup-0</th>\n",
       "      <td>mitchell</td>\n",
       "      <td>maxon</td>\n",
       "      <td>47</td>\n",
       "      <td>edkins street</td>\n",
       "      <td>lochaoair</td>\n",
       "      <td>north ryde</td>\n",
       "      <td>3355</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19390212</td>\n",
       "      <td>8859999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-608-dup-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>72</td>\n",
       "      <td>lambrigg street</td>\n",
       "      <td>kelgoola</td>\n",
       "      <td>broadbeach waters</td>\n",
       "      <td>3159</td>\n",
       "      <td>vic</td>\n",
       "      <td>19620216</td>\n",
       "      <td>9731855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3239-dup-0</th>\n",
       "      <td>elk i</td>\n",
       "      <td>menzies</td>\n",
       "      <td>1</td>\n",
       "      <td>lyster place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>northwood</td>\n",
       "      <td>2585</td>\n",
       "      <td>vic</td>\n",
       "      <td>19980624</td>\n",
       "      <td>4970481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2886-dup-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>garanggar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>may maxwell crescent</td>\n",
       "      <td>springettst arcade</td>\n",
       "      <td>forest hill</td>\n",
       "      <td>2342</td>\n",
       "      <td>vic</td>\n",
       "      <td>19921016</td>\n",
       "      <td>1366884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4495-dup-0</th>\n",
       "      <td>connor</td>\n",
       "      <td>belperio</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ryde</td>\n",
       "      <td>2570</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19170518</td>\n",
       "      <td>5394641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4211-dup-0</th>\n",
       "      <td>daniel</td>\n",
       "      <td>maspn</td>\n",
       "      <td>9</td>\n",
       "      <td>derrington crescent</td>\n",
       "      <td>el pedro caravan park</td>\n",
       "      <td>sunnybank</td>\n",
       "      <td>4350</td>\n",
       "      <td>vic</td>\n",
       "      <td>19500705</td>\n",
       "      <td>5525378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3131-dup-0</th>\n",
       "      <td>samuel</td>\n",
       "      <td>crofs</td>\n",
       "      <td>613</td>\n",
       "      <td>banjine street</td>\n",
       "      <td>kurrajong vlge</td>\n",
       "      <td>pengzin</td>\n",
       "      <td>2230</td>\n",
       "      <td>qld</td>\n",
       "      <td>19410531</td>\n",
       "      <td>4467228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3815-dup-0</th>\n",
       "      <td>saah</td>\n",
       "      <td>beattih</td>\n",
       "      <td>60</td>\n",
       "      <td>kay's place</td>\n",
       "      <td>oldershaw court</td>\n",
       "      <td>ashfield</td>\n",
       "      <td>2047</td>\n",
       "      <td>vic</td>\n",
       "      <td>19500712</td>\n",
       "      <td>9435148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-493-dup-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>blackwell</td>\n",
       "      <td>127</td>\n",
       "      <td>ferrier place</td>\n",
       "      <td>northwood npark</td>\n",
       "      <td>chelsea heights</td>\n",
       "      <td>4211</td>\n",
       "      <td>qld</td>\n",
       "      <td>19570409</td>\n",
       "      <td>8541055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:53.096009Z",
     "start_time": "2025-05-13T04:07:53.091912Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Length of dataframe dfB: {len(dfB)}')",
   "id": "d4e8cf3111f53877",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe dfB: 5000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:53.145523Z",
     "start_time": "2025-05-13T04:07:53.140524Z"
    }
   },
   "cell_type": "code",
   "source": "miTrueLinks",
   "id": "383dd0b1c6759687",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(   'rec-0-org',    'rec-0-dup-0'),\n",
       "            (   'rec-1-org',    'rec-1-dup-0'),\n",
       "            (   'rec-2-org',    'rec-2-dup-0'),\n",
       "            (   'rec-3-org',    'rec-3-dup-0'),\n",
       "            (   'rec-4-org',    'rec-4-dup-0'),\n",
       "            (   'rec-5-org',    'rec-5-dup-0'),\n",
       "            (   'rec-6-org',    'rec-6-dup-0'),\n",
       "            (   'rec-7-org',    'rec-7-dup-0'),\n",
       "            (   'rec-8-org',    'rec-8-dup-0'),\n",
       "            (   'rec-9-org',    'rec-9-dup-0'),\n",
       "            ...\n",
       "            ('rec-4990-org', 'rec-4990-dup-0'),\n",
       "            ('rec-4991-org', 'rec-4991-dup-0'),\n",
       "            ('rec-4992-org', 'rec-4992-dup-0'),\n",
       "            ('rec-4993-org', 'rec-4993-dup-0'),\n",
       "            ('rec-4994-org', 'rec-4994-dup-0'),\n",
       "            ('rec-4995-org', 'rec-4995-dup-0'),\n",
       "            ('rec-4996-org', 'rec-4996-dup-0'),\n",
       "            ('rec-4997-org', 'rec-4997-dup-0'),\n",
       "            ('rec-4998-org', 'rec-4998-dup-0'),\n",
       "            ('rec-4999-org', 'rec-4999-dup-0')],\n",
       "           length=5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Preprocessing\n",
    "Because we are using a synthetic dataset, the amount of scrubbing we need to do is minor relative to real-wold use cases (as we'll see later). In fact, much of the scrubbing we'll do on this dataset is done to align it with our real-world data. However, along with scrubbing we need to enable efficient comparison of data. This means that we want to be able to do phonetic comparisons of strings rather than relying on exact matching, strongly type dates for more efficient comparison, etc. As with most data science efforts, determining optimal preprocessing is usually a trial-and-error process."
   ],
   "id": "4514a4af49f49b14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:53.374596Z",
     "start_time": "2025-05-13T04:07:53.251553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# preprocess fields: given_name, surname, street_number, address_1, address_2, suburb, state, postcode, soc_sec_id, date_of_birth\n",
    "\n",
    "# force all strings to upper case\n",
    "dfA = dfA.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "dfB = dfB.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "# convert city abbreviations to names\n",
    "def convert_au_state(short_name):\n",
    "    if short_name == 'ACT':\n",
    "        return 'AUSTRALIAN CAPITAL TERRITORY'\n",
    "    elif short_name == 'NSW':\n",
    "        return 'NEW SOUTH WALES'\n",
    "    elif short_name == 'NT':\n",
    "        return 'NORTHERN TERRITORY'\n",
    "    elif short_name == 'QLD':\n",
    "        return 'QUEENSLAND'\n",
    "    elif short_name == 'SA':\n",
    "        return 'SOUTH AUSTRALIA'\n",
    "    elif short_name == 'TAS':\n",
    "        return 'TANZANIA'\n",
    "    elif short_name == 'VIC':\n",
    "        return 'VICTORIA'\n",
    "    else:\n",
    "        return short_name\n",
    "dfA['state'] = dfA['state'].apply(convert_au_state)\n",
    "dfB['state'] = dfB['state'].apply(convert_au_state)\n",
    "\n",
    "# process name fields phonetically\n",
    "dfA[['given_name', 'surname']] = dfA[['given_name', 'surname']].fillna('')\n",
    "dfB[['given_name', 'surname']] = dfB[['given_name', 'surname']].fillna('')\n",
    "dfA['given_name_ph'] = phonetic(dfA['given_name'],method='metaphone',decode_error='replace')\n",
    "dfB['given_name_ph'] = phonetic(dfB['given_name'],method='metaphone',decode_error='replace')\n",
    "dfA['surname_ph'] = phonetic(dfA['surname'],method='metaphone',decode_error='replace')\n",
    "dfB['surname_ph'] = phonetic(dfB['surname'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# create a full name field\n",
    "dfA['full_name'] = dfA['given_name'] + ' ' + dfA['surname']\n",
    "dfA['full_name'] = dfA['full_name'].str.strip()\n",
    "dfB['full_name'] = dfB['given_name'] + ' ' + dfB['surname']\n",
    "dfB['full_name'] = dfB['full_name'].str.strip()\n",
    "\n",
    "# process suburb phonetically\n",
    "dfA[['suburb', 'state']] = dfA[['suburb', 'state']].fillna('')\n",
    "dfB[['suburb', 'state']] = dfB[['suburb', 'state']].fillna('')\n",
    "dfA['suburb_ph'] = phonetic(dfA['suburb'],method='metaphone',decode_error='replace')\n",
    "dfB['suburb_ph'] = phonetic(dfA['suburb'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# replace nans in postcode and convert to int\n",
    "dfA['postcode'] = dfA['postcode'].fillna('0')\n",
    "dfB['postcode'] = dfB['postcode'].fillna('0')\n",
    "dfA['postcode_int'] = pd.to_numeric(dfA['postcode'])\n",
    "dfB['postcode_int'] = pd.to_numeric(dfB['postcode'])\n",
    "\n",
    "# replace nans in soc_sec_id and convert to int\n",
    "dfA['soc_sec_id'] = dfA['soc_sec_id'].fillna('0')\n",
    "dfB['soc_sec_id'] = dfB['soc_sec_id'].fillna('0')\n",
    "dfA['soc_sec_id_int'] = dfA['soc_sec_id'].apply(int)\n",
    "dfB['soc_sec_id_int'] = dfB['soc_sec_id'].apply(int)\n",
    "\n",
    "# cast date_of_birth as datetime64 in a new column\n",
    "dfA['dob_typed'] = pd.to_datetime(dfA['date_of_birth'],format='%Y%m%d',errors='coerce')\n",
    "dfB['dob_typed'] = pd.to_datetime(dfB['date_of_birth'],format='%Y%m%d',errors='coerce')\n",
    "\n",
    "# build an all-text column\n",
    "dfA['text'] = dfA['full_name'] + ' ' + dfA['suburb'] + ' ' + dfA[ 'state']\n",
    "dfB['text'] = dfB['full_name'] + ' ' + dfB['suburb'] + ' ' + dfB[ 'state']\n",
    "\n",
    "dfA\n"
   ],
   "id": "41b47ae6bfcab85",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v_mar\\AppData\\Local\\Temp\\ipykernel_19868\\976360393.py:4: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  dfA = dfA.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
      "C:\\Users\\v_mar\\AppData\\Local\\Temp\\ipykernel_19868\\976360393.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  dfB = dfB.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "             given_name    surname street_number            address_1  \\\n",
       "rec_id                                                                  \n",
       "rec-1070-org   MICHAELA    NEUMANN             8       STANLEY STREET   \n",
       "rec-1016-org   COURTNEY    PAINTER            12    PINKERTON CIRCUIT   \n",
       "rec-4405-org    CHARLES      GREEN            38  SALKAUSKAS CRESCENT   \n",
       "rec-1288-org    VANESSA       PARR           905       MACQUOID PLACE   \n",
       "rec-3585-org    MIKAYLA   MALLONEY            37        RANDWICK ROAD   \n",
       "...                 ...        ...           ...                  ...   \n",
       "rec-2153-org    ANNABEL   GRIERSON            97   MCLACHLAN CRESCENT   \n",
       "rec-1604-org     SIENNA   MUSOLINO            22      SMEATON CIRCUIT   \n",
       "rec-1003-org    BRADLEY   MATTHEWS             2         JONDOL PLACE   \n",
       "rec-4883-org     BRODEE       EGAN            88          AXON STREET   \n",
       "rec-66-org        KOULA  HOUWELING             3       MILEHAM STREET   \n",
       "\n",
       "                        address_2            suburb postcode            state  \\\n",
       "rec_id                                                                          \n",
       "rec-1070-org                MIAMI     WINSTON HILLS     4223  NEW SOUTH WALES   \n",
       "rec-1016-org           BEGA FLATS         RICHLANDS     4560         VICTORIA   \n",
       "rec-4405-org                 KELA             DAPTO     4566  NEW SOUTH WALES   \n",
       "rec-1288-org    BROADBRIDGE MANOR     SOUTH GRAFTON     2135  SOUTH AUSTRALIA   \n",
       "rec-3585-org              AVALIND  HOPPERS CROSSING     4552         VICTORIA   \n",
       "...                           ...               ...      ...              ...   \n",
       "rec-2153-org        LANTANA LODGE            BROOME     2480  NEW SOUTH WALES   \n",
       "rec-1604-org              PANGANI          MCKINNON     2700  NEW SOUTH WALES   \n",
       "rec-1003-org         HORSESHOE CK       JACOBS WELL     7018  SOUTH AUSTRALIA   \n",
       "rec-4883-org          GREENSLOPES          WAMBERAL     2067       QUEENSLAND   \n",
       "rec-66-org    OLD AIRDMILLAN ROAD      WILLIAMSTOWN     2350  NEW SOUTH WALES   \n",
       "\n",
       "             date_of_birth soc_sec_id given_name_ph surname_ph  \\\n",
       "rec_id                                                           \n",
       "rec-1070-org      19151111    5304218           MXL        NMN   \n",
       "rec-1016-org      19161214    4066625          KRTN       PNTR   \n",
       "rec-4405-org      19480930    4365168          XRLS        KRN   \n",
       "rec-1288-org      19951119    9239102           FNS         PR   \n",
       "rec-3585-org      19860208    7207688           MKL        MLN   \n",
       "...                    ...        ...           ...        ...   \n",
       "rec-2153-org      19840224    7676186          ANBL      KRRSN   \n",
       "rec-1604-org      19890525    4971506            SN       MSLN   \n",
       "rec-1003-org      19481122    8927667          BRTL        M0S   \n",
       "rec-4883-org      19121113    6039042           BRT        EKN   \n",
       "rec-66-org        19440718    6375537            KL      HWLNK   \n",
       "\n",
       "                     full_name  suburb_ph  postcode_int  soc_sec_id_int  \\\n",
       "rec_id                                                                    \n",
       "rec-1070-org  MICHAELA NEUMANN   WNSTNHLS          4223         5304218   \n",
       "rec-1016-org  COURTNEY PAINTER     RXLNTS          4560         4066625   \n",
       "rec-4405-org     CHARLES GREEN        TPT          4566         4365168   \n",
       "rec-1288-org      VANESSA PARR    S0KRFTN          2135         9239102   \n",
       "rec-3585-org  MIKAYLA MALLONEY  HPRSKRSNK          4552         7207688   \n",
       "...                        ...        ...           ...             ...   \n",
       "rec-2153-org  ANNABEL GRIERSON        BRM          2480         7676186   \n",
       "rec-1604-org   SIENNA MUSOLINO       MKNN          2700         4971506   \n",
       "rec-1003-org  BRADLEY MATTHEWS     JKBSWL          7018         8927667   \n",
       "rec-4883-org       BRODEE EGAN      WMBRL          2067         6039042   \n",
       "rec-66-org     KOULA HOUWELING     WLMSTN          2350         6375537   \n",
       "\n",
       "              dob_typed                                            text  \n",
       "rec_id                                                                   \n",
       "rec-1070-org 1915-11-11  MICHAELA NEUMANN WINSTON HILLS NEW SOUTH WALES  \n",
       "rec-1016-org 1916-12-14             COURTNEY PAINTER RICHLANDS VICTORIA  \n",
       "rec-4405-org 1948-09-30             CHARLES GREEN DAPTO NEW SOUTH WALES  \n",
       "rec-1288-org 1995-11-19      VANESSA PARR SOUTH GRAFTON SOUTH AUSTRALIA  \n",
       "rec-3585-org 1986-02-08      MIKAYLA MALLONEY HOPPERS CROSSING VICTORIA  \n",
       "...                 ...                                             ...  \n",
       "rec-2153-org 1984-02-24         ANNABEL GRIERSON BROOME NEW SOUTH WALES  \n",
       "rec-1604-org 1989-05-25        SIENNA MUSOLINO MCKINNON NEW SOUTH WALES  \n",
       "rec-1003-org 1948-11-22    BRADLEY MATTHEWS JACOBS WELL SOUTH AUSTRALIA  \n",
       "rec-4883-org 1912-11-13                 BRODEE EGAN WAMBERAL QUEENSLAND  \n",
       "rec-66-org   1944-07-18    KOULA HOUWELING WILLIAMSTOWN NEW SOUTH WALES  \n",
       "\n",
       "[5000 rows x 18 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>full_name</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>postcode_int</th>\n",
       "      <th>soc_sec_id_int</th>\n",
       "      <th>dob_typed</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-1070-org</th>\n",
       "      <td>MICHAELA</td>\n",
       "      <td>NEUMANN</td>\n",
       "      <td>8</td>\n",
       "      <td>STANLEY STREET</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>WINSTON HILLS</td>\n",
       "      <td>4223</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19151111</td>\n",
       "      <td>5304218</td>\n",
       "      <td>MXL</td>\n",
       "      <td>NMN</td>\n",
       "      <td>MICHAELA NEUMANN</td>\n",
       "      <td>WNSTNHLS</td>\n",
       "      <td>4223</td>\n",
       "      <td>5304218</td>\n",
       "      <td>1915-11-11</td>\n",
       "      <td>MICHAELA NEUMANN WINSTON HILLS NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1016-org</th>\n",
       "      <td>COURTNEY</td>\n",
       "      <td>PAINTER</td>\n",
       "      <td>12</td>\n",
       "      <td>PINKERTON CIRCUIT</td>\n",
       "      <td>BEGA FLATS</td>\n",
       "      <td>RICHLANDS</td>\n",
       "      <td>4560</td>\n",
       "      <td>VICTORIA</td>\n",
       "      <td>19161214</td>\n",
       "      <td>4066625</td>\n",
       "      <td>KRTN</td>\n",
       "      <td>PNTR</td>\n",
       "      <td>COURTNEY PAINTER</td>\n",
       "      <td>RXLNTS</td>\n",
       "      <td>4560</td>\n",
       "      <td>4066625</td>\n",
       "      <td>1916-12-14</td>\n",
       "      <td>COURTNEY PAINTER RICHLANDS VICTORIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4405-org</th>\n",
       "      <td>CHARLES</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>38</td>\n",
       "      <td>SALKAUSKAS CRESCENT</td>\n",
       "      <td>KELA</td>\n",
       "      <td>DAPTO</td>\n",
       "      <td>4566</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19480930</td>\n",
       "      <td>4365168</td>\n",
       "      <td>XRLS</td>\n",
       "      <td>KRN</td>\n",
       "      <td>CHARLES GREEN</td>\n",
       "      <td>TPT</td>\n",
       "      <td>4566</td>\n",
       "      <td>4365168</td>\n",
       "      <td>1948-09-30</td>\n",
       "      <td>CHARLES GREEN DAPTO NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1288-org</th>\n",
       "      <td>VANESSA</td>\n",
       "      <td>PARR</td>\n",
       "      <td>905</td>\n",
       "      <td>MACQUOID PLACE</td>\n",
       "      <td>BROADBRIDGE MANOR</td>\n",
       "      <td>SOUTH GRAFTON</td>\n",
       "      <td>2135</td>\n",
       "      <td>SOUTH AUSTRALIA</td>\n",
       "      <td>19951119</td>\n",
       "      <td>9239102</td>\n",
       "      <td>FNS</td>\n",
       "      <td>PR</td>\n",
       "      <td>VANESSA PARR</td>\n",
       "      <td>S0KRFTN</td>\n",
       "      <td>2135</td>\n",
       "      <td>9239102</td>\n",
       "      <td>1995-11-19</td>\n",
       "      <td>VANESSA PARR SOUTH GRAFTON SOUTH AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3585-org</th>\n",
       "      <td>MIKAYLA</td>\n",
       "      <td>MALLONEY</td>\n",
       "      <td>37</td>\n",
       "      <td>RANDWICK ROAD</td>\n",
       "      <td>AVALIND</td>\n",
       "      <td>HOPPERS CROSSING</td>\n",
       "      <td>4552</td>\n",
       "      <td>VICTORIA</td>\n",
       "      <td>19860208</td>\n",
       "      <td>7207688</td>\n",
       "      <td>MKL</td>\n",
       "      <td>MLN</td>\n",
       "      <td>MIKAYLA MALLONEY</td>\n",
       "      <td>HPRSKRSNK</td>\n",
       "      <td>4552</td>\n",
       "      <td>7207688</td>\n",
       "      <td>1986-02-08</td>\n",
       "      <td>MIKAYLA MALLONEY HOPPERS CROSSING VICTORIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2153-org</th>\n",
       "      <td>ANNABEL</td>\n",
       "      <td>GRIERSON</td>\n",
       "      <td>97</td>\n",
       "      <td>MCLACHLAN CRESCENT</td>\n",
       "      <td>LANTANA LODGE</td>\n",
       "      <td>BROOME</td>\n",
       "      <td>2480</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19840224</td>\n",
       "      <td>7676186</td>\n",
       "      <td>ANBL</td>\n",
       "      <td>KRRSN</td>\n",
       "      <td>ANNABEL GRIERSON</td>\n",
       "      <td>BRM</td>\n",
       "      <td>2480</td>\n",
       "      <td>7676186</td>\n",
       "      <td>1984-02-24</td>\n",
       "      <td>ANNABEL GRIERSON BROOME NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1604-org</th>\n",
       "      <td>SIENNA</td>\n",
       "      <td>MUSOLINO</td>\n",
       "      <td>22</td>\n",
       "      <td>SMEATON CIRCUIT</td>\n",
       "      <td>PANGANI</td>\n",
       "      <td>MCKINNON</td>\n",
       "      <td>2700</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19890525</td>\n",
       "      <td>4971506</td>\n",
       "      <td>SN</td>\n",
       "      <td>MSLN</td>\n",
       "      <td>SIENNA MUSOLINO</td>\n",
       "      <td>MKNN</td>\n",
       "      <td>2700</td>\n",
       "      <td>4971506</td>\n",
       "      <td>1989-05-25</td>\n",
       "      <td>SIENNA MUSOLINO MCKINNON NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1003-org</th>\n",
       "      <td>BRADLEY</td>\n",
       "      <td>MATTHEWS</td>\n",
       "      <td>2</td>\n",
       "      <td>JONDOL PLACE</td>\n",
       "      <td>HORSESHOE CK</td>\n",
       "      <td>JACOBS WELL</td>\n",
       "      <td>7018</td>\n",
       "      <td>SOUTH AUSTRALIA</td>\n",
       "      <td>19481122</td>\n",
       "      <td>8927667</td>\n",
       "      <td>BRTL</td>\n",
       "      <td>M0S</td>\n",
       "      <td>BRADLEY MATTHEWS</td>\n",
       "      <td>JKBSWL</td>\n",
       "      <td>7018</td>\n",
       "      <td>8927667</td>\n",
       "      <td>1948-11-22</td>\n",
       "      <td>BRADLEY MATTHEWS JACOBS WELL SOUTH AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4883-org</th>\n",
       "      <td>BRODEE</td>\n",
       "      <td>EGAN</td>\n",
       "      <td>88</td>\n",
       "      <td>AXON STREET</td>\n",
       "      <td>GREENSLOPES</td>\n",
       "      <td>WAMBERAL</td>\n",
       "      <td>2067</td>\n",
       "      <td>QUEENSLAND</td>\n",
       "      <td>19121113</td>\n",
       "      <td>6039042</td>\n",
       "      <td>BRT</td>\n",
       "      <td>EKN</td>\n",
       "      <td>BRODEE EGAN</td>\n",
       "      <td>WMBRL</td>\n",
       "      <td>2067</td>\n",
       "      <td>6039042</td>\n",
       "      <td>1912-11-13</td>\n",
       "      <td>BRODEE EGAN WAMBERAL QUEENSLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-66-org</th>\n",
       "      <td>KOULA</td>\n",
       "      <td>HOUWELING</td>\n",
       "      <td>3</td>\n",
       "      <td>MILEHAM STREET</td>\n",
       "      <td>OLD AIRDMILLAN ROAD</td>\n",
       "      <td>WILLIAMSTOWN</td>\n",
       "      <td>2350</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>19440718</td>\n",
       "      <td>6375537</td>\n",
       "      <td>KL</td>\n",
       "      <td>HWLNK</td>\n",
       "      <td>KOULA HOUWELING</td>\n",
       "      <td>WLMSTN</td>\n",
       "      <td>2350</td>\n",
       "      <td>6375537</td>\n",
       "      <td>1944-07-18</td>\n",
       "      <td>KOULA HOUWELING WILLIAMSTOWN NEW SOUTH WALES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 18 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Indexing\n",
    "The next step in the process is to link each row in the source to each row in the target so that we can check for matches based on weighted scores. In it's simplest form, this results in a full cartesian product of `dfA X dfB`. Clearly this does not scale well so most often a technique called Blocking is applied in which obvious non-matches are not included in the indexes. Simpler techniques block based on exact matches on one or more attributes (columns) while more complex and interesting techniques relax the matching criteria using techniques such as clustering, fuzzy hashing, and bloom filter grouping.\n",
    "\n",
    "The PRLT library includes fairly simple Indexing methods that include Full (no Blocking), Block which uses exact matches on specified attributes, and SortedNeighborhood which sorts data from both datasets together and groups data from two different sets according a window size (<ins>de Bruin, 2023</ins>). Interestingly, this concept is similar in functionality to convolution."
   ],
   "id": "6fcd0d04e80280d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:53.542572Z",
     "start_time": "2025-05-13T04:07:53.422054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# full indexing --> far too many rows to process\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.full()\n",
    "pairs = indexer.index(dfA, dfB)\n",
    "pairs"
   ],
   "id": "726ba00d246af6b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('rec-1070-org',  'rec-561-dup-0'),\n",
       "            ('rec-1070-org', 'rec-2642-dup-0'),\n",
       "            ('rec-1070-org',  'rec-608-dup-0'),\n",
       "            ('rec-1070-org', 'rec-3239-dup-0'),\n",
       "            ('rec-1070-org', 'rec-2886-dup-0'),\n",
       "            ('rec-1070-org', 'rec-4285-dup-0'),\n",
       "            ('rec-1070-org',  'rec-929-dup-0'),\n",
       "            ('rec-1070-org', 'rec-4833-dup-0'),\n",
       "            ('rec-1070-org',  'rec-717-dup-0'),\n",
       "            ('rec-1070-org', 'rec-3984-dup-0'),\n",
       "            ...\n",
       "            (  'rec-66-org',  'rec-670-dup-0'),\n",
       "            (  'rec-66-org', 'rec-4134-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3866-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3152-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3363-dup-0'),\n",
       "            (  'rec-66-org', 'rec-4495-dup-0'),\n",
       "            (  'rec-66-org', 'rec-4211-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3131-dup-0'),\n",
       "            (  'rec-66-org', 'rec-3815-dup-0'),\n",
       "            (  'rec-66-org',  'rec-493-dup-0')],\n",
       "           names=['rec_id_1', 'rec_id_2'], length=25000000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:53.594069Z",
     "start_time": "2025-05-13T04:07:53.576733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# exact match on phonetic surname --> not ideal based on the types of errors we expect to encounter\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block(left_on='surname_ph', right_on='surname_ph')\n",
    "pairs = indexer.index(dfA, dfB)\n",
    "pairs"
   ],
   "id": "640f8814ae7b3dcb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('rec-1070-org', 'rec-2672-dup-0'),\n",
       "            ('rec-1070-org', 'rec-4387-dup-0'),\n",
       "            ('rec-1070-org',  'rec-787-dup-0'),\n",
       "            ('rec-1070-org', 'rec-2158-dup-0'),\n",
       "            ('rec-1016-org', 'rec-3267-dup-0'),\n",
       "            ('rec-1016-org', 'rec-2136-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1948-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1016-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1032-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1321-dup-0'),\n",
       "            ...\n",
       "            ('rec-1003-org', 'rec-3462-dup-0'),\n",
       "            ('rec-1003-org', 'rec-1014-dup-0'),\n",
       "            ('rec-4883-org', 'rec-1662-dup-0'),\n",
       "            ('rec-4883-org',  'rec-835-dup-0'),\n",
       "            ('rec-4883-org', 'rec-4883-dup-0'),\n",
       "            ('rec-4883-org', 'rec-1884-dup-0'),\n",
       "            ('rec-4883-org',  'rec-785-dup-0'),\n",
       "            ('rec-4883-org', 'rec-3923-dup-0'),\n",
       "            ('rec-4883-org', 'rec-2609-dup-0'),\n",
       "            ('rec-4883-org', 'rec-4459-dup-0')],\n",
       "           names=['rec_id_1', 'rec_id_2'], length=105304)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Custom LSH Indexing Algorithm\n",
    "\n",
    "The PRLT library also allows the Index class to be extended to enable other blocking algorithms. One newer blocking algorithm found in the literature uses Locality Sensitive Hashing (LSH). The LSH algorithm has gained popularity for two reasons. First, it is less strict than standard blocking but still effectively reduces the comparison size relative to full indexing. Second, because the algorithm hashes values before indexing using LSH, it can be used to preserve the privacy of the original data sets (<ins>Dutt, 2023</ins>). In the code below, we extend the PRLT BaseIndexAlgorithm class using the [datasketch library](https://ekzhu.com/datasketch/index.html)'s MinHash and MinHashLSH algorithms. MinHash estimates the Jaccard Similarity Index for two inputs. These are then loaded into the MinHashed LSH index and matches are queried (<ins>Zhu, 2024</ins>). The resulting matches are output as Pandas MultiArray so that they work seamlessly within the PRLT libary. Note that two tokenizers are enabled. The first tokenizes text bigrams and the second tokenizes words. Both will be experimented with.\n"
   ],
   "id": "135d655eb4da1131"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:07:53.659077Z",
     "start_time": "2025-05-13T04:07:53.649073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _tokenize_bigram(string):\n",
    "    # Clean and create character bigrams\n",
    "    string = re.sub(r'\\W+', '', string.lower())\n",
    "    tokens = set(string[i:i+2] for i in range(len(string)-1))\n",
    "    return tokens\n",
    "\n",
    "def _tokenize_words(string):\n",
    "    # Clean and create character bigrams\n",
    "    tokens = string.split()\n",
    "    return tokens\n",
    "\n",
    "class LSHIndex(BaseIndexAlgorithm):\n",
    "\n",
    "    def __init__(self, column, threshold=0.3, num_perm=128, tokenizer='words'):\n",
    "        super().__init__()\n",
    "        self.column = column\n",
    "        self.threshold = threshold\n",
    "        self.num_perm = num_perm\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def _tokenize(self, string):\n",
    "        if self.tokenizer == 'words':\n",
    "            return _tokenize_words(string)\n",
    "        elif self.tokenizer == 'bigrams':\n",
    "            return _tokenize_bigram(string)\n",
    "\n",
    "    def _create_minhash(self, row):\n",
    "        string = row[self.column]\n",
    "        tokens = self._tokenize(string)\n",
    "        m = MinHash(num_perm=self.num_perm)\n",
    "        for token in tokens:\n",
    "            m.update(token.encode('utf8'))\n",
    "        return LeanMinHash(m)\n",
    "\n",
    "    def _link_index(self, dfA, dfB):\n",
    "        is_deduplication = dfA.equals(dfB)\n",
    "\n",
    "        # MinHash computation\n",
    "        start = time.perf_counter()\n",
    "        dfA['minhash'] = dfA.apply(func=self._create_minhash, axis=1)\n",
    "        end = time.perf_counter()\n",
    "        print(f'Seconds to compute minhash dfA: {end - start}')\n",
    "        if is_deduplication:\n",
    "            dfB = dfA\n",
    "        else:\n",
    "            start = time.perf_counter()\n",
    "            dfB['minhash'] = dfB.apply(func=self._create_minhash, axis=1)\n",
    "            end = time.perf_counter()\n",
    "            print(f'Seconds to compute minhash dfB: {end - start}')\n",
    "\n",
    "        # Insert into LSH\n",
    "        lsh = MinHashLSH(threshold=self.threshold, num_perm=self.num_perm)\n",
    "        start = time.perf_counter()\n",
    "        for index, row in dfB.iterrows():\n",
    "            lsh.insert(index, row['minhash'])\n",
    "        end = time.perf_counter()\n",
    "        print(f'Seconds to build LSH of dfB: {end - start}')\n",
    "\n",
    "        # Query LSH for candidate pairs\n",
    "        l_rows = []\n",
    "        start = time.perf_counter()\n",
    "        for index, row in dfA.iterrows():\n",
    "            result = lsh.query(row['minhash'])\n",
    "            for idx_b in result:\n",
    "                if is_deduplication and index >= idx_b:\n",
    "                    continue\n",
    "                l_rows.append({'dfA_idx': index, 'dfB_idx': idx_b})\n",
    "        df_out = pd.DataFrame(l_rows)\n",
    "        end = time.perf_counter()\n",
    "        print(f'Seconds to query dfB for each row of dfA: {end - start}')\n",
    "\n",
    "        # Convert result to MultiIndex\n",
    "        start = time.perf_counter()\n",
    "        output = pd.MultiIndex.from_frame(df_out)\n",
    "        end = time.perf_counter()\n",
    "        print(f'Seconds to convert df to MultiIndex: {end - start}')\n",
    "        return output"
   ],
   "id": "eca6d004795c7aa5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Indexing Results Using LSHIndex\n",
    "\n",
    "Below we index our dataset using the custom LSHIndex Blocking algorithm. In earlier tests, we used the bigram tokenizer to compare the `full_name` column from the two datasets. This method is computationally intensive and did not scale as well as the word tokenizer. In the code below, we use the word-based tokenizer to tokenize all strings in the row, concatenated into a column named `text`. This method performed somewhat better than bigram tokenizer after tuning the Jaccard Similarity threshold and number of MinHash permutations variables based on guidance in the DataSketch documentation (<ins>Zhu, 2024</ins>) and in a reference implementation by Martin Boyanov (<ins>Boyanov, 2020</ins>). This method allows us to generate a comparison index that is somewhere between full, which we know is unnecessarily large, and an exact match blocking set, which appears to be too restrictive even when using phonetic encoding."
   ],
   "id": "acdda033f1df27f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:01.049797Z",
     "start_time": "2025-05-13T04:07:53.702908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indexer = LSHIndex(column='text', threshold=0.5, num_perm=64, tokenizer='words')\n",
    "pairs_lsh = indexer.index(dfA, dfB)\n",
    "pairs_lsh"
   ],
   "id": "5f85f83d6d3da2d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfA: 3.1197030999464914\n",
      "Seconds to compute minhash dfB: 3.086601300048642\n",
      "Seconds to build LSH of dfB: 0.41145350004080683\n",
      "Seconds to query dfB for each row of dfA: 0.6348346999147907\n",
      "Seconds to convert df to MultiIndex: 0.059456099988892674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('rec-1070-org', 'rec-4233-dup-0'),\n",
       "            ('rec-1070-org', 'rec-3674-dup-0'),\n",
       "            ('rec-1070-org', 'rec-2473-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1209-dup-0'),\n",
       "            ('rec-1016-org', 'rec-2389-dup-0'),\n",
       "            ('rec-1016-org', 'rec-1016-dup-0'),\n",
       "            ('rec-4405-org', 'rec-1236-dup-0'),\n",
       "            ('rec-4405-org', 'rec-4405-dup-0'),\n",
       "            ('rec-4405-org',  'rec-853-dup-0'),\n",
       "            ('rec-4405-org', 'rec-2150-dup-0'),\n",
       "            ...\n",
       "            (  'rec-66-org', 'rec-3731-dup-0'),\n",
       "            (  'rec-66-org',  'rec-534-dup-0'),\n",
       "            (  'rec-66-org', 'rec-1932-dup-0'),\n",
       "            (  'rec-66-org', 'rec-4401-dup-0'),\n",
       "            (  'rec-66-org',  'rec-105-dup-0'),\n",
       "            (  'rec-66-org',  'rec-987-dup-0'),\n",
       "            (  'rec-66-org',  'rec-592-dup-0'),\n",
       "            (  'rec-66-org', 'rec-2962-dup-0'),\n",
       "            (  'rec-66-org',  'rec-852-dup-0'),\n",
       "            (  'rec-66-org', 'rec-1156-dup-0')],\n",
       "           names=['rec_id_1', 'rec_id_2'], length=421590)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Index Runtime Benchmarks:\n",
    "\n",
    "Time to generate the Pandas MultiIndex for two 5000 row datasets (see Appendix 1 for system info):\n",
    "\n",
    "- *Full Index Generation*: 118ms / 25M rows\n",
    "- *Exact-Match Blocking Index Generation*: 25ms / 89727 rows\n",
    "- *LSH Blocking Index Generation*: 11.6s / 400432 rows\n"
   ],
   "id": "5a6789d6389f044e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparison\n",
    "\n",
    "When comparing the candidate records generated by the Indexing steps above in order to generate comparison scores, there are a number of algorithms that can be applied. The PRLT library includes several methods that compare data based on it's type. These comparisons, run alone, all return scores. When a Pandas dataframe is provided with a set of records, the library can be used to compute scores for each row in the dataframe. Each matching column between the two datasets can be assigned it's own comparison algorithm. The result in this case is a vector that includes the row keys of the two rows being compared and columns for each compared variable that includes their match score.\n",
    "\n",
    "#### Algorithms by Data Type\n",
    "\n",
    "##### General\n",
    "\n",
    "  - Exact --> straight equivalence that returns a score of 1 or 0\n",
    "  - Custom --> As with Indexers above, the library offers the BaseCompareFeature from which custom algorithms can be implemented\n",
    "\n",
    "##### String\n",
    "\n",
    "String comparisons are implemented in the PRLT library by wrapping the Python [jellyfish](https://jamesturk.github.io/jellyfish/) library for approximate and phonetic string matching. PRLT implements the following string comparison methods from the jellyfish library:\n",
    "\n",
    "   - Jaro\n",
    "   - Jaro-Winkler\n",
    "   - Levenshtein\n",
    "   - Damerau-Levenshtein\n",
    "\n",
    "Interestingly, it excludes Hamming Distance and Match Rating Approach algorithms. The PRLT library also excludes the phonetic encoding tools provided in the jellyfish library. These tools are interesting in that they address phonetic misspellings that might fail edit distance algorithms like the ones above. For example, the spellings Clumps and Klumpz sound the same but would have a low edit distance score. Applying a phonetic encoding tool early can improve match scores (<ins>Zhu, 2024</ins>).\n",
    "\n",
    "##### Numeric\n",
    "\n",
    "The PRLT library can compare numeric values using a variety of nearness measures all of which are based on a distance from a comparison point. The following diagram, referenced from the PRLT documentation, well illustrates how the comparisons work (<ins>Elastic, 2025</ins>):\n",
    "\n",
    "<br><center>\n",
    "![numeric matching algorithms](images/elas_1705.png)\n",
    "</center>\n",
    "\n",
    "As the diagram shows, two values are compared as a distance using one of several decay algorithms (step, linear, exponential, gaussian or squared), returning a float value between 0 and 1.\n",
    "\n",
    "##### Geospatial\n",
    "\n",
    "For locations that include lattidue and longitude, the toolkit can compute the haversine distance between coordinates and then compute the numeric similarity between the distances as described for numeric values above.\n",
    "\n",
    "##### Date\n",
    "\n",
    "Again, the numeric distance between dates is computed with a few date-specific scoring optimizations applied.\n",
    "\n",
    "- score when month and day are swapped: allows for a set score to be applied if the only difference between two dates is that day and month are transposed\n",
    "- score for common month swapping errors: allows for a set score to be applied if the only difference between two dates is that a common string to numeric date conversion error occurred\n",
    "\n",
    "##### Precomputed Variable\n",
    "\n",
    "In addition to row-specific values, the toolkit allows for precomputed scores already contained in the dataset to be passed in as variables. By default, these variables are normalized to a score range from 0-1.\n",
    "\n",
    "#### Comparison Algorithm Applied by Column\n",
    "\n",
    "- *given_name_ph*: exact\n",
    "- *surname_ph*: exact\n",
    "- *suburb_ph*: exact\n",
    "- *postcode*: numeric (exponential)\n",
    "- *state*: Jaro-Winkler distance\n",
    "- *date_of_birth*: date with default scoring for month/day and text to numeric month errors\n",
    "- *soc_sec_id*: numeric (exponential)"
   ],
   "id": "80de2d58c1966bd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:02.157420Z",
     "start_time": "2025-05-13T04:08:01.067313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comparison = recordlinkage.Compare()\n",
    "comparison.exact(left_on=\"given_name_ph\", right_on=\"given_name_ph\", label=\"given_name_ph\")\n",
    "comparison.exact(left_on=\"surname_ph\", right_on=\"surname_ph\", label=\"surname_ph\")\n",
    "comparison.string(left_on=\"given_name\", right_on=\"given_name\", method='jarowinkler', label='given_name')\n",
    "comparison.string(left_on=\"surname\", right_on=\"state\", method='jarowinkler', label='surname')\n",
    "# comparison.string(left_on=\"street_number\", right_on=\"street_number\", method='damerau_levenshtein', label='street_number')\n",
    "# comparison.string(left_on=\"address_1\", right_on=\"address_1\", method='damerau_levenshtein', label='address_1')\n",
    "# comparison.string(left_on=\"address_2\", right_on=\"address_2\", method='damerau_levenshtein', label='address_2')\n",
    "comparison.exact(left_on=\"suburb_ph\", right_on=\"suburb_ph\", label='suburb_ph')\n",
    "comparison.string(left_on=\"suburb\", right_on=\"suburb\", label='suburb')\n",
    "comparison.numeric (left_on=\"postcode_int\", right_on=\"postcode_int\", method='exp', label='postcode')\n",
    "comparison.exact(left_on=\"state\", right_on=\"state\", label='state')\n",
    "comparison.numeric(left_on=\"soc_sec_id_int\", right_on=\"soc_sec_id_int\", method=\"exp\", label='soc_sec_id')\n",
    "comparison.date(left_on=\"dob_typed\", right_on=\"dob_typed\", label='dob')\n",
    "print(len(pairs))\n",
    "features = comparison.compute(pairs=pairs, x=dfA, x_link=dfB)\n",
    "features"
   ],
   "id": "83feb348a41636a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\recordlinkage\\algorithms\\string.py:56: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - levenshtein_distance(x[0], x[1]) / np.max([len(x[0]), len(x[1])])\n",
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\recordlinkage\\compare.py:414: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  c[\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                             given_name_ph  surname_ph  given_name   surname  \\\n",
       "rec_id_1     rec_id_2                                                          \n",
       "rec-1070-org rec-2672-dup-0              0           1    0.638889  0.000000   \n",
       "             rec-4387-dup-0              0           1    0.550000  0.671429   \n",
       "             rec-787-dup-0               0           1    0.430556  0.422619   \n",
       "             rec-2158-dup-0              0           1    0.441667  0.671429   \n",
       "rec-1016-org rec-3267-dup-0              0           1    0.000000  0.431746   \n",
       "...                                    ...         ...         ...       ...   \n",
       "rec-4883-org rec-1884-dup-0              0           1    0.444444  0.377778   \n",
       "             rec-785-dup-0               0           1    0.000000  0.438889   \n",
       "             rec-3923-dup-0              0           1    0.000000  0.000000   \n",
       "             rec-2609-dup-0              0           1    0.844444  0.000000   \n",
       "             rec-4459-dup-0              0           1    0.577778  0.377778   \n",
       "\n",
       "                             suburb_ph    suburb       postcode  state  \\\n",
       "rec_id_1     rec_id_2                                                    \n",
       "rec-1070-org rec-2672-dup-0          0  0.307692   0.000000e+00      0   \n",
       "             rec-4387-dup-0          0  0.000000   0.000000e+00      0   \n",
       "             rec-787-dup-0           0  0.076923   0.000000e+00      0   \n",
       "             rec-2158-dup-0          0  0.307692  1.430222e-247      0   \n",
       "rec-1016-org rec-3267-dup-0          0  0.222222   0.000000e+00      0   \n",
       "...                                ...       ...            ...    ...   \n",
       "rec-4883-org rec-1884-dup-0          0  0.125000  3.131513e-294      0   \n",
       "             rec-785-dup-0           0  0.111111   0.000000e+00      0   \n",
       "             rec-3923-dup-0          0  0.111111   7.812500e-03      0   \n",
       "             rec-2609-dup-0          0  0.222222   0.000000e+00      0   \n",
       "             rec-4459-dup-0          0  0.181818   0.000000e+00      0   \n",
       "\n",
       "                             soc_sec_id  dob  \n",
       "rec_id_1     rec_id_2                         \n",
       "rec-1070-org rec-2672-dup-0         0.0  0.0  \n",
       "             rec-4387-dup-0         0.0  0.0  \n",
       "             rec-787-dup-0          0.0  0.0  \n",
       "             rec-2158-dup-0         0.0  0.0  \n",
       "rec-1016-org rec-3267-dup-0         0.0  0.0  \n",
       "...                                 ...  ...  \n",
       "rec-4883-org rec-1884-dup-0         0.0  0.0  \n",
       "             rec-785-dup-0          0.0  0.0  \n",
       "             rec-3923-dup-0         0.0  0.0  \n",
       "             rec-2609-dup-0         0.0  0.0  \n",
       "             rec-4459-dup-0         0.0  0.0  \n",
       "\n",
       "[105304 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">rec-1070-org</th>\n",
       "      <th>rec-2672-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4387-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-787-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.422619</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2158-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.430222e-247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1016-org</th>\n",
       "      <th>rec-3267-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rec-4883-org</th>\n",
       "      <th>rec-1884-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.131513e-294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-785-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3923-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7.812500e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2609-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4459-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105304 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:02.250260Z",
     "start_time": "2025-05-13T04:08:02.208260Z"
    }
   },
   "cell_type": "code",
   "source": "features.describe()",
   "id": "75397fba54ee8f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       given_name_ph  surname_ph     given_name        surname  suburb_ph  \\\n",
       "count  105304.000000    105304.0  105304.000000  105304.000000   105304.0   \n",
       "mean        0.033361         1.0       0.401377       0.379457        0.0   \n",
       "std         0.179577         0.0       0.258514       0.192889        0.0   \n",
       "min         0.000000         1.0       0.000000       0.000000        0.0   \n",
       "25%         0.000000         1.0       0.000000       0.344444        0.0   \n",
       "50%         0.000000         1.0       0.464286       0.438889        0.0   \n",
       "75%         0.000000         1.0       0.555556       0.488889        0.0   \n",
       "max         1.000000         1.0       1.000000       0.822222        0.0   \n",
       "\n",
       "              suburb       postcode          state     soc_sec_id  \\\n",
       "count  105304.000000   1.053040e+05  105304.000000  105304.000000   \n",
       "mean        0.164120   3.214702e-02       0.245252       0.031903   \n",
       "std         0.181727   1.738743e-01       0.430238       0.175736   \n",
       "min         0.000000   0.000000e+00       0.000000       0.000000   \n",
       "25%         0.076923   0.000000e+00       0.000000       0.000000   \n",
       "50%         0.125000   0.000000e+00       0.000000       0.000000   \n",
       "75%         0.200000  2.002083e-146       0.000000       0.000000   \n",
       "max         1.000000   1.000000e+00       1.000000       1.000000   \n",
       "\n",
       "                 dob  \n",
       "count  105304.000000  \n",
       "mean        0.031542  \n",
       "std         0.174771  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.0</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.0</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>1.053040e+05</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.000000</td>\n",
       "      <td>105304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.033361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401377</td>\n",
       "      <td>0.379457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164120</td>\n",
       "      <td>3.214702e-02</td>\n",
       "      <td>0.245252</td>\n",
       "      <td>0.031903</td>\n",
       "      <td>0.031542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.179577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258514</td>\n",
       "      <td>0.192889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181727</td>\n",
       "      <td>1.738743e-01</td>\n",
       "      <td>0.430238</td>\n",
       "      <td>0.175736</td>\n",
       "      <td>0.174771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.438889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.002083e-146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:06.692835Z",
     "start_time": "2025-05-13T04:08:02.337185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_lsh = comparison.compute(pairs=pairs_lsh, x=dfA, x_link=dfB)\n",
    "features_lsh"
   ],
   "id": "d72d8c17a87bb30",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\recordlinkage\\algorithms\\string.py:56: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - levenshtein_distance(x[0], x[1]) / np.max([len(x[0]), len(x[1])])\n",
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\recordlinkage\\compare.py:388: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  c[\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                             given_name_ph  surname_ph  given_name   surname  \\\n",
       "rec_id_1     rec_id_2                                                          \n",
       "rec-1070-org rec-4233-dup-0              0           0    0.527778  0.542857   \n",
       "             rec-3674-dup-0              0           0    0.513889  0.542857   \n",
       "             rec-2473-dup-0              0           0    0.713095  0.542857   \n",
       "rec-1016-org rec-1209-dup-0              1           0    1.000000  0.601190   \n",
       "             rec-2389-dup-0              1           0    1.000000  0.601190   \n",
       "...                                    ...         ...         ...       ...   \n",
       "rec-66-org   rec-987-dup-0               0           0    0.000000  0.403704   \n",
       "             rec-592-dup-0               0           0    0.466667  0.403704   \n",
       "             rec-2962-dup-0              0           0    0.447619  0.403704   \n",
       "             rec-852-dup-0               0           0    0.374074  0.403704   \n",
       "             rec-1156-dup-0              0           0    0.000000  0.403704   \n",
       "\n",
       "                             suburb_ph    suburb      postcode  state  \\\n",
       "rec_id_1     rec_id_2                                                   \n",
       "rec-1070-org rec-4233-dup-0          0  0.461538  0.000000e+00      1   \n",
       "             rec-3674-dup-0          0  0.461538  0.000000e+00      1   \n",
       "             rec-2473-dup-0          0  0.538462  0.000000e+00      1   \n",
       "rec-1016-org rec-1209-dup-0          0  0.222222  0.000000e+00      1   \n",
       "             rec-2389-dup-0          0  0.111111  2.430865e-63      1   \n",
       "...                                ...       ...           ...    ...   \n",
       "rec-66-org   rec-987-dup-0           0  0.250000  3.622272e-71      1   \n",
       "             rec-592-dup-0           0  0.083333  0.000000e+00      1   \n",
       "             rec-2962-dup-0          0  0.250000  1.686752e-80      1   \n",
       "             rec-852-dup-0           0  0.071429  0.000000e+00      1   \n",
       "             rec-1156-dup-0          0  0.083333  1.019579e-56      1   \n",
       "\n",
       "                             soc_sec_id  dob  \n",
       "rec_id_1     rec_id_2                         \n",
       "rec-1070-org rec-4233-dup-0         0.0  0.0  \n",
       "             rec-3674-dup-0         0.0  0.0  \n",
       "             rec-2473-dup-0         0.0  0.0  \n",
       "rec-1016-org rec-1209-dup-0         0.0  0.0  \n",
       "             rec-2389-dup-0         0.0  0.0  \n",
       "...                                 ...  ...  \n",
       "rec-66-org   rec-987-dup-0          0.0  0.0  \n",
       "             rec-592-dup-0          0.0  0.0  \n",
       "             rec-2962-dup-0         0.0  0.0  \n",
       "             rec-852-dup-0          0.0  0.0  \n",
       "             rec-1156-dup-0         0.0  0.0  \n",
       "\n",
       "[421590 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rec-1070-org</th>\n",
       "      <th>rec-4233-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3674-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2473-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713095</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rec-1016-org</th>\n",
       "      <th>rec-1209-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2389-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2.430865e-63</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rec-66-org</th>\n",
       "      <th>rec-987-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.622272e-71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-592-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2962-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.686752e-80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-852-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374074</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1156-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.019579e-56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421590 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:06.833997Z",
     "start_time": "2025-05-13T04:08:06.726743Z"
    }
   },
   "cell_type": "code",
   "source": "features_lsh.describe()",
   "id": "b11711dd76eb9c1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       given_name_ph     surname_ph     given_name        surname  suburb_ph  \\\n",
       "count  421590.000000  421590.000000  421590.000000  421590.000000   421590.0   \n",
       "mean        0.025098       0.026144       0.379960       0.417901        0.0   \n",
       "std         0.156423       0.159563       0.257153       0.120584        0.0   \n",
       "min         0.000000       0.000000       0.000000       0.000000        0.0   \n",
       "25%         0.000000       0.000000       0.000000       0.397222        0.0   \n",
       "50%         0.000000       0.000000       0.455556       0.438889        0.0   \n",
       "75%         0.000000       0.000000       0.539683       0.488889        0.0   \n",
       "max         1.000000       1.000000       1.000000       0.822222        0.0   \n",
       "\n",
       "              suburb       postcode          state     soc_sec_id  \\\n",
       "count  421590.000000   4.215900e+05  421590.000000  421590.000000   \n",
       "mean        0.151056   1.029839e-02       0.995754       0.008973   \n",
       "std         0.150471   9.743818e-02       0.065022       0.094292   \n",
       "min         0.000000   0.000000e+00       0.000000       0.000000   \n",
       "25%         0.076923   0.000000e+00       1.000000       0.000000   \n",
       "50%         0.125000   0.000000e+00       1.000000       0.000000   \n",
       "75%         0.200000  1.820884e-158       1.000000       0.000000   \n",
       "max         1.000000   1.000000e+00       1.000000       1.000000   \n",
       "\n",
       "                 dob  \n",
       "count  421590.000000  \n",
       "mean        0.008901  \n",
       "std         0.093895  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb_ph</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>dob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>421590.000000</td>\n",
       "      <td>421590.000000</td>\n",
       "      <td>421590.000000</td>\n",
       "      <td>421590.000000</td>\n",
       "      <td>421590.0</td>\n",
       "      <td>421590.000000</td>\n",
       "      <td>4.215900e+05</td>\n",
       "      <td>421590.000000</td>\n",
       "      <td>421590.000000</td>\n",
       "      <td>421590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025098</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.379960</td>\n",
       "      <td>0.417901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151056</td>\n",
       "      <td>1.029839e-02</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.008901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.156423</td>\n",
       "      <td>0.159563</td>\n",
       "      <td>0.257153</td>\n",
       "      <td>0.120584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150471</td>\n",
       "      <td>9.743818e-02</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.094292</td>\n",
       "      <td>0.093895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.438889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.820884e-158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Comparison Runtime Benchmarks:\n",
    "\n",
    "Time to run a comparison of two 5000 row datasets (see Appendix 1 for system info):\n",
    "\n",
    "- *Full Index*: 27m, 18s\n",
    "- *Exact-Match Blocking Index*: 5.5s\n",
    "- *LSH Blocking Index*: 25.1s\n",
    "\n"
   ],
   "id": "de7a68de3d4a84ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Classification\n",
    "\n",
    "The PRLT library includes the following classifiers that can be used to classify matches based on the features generated above:\n",
    "\n",
    "Supervised:\n",
    "\n",
    "- Logistic Regression Classifier\n",
    "- Naive Bayesian Classifier\n",
    "- Support Vector Machine (SVM) Classifier\n",
    "\n",
    "Unsupervised:\n",
    "\n",
    "- Expectation/Conditional Maximization (ECM) Classifier\n",
    "- KMeans Classifier\n",
    "\n",
    "### Unsupervised Classifiers"
   ],
   "id": "e45f5da9d7fdc7ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:08.756690Z",
     "start_time": "2025-05-13T04:08:06.913129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# k-means clustering using exact match blocking\n",
    "kmeans = recordlinkage.KMeansClassifier()\n",
    "result_kmeans = kmeans.fit_predict(features)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_kmeans, total=len(dfA.index))"
   ],
   "id": "59dc322633392bb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3693, 1307],\n",
       "       [   1,   -1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:08.892140Z",
     "start_time": "2025-05-13T04:08:08.881709Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_kmeans)",
   "id": "ef7f6c4b844712cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849551414768806"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:09.206048Z",
     "start_time": "2025-05-13T04:08:09.035015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# k-means clustering using LSH blocking\n",
    "kmeans = recordlinkage.KMeansClassifier()\n",
    "result_kmeans = kmeans.fit_predict(features_lsh)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_kmeans, total=len(dfA.index))"
   ],
   "id": "fc9919a9cbede0f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4143,  857],\n",
       "       [   1,   -1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:09.330268Z",
     "start_time": "2025-05-13T04:08:09.318835Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_kmeans)",
   "id": "2d9bf6e3572486ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9061679790026246"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:10.348487Z",
     "start_time": "2025-05-13T04:08:09.437368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ECM using exact blocking\n",
    "ecm = recordlinkage.ECMClassifier(binarize=0.8)\n",
    "result_ecm = ecm.fit_predict(features)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_ecm, total=len(dfA.index))"
   ],
   "id": "e2489b0db8512857",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3712, 1288],\n",
       "       [   5,   -5]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:10.400880Z",
     "start_time": "2025-05-13T04:08:10.388900Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_ecm)",
   "id": "53dfe0da77612d55",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516691522312723"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:14.516009Z",
     "start_time": "2025-05-13T04:08:10.479538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ECM using LSH blocking\n",
    "ecm = recordlinkage.ECMClassifier(binarize=0.8)\n",
    "result_ecm = ecm.fit_predict(features_lsh)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_ecm, total=len(dfA.index))"
   ],
   "id": "dff10a7ed5e4cfec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4158,  842],\n",
       "       [  60,  -60]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:14.567280Z",
     "start_time": "2025-05-13T04:08:14.556877Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_ecm)",
   "id": "d0e22621fba512b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9021479713603819"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The results above demonstrate that LSH provides better results than exact-match blocking when dealing with dirty data in the blocking set. However, classification performance is not great.\n",
    "\n",
    "### Supervised Classifiers\n"
   ],
   "id": "5252849d62ec40c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:15.942872Z",
     "start_time": "2025-05-13T04:08:14.657449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a training set by splitting data\n",
    "training_dfA = dfA[0:500]\n",
    "training_dfB = dfB[0:500]\n",
    "training_match_idx = miTrueLinks[miTrueLinks.get_level_values(0).isin(training_dfA.index)]\n",
    "\n",
    "# index training set using LSH\n",
    "training_pairs_lsh = indexer.index(training_dfA, training_dfB)\n",
    "\n",
    "# compare training data\n",
    "training_features_lsh = comparison.compute(pairs=training_pairs_lsh, x=training_dfA, x_link=training_dfB)\n",
    "\n",
    "#classify using Naive Bayes Classifier\n",
    "nbc = recordlinkage.NaiveBayesClassifier(binarize=0.8)\n",
    "nbc.fit(training_features_lsh, training_match_idx)\n",
    "result_nbc = nbc.predict(features_lsh)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_nbc, total=len(dfA.index))\n"
   ],
   "id": "e6fceaae5905eb4f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v_mar\\AppData\\Local\\Temp\\ipykernel_19868\\3317755455.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfA['minhash'] = dfA.apply(func=self._create_minhash, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfA: 0.3116633000317961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v_mar\\AppData\\Local\\Temp\\ipykernel_19868\\3317755455.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfB['minhash'] = dfB.apply(func=self._create_minhash, axis=1)\n",
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\recordlinkage\\algorithms\\string.py:56: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - levenshtein_distance(x[0], x[1]) / np.max([len(x[0]), len(x[1])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfB: 0.31231089995708317\n",
      "Seconds to build LSH of dfB: 0.03385699994396418\n",
      "Seconds to query dfB for each row of dfA: 0.03267500002402812\n",
      "Seconds to convert df to MultiIndex: 0.0014438999351114035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4160,  840],\n",
       "       [  77,  -77]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:15.992424Z",
     "start_time": "2025-05-13T04:08:15.982425Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_nbc)",
   "id": "409d1a35a5b9be7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9007253437263181"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:16.078611Z",
     "start_time": "2025-05-13T04:08:16.070841Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.precision(links_true=miTrueLinks, links_pred=result_nbc)",
   "id": "497226046bcab9e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.981826764219967"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:16.142879Z",
     "start_time": "2025-05-13T04:08:16.133617Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.recall(links_true=miTrueLinks, links_pred=result_nbc)",
   "id": "9f30b04290b4ced5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:16.220480Z",
     "start_time": "2025-05-13T04:08:16.177529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#classify using SVM\n",
    "svc = recordlinkage.SVMClassifier() # options --> ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’\n",
    "svc.fit(training_features_lsh, training_match_idx)\n",
    "result_svc = svc.predict(features_lsh)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=result_svc, total=len(dfA.index))"
   ],
   "id": "2ebc732bcb41e33d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4143,  857],\n",
       "       [   0,    0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:16.300611Z",
     "start_time": "2025-05-13T04:08:16.290198Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=result_svc)",
   "id": "9e353bfae1e64047",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9062670895767254"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Real World Case\n",
    "\n",
    "Identifying personnel involved in clinical trials is a real-world challenge. For companies that sell software to organizations that perform clinical trials, having consistent and correct information about the physicians involved in clinical trials provides real value to customers. Often the same investigators participate in many clinical trials across many trial sponsors, each of whom have their own record of the investigator. Matching and deduplicating these records represents a challenge that all vendors have.\n",
    "\n",
    "The United States government requires providers that participate in electronic transactions specified in HIPAA to register with the National Plan & Provider Enumeration System (NPPES). When they register, they are supplied with National Provider Identifier (NPI) number. The NPPES database is available for download as text files.\n",
    "\n",
    "The government also requires that clinical trials run in the United States be registered online at the ClinicalTrials.gov website. This registry contains information about trials once they are registered with the FDA. The database includes information about investigators that are currently enrolling patients in clinical trials. Snapshots of the database are available for download.\n",
    "\n",
    "Using the PRLT library, we will attempt to match investigators between these two databases.\n",
    "\n",
    "The ClinicalTrials.gov investigators list was generated by downloading a snapshot of a PostgreSQL database from the [Clinical Trials Transformation Initiative](https://aact.ctti-clinicaltrials.org/download)'s website. The snapshot downloaded was from 2025-04-30. Once downloaded, the database was restored to a local PostgreSQL 17 instance and was analyzed. The following query was used to generate a csv file used for this analysis.\n",
    "\n",
    "    select\n",
    "        b.name as full_name,\n",
    "        a.city as city,\n",
    "        a.state as state,\n",
    "        a.zip as postal_code,\n",
    "        a.country as country,\n",
    "        a.nct_id\n",
    "    from\n",
    "        ctgov.facilities a\n",
    "    inner join\n",
    "        ctgov.facility_investigators b\n",
    "            on a.id = b.facility_id;\n",
    "\n"
   ],
   "id": "72d64065953048f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:16.628709Z",
     "start_time": "2025-05-13T04:08:16.380649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfCTGov = pd.read_csv('data/ctgov_investigators.csv', dtype='str')\n",
    "dfCTGov = dfCTGov.drop(columns=['country'])\n",
    "dfCTGov.rename(columns={\"full_name\": \"long_name\", \"postal_code\": \"postcode\"},inplace=True)\n",
    "dfCTGov.index.name = 'rec_id'\n",
    "dfCTGov"
   ],
   "id": "42cd3ee5ce360eb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      long_name        city       state postcode       nct_id\n",
       "rec_id                                                                       \n",
       "0        Raymond Reding, MD-PhD    Brussels         NaN     1200  NCT02064777\n",
       "1       Vanessa Guy-Viterbo, MD    Brussels         NaN     1200  NCT02064777\n",
       "2         Athan BAILLET, MD, Pr    Grenoble         NaN      NaN  NCT03227419\n",
       "3          John M. Schallenkamp    Missoula     Montana    59804  NCT06422806\n",
       "4             Malcolm D. Mattes      Newark  New Jersey    07101  NCT05172245\n",
       "...                         ...         ...         ...      ...          ...\n",
       "196585     Bethany Walker, CRNP  Birmingham     Alabama    35233  NCT02418442\n",
       "196586        Carolyn Smith, RN  Birmingham     Alabama    35233  NCT02418442\n",
       "196587          Eileen Rife, MD  Birmingham     Alabama    35233  NCT02418442\n",
       "196588  Sven Möbius-Winkler, MD     Leipzig         NaN    04289  NCT00176358\n",
       "196589      Claudia Walther, MD     Leipzig         NaN    04289  NCT00176358\n",
       "\n",
       "[196590 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>nct_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raymond Reding, MD-PhD</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>NCT02064777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vanessa Guy-Viterbo, MD</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200</td>\n",
       "      <td>NCT02064777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athan BAILLET, MD, Pr</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCT03227419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John M. Schallenkamp</td>\n",
       "      <td>Missoula</td>\n",
       "      <td>Montana</td>\n",
       "      <td>59804</td>\n",
       "      <td>NCT06422806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malcolm D. Mattes</td>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>07101</td>\n",
       "      <td>NCT05172245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196585</th>\n",
       "      <td>Bethany Walker, CRNP</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>35233</td>\n",
       "      <td>NCT02418442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196586</th>\n",
       "      <td>Carolyn Smith, RN</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>35233</td>\n",
       "      <td>NCT02418442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196587</th>\n",
       "      <td>Eileen Rife, MD</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>35233</td>\n",
       "      <td>NCT02418442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196588</th>\n",
       "      <td>Sven Möbius-Winkler, MD</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04289</td>\n",
       "      <td>NCT00176358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196589</th>\n",
       "      <td>Claudia Walther, MD</td>\n",
       "      <td>Leipzig</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04289</td>\n",
       "      <td>NCT00176358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196590 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The list of NPI investigators was generated by downloading NPI files from the [Centers fo Medicare & Medicaid Services website](https://download.cms.gov/nppes/NPI_Files.html). The file downloaded was the [Monthly NPPES Downloadable File Version 2 (April 14.2025)](https://download.cms.gov/nppes/NPPES_Data_Dissemination_April_2025_V2.zip). It was a very large file (~10GB), so the first 1000 rows was loaded as a Pandas Dataframe in order to understand it better.\n",
    "\n",
    "    dfNPI = pd.read_csv(\"npidata_pfile_20050523-20250413.csv\",nrows=1000)\n",
    "    cols = dfNPI.columns.tolist()\n",
    "\n",
    "This yielded 330 columns, of which the following were selected for use in further filtering and/or matching:\n",
    "\n",
    "    cols = ['NPI', 'Entity Type Code', 'Replacement NPI', 'Employer Identification Number (EIN)', 'Provider Organization Name (Legal Business Name)', 'Provider Last Name (Legal Name)', 'Provider First Name', 'Provider Middle Name', 'Provider Name Prefix Text', 'Provider Name Suffix Text', 'Provider Credential Text', 'Provider First Line Business Mailing Address', 'Provider Second Line Business Mailing Address', 'Provider Business Mailing Address City Name', 'Provider Business Mailing Address State Name', 'Provider Business Mailing Address Postal Code', 'Provider Business Mailing Address Country Code (If outside U.S.)', 'Provider Enumeration Date', 'Last Update Date', 'NPI Deactivation Reason Code', 'NPI Deactivation Date', 'NPI Reactivation Date']\n",
    "\n",
    "Using this list, all data was loaded:\n",
    "\n",
    "    dfNPI = pd.read_csv(\"npidata_pfile_20050523-20250413.csv\",usecols=cols)\n",
    "\n",
    "This yielded an 8.8M row dataset. To further reduce the size of the dataset, the following processing steps were applied:\n",
    "\n",
    "    # removed deactived entries\n",
    "    dfNPI = dfNPI[dfNPI['NPI Deactivation Date'].isna()]\n",
    "\n",
    "    # remove orgnization entries by restricting to type code 1\n",
    "    dfNPI = dfNPI[dfNPI['Entity Type Code'] == 1]\n",
    "\n",
    "    # process credentials to restrict to only physians (MD or DO)\n",
    "    dfNPI['creds'] = dfNPI['Provider Credential Text'].str.replace('.','')\n",
    "    dfNPI = dfNPI[(dfNPI['creds'].str.contains('md', case=False, na=False) | dfNPI['creds'].str.contains('do', case=False, na=False))\n",
    "                                               & ~dfNPI['creds'].str.contains('pharmd', case=False, na=False)]\n",
    "\n",
    "This reduced the file down to 1.3M rows. Column names that were to be used for processing were aligned with the column names used through this project and the dataset was trimmed further so that only the columns that matched the columns available from the CTGov sight were extracted and saved into a new CSV file.\n",
    "\n",
    "    dfNPI = dfNPI.rename(columns={'Provider Last Name (Legal Name)': 'surname', 'Provider First Name':'given_name', 'Provider Business Mailing Address City Name': 'city', 'Provider Business Mailing Address State Name': 'state', 'Provider Business Mailing Address Postal Code': 'postcode', 'NPI': 'npi' })\n",
    "    dfNPI.to_csv('data/npi_investigators.csv', columns=['given_name', 'surname', 'city', 'state', 'postcode', 'npi'], index=False, header=True)\n",
    "\n",
    "*NOTE: Code is included for completeness but files were too large to include as part of notebook*\n",
    "\n"
   ],
   "id": "e7522aee9f60f4be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:18.338666Z",
     "start_time": "2025-05-13T04:08:16.668747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfNPI = pd.read_csv('data/npi_investigators.csv', dtype='str')\n",
    "dfNPI['postcode'] = dfNPI['postcode'].str.replace('.0','',regex=False)\n",
    "dfNPI.index.name = 'rec_id'\n",
    "dfNPI"
   ],
   "id": "4b66f98dbafb3ff2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        given_name     surname          city state   postcode         npi\n",
       "rec_id                                                                   \n",
       "0            DAVID       WIEBE       KEARNEY    NE  688482168  1679576722\n",
       "1          WILLIAM     PILCHER  JACKSONVILLE    FL  322044736  1588667638\n",
       "2          LAURENT     GRESSOT       HOUSTON    TX  770901243  1215930367\n",
       "3             RAVI  ADUSUMILLI        TOLEDO    OH  436151753  1932102084\n",
       "4           ROBERT      BISBEE       LUBBOCK    TX  794073537  1750384806\n",
       "...            ...         ...           ...   ...        ...         ...\n",
       "1319114     ARMEND   BALIDEMAJ         BRONX    NY  104611197  1952196685\n",
       "1319115  ALEXANDER          LE    SUGAR LAND    TX  774786156  1770378408\n",
       "1319116       JAKE    HUNSAKER   GAINESVILLE    FL  326100254  1689469314\n",
       "1319117       ZAIN      MAJEED    SCOTTSDALE    AZ  852554866  1124813852\n",
       "1319118   SAMANTHA      BOEVER       GILBERT    AZ  852954874  1396530028\n",
       "\n",
       "[1319119 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>npi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>WIEBE</td>\n",
       "      <td>KEARNEY</td>\n",
       "      <td>NE</td>\n",
       "      <td>688482168</td>\n",
       "      <td>1679576722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>PILCHER</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "      <td>FL</td>\n",
       "      <td>322044736</td>\n",
       "      <td>1588667638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAURENT</td>\n",
       "      <td>GRESSOT</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TX</td>\n",
       "      <td>770901243</td>\n",
       "      <td>1215930367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAVI</td>\n",
       "      <td>ADUSUMILLI</td>\n",
       "      <td>TOLEDO</td>\n",
       "      <td>OH</td>\n",
       "      <td>436151753</td>\n",
       "      <td>1932102084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>BISBEE</td>\n",
       "      <td>LUBBOCK</td>\n",
       "      <td>TX</td>\n",
       "      <td>794073537</td>\n",
       "      <td>1750384806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319114</th>\n",
       "      <td>ARMEND</td>\n",
       "      <td>BALIDEMAJ</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NY</td>\n",
       "      <td>104611197</td>\n",
       "      <td>1952196685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319115</th>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>LE</td>\n",
       "      <td>SUGAR LAND</td>\n",
       "      <td>TX</td>\n",
       "      <td>774786156</td>\n",
       "      <td>1770378408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319116</th>\n",
       "      <td>JAKE</td>\n",
       "      <td>HUNSAKER</td>\n",
       "      <td>GAINESVILLE</td>\n",
       "      <td>FL</td>\n",
       "      <td>326100254</td>\n",
       "      <td>1689469314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319117</th>\n",
       "      <td>ZAIN</td>\n",
       "      <td>MAJEED</td>\n",
       "      <td>SCOTTSDALE</td>\n",
       "      <td>AZ</td>\n",
       "      <td>852554866</td>\n",
       "      <td>1124813852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319118</th>\n",
       "      <td>SAMANTHA</td>\n",
       "      <td>BOEVER</td>\n",
       "      <td>GILBERT</td>\n",
       "      <td>AZ</td>\n",
       "      <td>852954874</td>\n",
       "      <td>1396530028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319119 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will use the two 5000 record FEBRL datasets as training datasets and will use the CTGov and NPI datasets as our unknowns and will follow the same steps (Preprocessing, Indexing, Comparison, Classification).\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Since the ClinicalTrials.gov name field only stores a full name with middle initials and titles at the beginning and end of the name, we needed to use bespoke library called [Nameparser](https://nameparser.readthedocs.io/en/latest/index.html) for name parsing. This was necessary in order to properly split the names into first last and full, which is just first and last."
   ],
   "id": "d1ad259df08ddb9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:42.092134Z",
     "start_time": "2025-05-13T04:08:18.369851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# force strings to upper case\n",
    "dfCTGov = dfCTGov.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "# create given_name and surname fields from full_name\n",
    "dfCTGov['long_name'] = dfCTGov['long_name'].fillna('')\n",
    "\n",
    "constants = Constants()\n",
    "constants.titles.add(\"MD-PhD\",'pr','msc','otd','msci','b.a.')\n",
    "constants.suffix_acronyms.add(\"MD-PhD\",'pr','msc','otd','msci','b.a.')\n",
    "\n",
    "def parse_full_name(long_name):\n",
    "    name_obj = HumanName(long_name,constants=constants)\n",
    "    if len(name_obj.first) > 0 and len(name_obj.last) > 0:\n",
    "        full_name = name_obj.first + ' ' + name_obj.last\n",
    "    elif len(name_obj.first) == 0 and len(name_obj.last) > 0:\n",
    "        full_name = name_obj.last\n",
    "    else:\n",
    "        full_name = name_obj.first\n",
    "    return name_obj.first, name_obj.last, full_name\n",
    "\n",
    "dfCTGov[['given_name','surname', 'full_name']] = dfCTGov['long_name'].apply(lambda x: pd.Series(parse_full_name(x)))\n",
    "\n",
    "# process name fields phonetically\n",
    "dfCTGov['given_name_ph'] = phonetic(dfCTGov['given_name'],method='metaphone',decode_error='replace')\n",
    "dfCTGov['surname_ph'] = phonetic(dfCTGov['surname'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# process city phonetically\n",
    "dfCTGov[['city', 'state']] = dfCTGov[['city', 'state']].fillna('')\n",
    "dfCTGov['city_ph'] = phonetic(dfCTGov['city'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# replace nans in postcode and convert to int\n",
    "dfCTGov['postcode'] = dfCTGov['postcode'].fillna('0')\n",
    "dfCTGov['postcode_int'] = pd.to_numeric(dfCTGov['postcode'],errors='coerce')\n",
    "dfCTGov['postcode_int'] = dfCTGov['postcode_int'].fillna(0)\n",
    "\n",
    "# build text column\n",
    "dfCTGov['text'] = dfCTGov['full_name'] + ' ' + dfCTGov['city'] + ' ' + dfCTGov['state']\n",
    "\n",
    "dfCTGov"
   ],
   "id": "3a71eabde6a5d33a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v_mar\\AppData\\Local\\Temp\\ipykernel_19868\\2904586972.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  dfCTGov = dfCTGov.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                      long_name        city       state postcode       nct_id  \\\n",
       "rec_id                                                                          \n",
       "0        RAYMOND REDING, MD-PHD    BRUSSELS                 1200  NCT02064777   \n",
       "1       VANESSA GUY-VITERBO, MD    BRUSSELS                 1200  NCT02064777   \n",
       "2         ATHAN BAILLET, MD, PR    GRENOBLE                    0  NCT03227419   \n",
       "3          JOHN M. SCHALLENKAMP    MISSOULA     MONTANA    59804  NCT06422806   \n",
       "4             MALCOLM D. MATTES      NEWARK  NEW JERSEY    07101  NCT05172245   \n",
       "...                         ...         ...         ...      ...          ...   \n",
       "196585     BETHANY WALKER, CRNP  BIRMINGHAM     ALABAMA    35233  NCT02418442   \n",
       "196586        CAROLYN SMITH, RN  BIRMINGHAM     ALABAMA    35233  NCT02418442   \n",
       "196587          EILEEN RIFE, MD  BIRMINGHAM     ALABAMA    35233  NCT02418442   \n",
       "196588  SVEN MÖBIUS-WINKLER, MD     LEIPZIG                04289  NCT00176358   \n",
       "196589      CLAUDIA WALTHER, MD     LEIPZIG                04289  NCT00176358   \n",
       "\n",
       "       given_name         surname            full_name given_name_ph  \\\n",
       "rec_id                                                                 \n",
       "0         RAYMOND          REDING       RAYMOND REDING          RMNT   \n",
       "1         VANESSA     GUY-VITERBO  VANESSA GUY-VITERBO           FNS   \n",
       "2           ATHAN         BAILLET        ATHAN BAILLET           A0N   \n",
       "3            JOHN    SCHALLENKAMP    JOHN SCHALLENKAMP            JN   \n",
       "4         MALCOLM          MATTES       MALCOLM MATTES         MLKLM   \n",
       "...           ...             ...                  ...           ...   \n",
       "196585       CRNP  BETHANY WALKER  CRNP BETHANY WALKER          KRNP   \n",
       "196586    CAROLYN           SMITH        CAROLYN SMITH          KRLN   \n",
       "196587     EILEEN            RIFE          EILEEN RIFE           ELN   \n",
       "196588       SVEN  MÖBIUS-WINKLER  SVEN MÖBIUS-WINKLER           SFN   \n",
       "196589    CLAUDIA         WALTHER      CLAUDIA WALTHER           KLT   \n",
       "\n",
       "       surname_ph  city_ph  postcode_int  \\\n",
       "rec_id                                     \n",
       "0            RTNK    BRSLS        1200.0   \n",
       "1           KFTRB    BRSLS        1200.0   \n",
       "2             BLT    KRNBL           0.0   \n",
       "3         SXLNKMP      MSL       59804.0   \n",
       "4             MTS     NWRK        7101.0   \n",
       "...           ...      ...           ...   \n",
       "196585    B0NWLKR  BRMNKHM       35233.0   \n",
       "196586        SM0  BRMNKHM       35233.0   \n",
       "196587         RF  BRMNKHM       35233.0   \n",
       "196588   MBSWNKLR     LPSK        4289.0   \n",
       "196589       WL0R     LPSK        4289.0   \n",
       "\n",
       "                                          text  \n",
       "rec_id                                          \n",
       "0                     RAYMOND REDING BRUSSELS   \n",
       "1                VANESSA GUY-VITERBO BRUSSELS   \n",
       "2                      ATHAN BAILLET GRENOBLE   \n",
       "3           JOHN SCHALLENKAMP MISSOULA MONTANA  \n",
       "4             MALCOLM MATTES NEWARK NEW JERSEY  \n",
       "...                                        ...  \n",
       "196585  CRNP BETHANY WALKER BIRMINGHAM ALABAMA  \n",
       "196586        CAROLYN SMITH BIRMINGHAM ALABAMA  \n",
       "196587          EILEEN RIFE BIRMINGHAM ALABAMA  \n",
       "196588            SVEN MÖBIUS-WINKLER LEIPZIG   \n",
       "196589                CLAUDIA WALTHER LEIPZIG   \n",
       "\n",
       "[196590 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>full_name</th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>postcode_int</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAYMOND REDING, MD-PHD</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td></td>\n",
       "      <td>1200</td>\n",
       "      <td>NCT02064777</td>\n",
       "      <td>RAYMOND</td>\n",
       "      <td>REDING</td>\n",
       "      <td>RAYMOND REDING</td>\n",
       "      <td>RMNT</td>\n",
       "      <td>RTNK</td>\n",
       "      <td>BRSLS</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>RAYMOND REDING BRUSSELS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VANESSA GUY-VITERBO, MD</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td></td>\n",
       "      <td>1200</td>\n",
       "      <td>NCT02064777</td>\n",
       "      <td>VANESSA</td>\n",
       "      <td>GUY-VITERBO</td>\n",
       "      <td>VANESSA GUY-VITERBO</td>\n",
       "      <td>FNS</td>\n",
       "      <td>KFTRB</td>\n",
       "      <td>BRSLS</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>VANESSA GUY-VITERBO BRUSSELS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATHAN BAILLET, MD, PR</td>\n",
       "      <td>GRENOBLE</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NCT03227419</td>\n",
       "      <td>ATHAN</td>\n",
       "      <td>BAILLET</td>\n",
       "      <td>ATHAN BAILLET</td>\n",
       "      <td>A0N</td>\n",
       "      <td>BLT</td>\n",
       "      <td>KRNBL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATHAN BAILLET GRENOBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOHN M. SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>JOHN SCHALLENKAMP</td>\n",
       "      <td>JN</td>\n",
       "      <td>SXLNKMP</td>\n",
       "      <td>MSL</td>\n",
       "      <td>59804.0</td>\n",
       "      <td>JOHN SCHALLENKAMP MISSOULA MONTANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MALCOLM D. MATTES</td>\n",
       "      <td>NEWARK</td>\n",
       "      <td>NEW JERSEY</td>\n",
       "      <td>07101</td>\n",
       "      <td>NCT05172245</td>\n",
       "      <td>MALCOLM</td>\n",
       "      <td>MATTES</td>\n",
       "      <td>MALCOLM MATTES</td>\n",
       "      <td>MLKLM</td>\n",
       "      <td>MTS</td>\n",
       "      <td>NWRK</td>\n",
       "      <td>7101.0</td>\n",
       "      <td>MALCOLM MATTES NEWARK NEW JERSEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196585</th>\n",
       "      <td>BETHANY WALKER, CRNP</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>CRNP</td>\n",
       "      <td>BETHANY WALKER</td>\n",
       "      <td>CRNP BETHANY WALKER</td>\n",
       "      <td>KRNP</td>\n",
       "      <td>B0NWLKR</td>\n",
       "      <td>BRMNKHM</td>\n",
       "      <td>35233.0</td>\n",
       "      <td>CRNP BETHANY WALKER BIRMINGHAM ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196586</th>\n",
       "      <td>CAROLYN SMITH, RN</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>CAROLYN</td>\n",
       "      <td>SMITH</td>\n",
       "      <td>CAROLYN SMITH</td>\n",
       "      <td>KRLN</td>\n",
       "      <td>SM0</td>\n",
       "      <td>BRMNKHM</td>\n",
       "      <td>35233.0</td>\n",
       "      <td>CAROLYN SMITH BIRMINGHAM ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196587</th>\n",
       "      <td>EILEEN RIFE, MD</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>EILEEN RIFE</td>\n",
       "      <td>ELN</td>\n",
       "      <td>RF</td>\n",
       "      <td>BRMNKHM</td>\n",
       "      <td>35233.0</td>\n",
       "      <td>EILEEN RIFE BIRMINGHAM ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196588</th>\n",
       "      <td>SVEN MÖBIUS-WINKLER, MD</td>\n",
       "      <td>LEIPZIG</td>\n",
       "      <td></td>\n",
       "      <td>04289</td>\n",
       "      <td>NCT00176358</td>\n",
       "      <td>SVEN</td>\n",
       "      <td>MÖBIUS-WINKLER</td>\n",
       "      <td>SVEN MÖBIUS-WINKLER</td>\n",
       "      <td>SFN</td>\n",
       "      <td>MBSWNKLR</td>\n",
       "      <td>LPSK</td>\n",
       "      <td>4289.0</td>\n",
       "      <td>SVEN MÖBIUS-WINKLER LEIPZIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196589</th>\n",
       "      <td>CLAUDIA WALTHER, MD</td>\n",
       "      <td>LEIPZIG</td>\n",
       "      <td></td>\n",
       "      <td>04289</td>\n",
       "      <td>NCT00176358</td>\n",
       "      <td>CLAUDIA</td>\n",
       "      <td>WALTHER</td>\n",
       "      <td>CLAUDIA WALTHER</td>\n",
       "      <td>KLT</td>\n",
       "      <td>WL0R</td>\n",
       "      <td>LPSK</td>\n",
       "      <td>4289.0</td>\n",
       "      <td>CLAUDIA WALTHER LEIPZIG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196590 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Processing of the NPI dataset is very similar to the processing of the FEBRL datasets used for training.",
   "id": "6967bde84e5a7bbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:08:54.422017Z",
     "start_time": "2025-05-13T04:08:42.128594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create given_name and surname fields from full_name\n",
    "dfNPI['full_name'] = dfNPI['given_name'] + ' ' + dfNPI['surname']\n",
    "dfNPI['full_name'] = dfNPI['full_name'].str.strip()\n",
    "dfNPI['full_name'] = dfNPI['full_name'].fillna('')\n",
    "\n",
    "# process name fields phonetically\n",
    "dfNPI[['given_name', 'surname']] = dfNPI[['given_name', 'surname']].fillna('')\n",
    "dfNPI['given_name_ph'] = phonetic(dfNPI['given_name'],method='metaphone',decode_error='replace')\n",
    "dfNPI['surname_ph'] = phonetic(dfNPI['surname'],method='metaphone',decode_error='replace')\n",
    "\n",
    "# process city phonetically\n",
    "dfNPI[['city', 'state']] = dfNPI[['city', 'state']].fillna('')\n",
    "dfNPI['city_ph'] = phonetic(dfNPI['city'],method='metaphone',decode_error='replace')\n",
    "def convert_abbr_to_name(input):\n",
    "    state = us.states.lookup(input)\n",
    "    return state.name.upper() if state else input\n",
    "dfNPI['state'] = dfNPI['state'].apply(convert_abbr_to_name)\n",
    "\n",
    "# replace nans in postcode and convert to int\n",
    "dfNPI['postcode'] = dfNPI['postcode'].fillna('0')\n",
    "dfNPI['postcode'] = dfNPI['postcode'].str[:5]  # take the first 5 for US matches\n",
    "dfNPI['postcode_int'] = pd.to_numeric(dfNPI['postcode'],errors='coerce')\n",
    "dfNPI['postcode_int'] = dfNPI['postcode_int'].fillna(0)\n",
    "\n",
    "# build text column\n",
    "dfNPI['text'] = dfNPI['full_name'] + ' ' + dfNPI['city'] + ' ' + dfNPI['state']\n",
    "\n",
    "dfNPI"
   ],
   "id": "5ddebab67961d23b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        given_name     surname          city     state postcode         npi  \\\n",
       "rec_id                                                                        \n",
       "0            DAVID       WIEBE       KEARNEY  NEBRASKA    68848  1679576722   \n",
       "1          WILLIAM     PILCHER  JACKSONVILLE   FLORIDA    32204  1588667638   \n",
       "2          LAURENT     GRESSOT       HOUSTON     TEXAS    77090  1215930367   \n",
       "3             RAVI  ADUSUMILLI        TOLEDO      OHIO    43615  1932102084   \n",
       "4           ROBERT      BISBEE       LUBBOCK     TEXAS    79407  1750384806   \n",
       "...            ...         ...           ...       ...      ...         ...   \n",
       "1319114     ARMEND   BALIDEMAJ         BRONX  NEW YORK    10461  1952196685   \n",
       "1319115  ALEXANDER          LE    SUGAR LAND     TEXAS    77478  1770378408   \n",
       "1319116       JAKE    HUNSAKER   GAINESVILLE   FLORIDA    32610  1689469314   \n",
       "1319117       ZAIN      MAJEED    SCOTTSDALE   ARIZONA    85255  1124813852   \n",
       "1319118   SAMANTHA      BOEVER       GILBERT   ARIZONA    85295  1396530028   \n",
       "\n",
       "                full_name given_name_ph surname_ph city_ph  postcode_int  \\\n",
       "rec_id                                                                     \n",
       "0             DAVID WIEBE           TFT         WB     KRN       68848.0   \n",
       "1         WILLIAM PILCHER           WLM       PLXR  JKSNFL       32204.0   \n",
       "2         LAURENT GRESSOT          LRNT       KRST    HSTN       77090.0   \n",
       "3         RAVI ADUSUMILLI            RF      ATSML     TLT       43615.0   \n",
       "4           ROBERT BISBEE          RBRT        BSB     LBK       79407.0   \n",
       "...                   ...           ...        ...     ...           ...   \n",
       "1319114  ARMEND BALIDEMAJ         ARMNT      BLTMJ   BRNKS       10461.0   \n",
       "1319115      ALEXANDER LE       ALKSNTR          L  SKRLNT       77478.0   \n",
       "1319116     JAKE HUNSAKER            JK      HNSKR   KNSFL       32610.0   \n",
       "1319117       ZAIN MAJEED            SN        MJT  SKTSTL       85255.0   \n",
       "1319118   SAMANTHA BOEVER          SMN0        BFR   JLBRT       85295.0   \n",
       "\n",
       "                                         text  \n",
       "rec_id                                         \n",
       "0                DAVID WIEBE KEARNEY NEBRASKA  \n",
       "1        WILLIAM PILCHER JACKSONVILLE FLORIDA  \n",
       "2               LAURENT GRESSOT HOUSTON TEXAS  \n",
       "3                 RAVI ADUSUMILLI TOLEDO OHIO  \n",
       "4                 ROBERT BISBEE LUBBOCK TEXAS  \n",
       "...                                       ...  \n",
       "1319114       ARMEND BALIDEMAJ BRONX NEW YORK  \n",
       "1319115         ALEXANDER LE SUGAR LAND TEXAS  \n",
       "1319116     JAKE HUNSAKER GAINESVILLE FLORIDA  \n",
       "1319117        ZAIN MAJEED SCOTTSDALE ARIZONA  \n",
       "1319118       SAMANTHA BOEVER GILBERT ARIZONA  \n",
       "\n",
       "[1319119 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postcode</th>\n",
       "      <th>npi</th>\n",
       "      <th>full_name</th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>postcode_int</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DAVID</td>\n",
       "      <td>WIEBE</td>\n",
       "      <td>KEARNEY</td>\n",
       "      <td>NEBRASKA</td>\n",
       "      <td>68848</td>\n",
       "      <td>1679576722</td>\n",
       "      <td>DAVID WIEBE</td>\n",
       "      <td>TFT</td>\n",
       "      <td>WB</td>\n",
       "      <td>KRN</td>\n",
       "      <td>68848.0</td>\n",
       "      <td>DAVID WIEBE KEARNEY NEBRASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>PILCHER</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>32204</td>\n",
       "      <td>1588667638</td>\n",
       "      <td>WILLIAM PILCHER</td>\n",
       "      <td>WLM</td>\n",
       "      <td>PLXR</td>\n",
       "      <td>JKSNFL</td>\n",
       "      <td>32204.0</td>\n",
       "      <td>WILLIAM PILCHER JACKSONVILLE FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAURENT</td>\n",
       "      <td>GRESSOT</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77090</td>\n",
       "      <td>1215930367</td>\n",
       "      <td>LAURENT GRESSOT</td>\n",
       "      <td>LRNT</td>\n",
       "      <td>KRST</td>\n",
       "      <td>HSTN</td>\n",
       "      <td>77090.0</td>\n",
       "      <td>LAURENT GRESSOT HOUSTON TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAVI</td>\n",
       "      <td>ADUSUMILLI</td>\n",
       "      <td>TOLEDO</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>43615</td>\n",
       "      <td>1932102084</td>\n",
       "      <td>RAVI ADUSUMILLI</td>\n",
       "      <td>RF</td>\n",
       "      <td>ATSML</td>\n",
       "      <td>TLT</td>\n",
       "      <td>43615.0</td>\n",
       "      <td>RAVI ADUSUMILLI TOLEDO OHIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>BISBEE</td>\n",
       "      <td>LUBBOCK</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>79407</td>\n",
       "      <td>1750384806</td>\n",
       "      <td>ROBERT BISBEE</td>\n",
       "      <td>RBRT</td>\n",
       "      <td>BSB</td>\n",
       "      <td>LBK</td>\n",
       "      <td>79407.0</td>\n",
       "      <td>ROBERT BISBEE LUBBOCK TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319114</th>\n",
       "      <td>ARMEND</td>\n",
       "      <td>BALIDEMAJ</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>10461</td>\n",
       "      <td>1952196685</td>\n",
       "      <td>ARMEND BALIDEMAJ</td>\n",
       "      <td>ARMNT</td>\n",
       "      <td>BLTMJ</td>\n",
       "      <td>BRNKS</td>\n",
       "      <td>10461.0</td>\n",
       "      <td>ARMEND BALIDEMAJ BRONX NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319115</th>\n",
       "      <td>ALEXANDER</td>\n",
       "      <td>LE</td>\n",
       "      <td>SUGAR LAND</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>77478</td>\n",
       "      <td>1770378408</td>\n",
       "      <td>ALEXANDER LE</td>\n",
       "      <td>ALKSNTR</td>\n",
       "      <td>L</td>\n",
       "      <td>SKRLNT</td>\n",
       "      <td>77478.0</td>\n",
       "      <td>ALEXANDER LE SUGAR LAND TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319116</th>\n",
       "      <td>JAKE</td>\n",
       "      <td>HUNSAKER</td>\n",
       "      <td>GAINESVILLE</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>32610</td>\n",
       "      <td>1689469314</td>\n",
       "      <td>JAKE HUNSAKER</td>\n",
       "      <td>JK</td>\n",
       "      <td>HNSKR</td>\n",
       "      <td>KNSFL</td>\n",
       "      <td>32610.0</td>\n",
       "      <td>JAKE HUNSAKER GAINESVILLE FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319117</th>\n",
       "      <td>ZAIN</td>\n",
       "      <td>MAJEED</td>\n",
       "      <td>SCOTTSDALE</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>85255</td>\n",
       "      <td>1124813852</td>\n",
       "      <td>ZAIN MAJEED</td>\n",
       "      <td>SN</td>\n",
       "      <td>MJT</td>\n",
       "      <td>SKTSTL</td>\n",
       "      <td>85255.0</td>\n",
       "      <td>ZAIN MAJEED SCOTTSDALE ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319118</th>\n",
       "      <td>SAMANTHA</td>\n",
       "      <td>BOEVER</td>\n",
       "      <td>GILBERT</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>85295</td>\n",
       "      <td>1396530028</td>\n",
       "      <td>SAMANTHA BOEVER</td>\n",
       "      <td>SMN0</td>\n",
       "      <td>BFR</td>\n",
       "      <td>JLBRT</td>\n",
       "      <td>85295.0</td>\n",
       "      <td>SAMANTHA BOEVER GILBERT ARIZONA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319119 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Indexing\n",
    "\n",
    "In this step, we will rely on LSH Blocking of the `full_name` field as it has consistently delivered better performance than exact match"
   ],
   "id": "a00919e9ea18da95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:29:14.767404Z",
     "start_time": "2025-05-13T04:08:54.454452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indexer = LSHIndex(column='text', threshold=0.5, num_perm=64, tokenizer='words')\n",
    "pairs_lsh_unknowns = indexer.index(dfCTGov, dfNPI)\n",
    "pairs_lsh_unknowns\n",
    "# indexer = recordlinkage.Index()\n",
    "# indexer.block(left_on='surname_ph', right_on='surname_ph')\n",
    "# pairs_unknowns = indexer.index(dfCTGov, dfNPI)\n",
    "# pairs_unknowns"
   ],
   "id": "882013987cff31c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds to compute minhash dfA: 118.57447280001361\n",
      "Seconds to compute minhash dfB: 817.7580369999632\n",
      "Seconds to build LSH of dfB: 112.41691440006252\n",
      "Seconds to query dfB for each row of dfA: 146.62820700008888\n",
      "Seconds to convert df to MultiIndex: 7.7093534000450745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([(     3,  294912),\n",
       "            (     3,  329728),\n",
       "            (     3,  388097),\n",
       "            (     3,  304132),\n",
       "            (     3,   36357),\n",
       "            (     3,  412676),\n",
       "            (     3,  527879),\n",
       "            (     3,  252936),\n",
       "            (     3,   73225),\n",
       "            (     3,  647175),\n",
       "            ...\n",
       "            (196587,  884678),\n",
       "            (196587, 1073098),\n",
       "            (196587, 1253328),\n",
       "            (196587,  532444),\n",
       "            (196587,  868318),\n",
       "            (196587,   73705),\n",
       "            (196587,   98281),\n",
       "            (196587,  253930),\n",
       "            (196587,  868333),\n",
       "            (196587,  819198)],\n",
       "           names=['rec_id_1', 'rec_id_2'], length=114114070)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:29:14.929505Z",
     "start_time": "2025-05-13T04:29:14.922175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pairs_lsh_unknowns.rename(['dfA_rec_id', 'dfB_rec_id'], inplace=True)\n",
    "pairs_lsh_unknowns"
   ],
   "id": "392ecdea3187f42e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(     3,  294912),\n",
       "            (     3,  329728),\n",
       "            (     3,  388097),\n",
       "            (     3,  304132),\n",
       "            (     3,   36357),\n",
       "            (     3,  412676),\n",
       "            (     3,  527879),\n",
       "            (     3,  252936),\n",
       "            (     3,   73225),\n",
       "            (     3,  647175),\n",
       "            ...\n",
       "            (196587,  884678),\n",
       "            (196587, 1073098),\n",
       "            (196587, 1253328),\n",
       "            (196587,  532444),\n",
       "            (196587,  868318),\n",
       "            (196587,   73705),\n",
       "            (196587,   98281),\n",
       "            (196587,  253930),\n",
       "            (196587,  868333),\n",
       "            (196587,  819198)],\n",
       "           names=['dfA_rec_id', 'dfB_rec_id'], length=114114070)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The generation of the above MultiIndex takes about 25m on the reference system described in Appendix 1, so we'll persist it to disk so that we have the option of skipping this step if we choose to on subsequent runs.",
   "id": "ec14e82173072c90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:35:23.776255Z",
     "start_time": "2025-05-13T04:29:14.948512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_multiindex = pairs_lsh_unknowns.to_frame()\n",
    "df_multiindex.to_csv('data/pairs_lsh_unknowns.csv')\n",
    "# df_multiindex = pd.read_csv('data/pairs_lsh_unknowns.csv')\n",
    "# pairs_lsh_unknowns = pd.MultiIndex.from_frame(df_multiindex)"
   ],
   "id": "9fe491d82ba4e91f",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparison\n",
    "\n",
    "Here, we will use the same comparison algorithms but will need to eliminate a few columns that we do not have data for."
   ],
   "id": "e2144e1337943c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:52:57.844260Z",
     "start_time": "2025-05-13T04:35:23.872136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comp_ctgov_npi = recordlinkage.Compare()\n",
    "comp_ctgov_npi.exact(left_on=\"given_name_ph\", right_on=\"given_name_ph\", label=\"given_name_ph\")\n",
    "comp_ctgov_npi.exact(left_on=\"surname_ph\", right_on=\"surname_ph\", label=\"surname_ph\")\n",
    "comp_ctgov_npi.string(left_on=\"given_name\", right_on=\"given_name\", method='jarowinkler', label='given_name')\n",
    "comp_ctgov_npi.string(left_on=\"surname\", right_on=\"state\", method='jarowinkler', label='surname')\n",
    "comp_ctgov_npi.exact(left_on=\"city_ph\", right_on=\"city_ph\", label='city_ph')\n",
    "comp_ctgov_npi.string(left_on=\"city\", right_on=\"city\", label='city')\n",
    "comp_ctgov_npi.numeric (left_on=\"postcode_int\", right_on=\"postcode_int\", method='exp', label='postcode')\n",
    "comp_ctgov_npi.exact(left_on=\"state\", right_on=\"state\", label='state')\n",
    "f_unknown = comp_ctgov_npi.compute(pairs=pairs_lsh_unknowns, x=dfCTGov, x_link=dfNPI)\n",
    "f_unknown"
   ],
   "id": "e782a69b3ab91da6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       given_name_ph  surname_ph  given_name   surname  \\\n",
       "dfA_rec_id dfB_rec_id                                                    \n",
       "3          294912                  0           0    0.458333  0.448413   \n",
       "           329728                  0           0    0.444444  0.448413   \n",
       "           388097                  1           1    1.000000  0.448413   \n",
       "           304132                  0           0    0.472222  0.448413   \n",
       "           36357                   0           0    0.464286  0.448413   \n",
       "...                              ...         ...         ...       ...   \n",
       "196587     73705                   0           0    0.000000  0.000000   \n",
       "           98281                   0           0    0.722222  0.000000   \n",
       "           253930                  0           0    0.444444  0.000000   \n",
       "           868333                  0           0    0.000000  0.000000   \n",
       "           819198                  0           0    0.430556  0.000000   \n",
       "\n",
       "                       city_ph   city       postcode  state  \n",
       "dfA_rec_id dfB_rec_id                                        \n",
       "3          294912            1  1.000   1.250000e-01      1  \n",
       "           329728            1  1.000   1.250000e-01      1  \n",
       "           388097            0  0.125  1.520873e-210      1  \n",
       "           304132            1  1.000   1.250000e-01      1  \n",
       "           36357             1  1.000   1.000000e+00      1  \n",
       "...                        ...    ...            ...    ...  \n",
       "196587     73705             1  1.000   1.000000e+00      1  \n",
       "           98281             1  1.000   1.220703e-04      1  \n",
       "           253930            1  1.000   2.384186e-07      1  \n",
       "           868333            1  1.000   2.384186e-07      1  \n",
       "           819198            1  1.000   2.500000e-01      1  \n",
       "\n",
       "[114114070 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>city</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfA_rec_id</th>\n",
       "      <th>dfB_rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>294912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.250000e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329728</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.250000e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388097</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.520873e-210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.250000e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36357</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">196587</th>\n",
       "      <th>73705</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98281</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.220703e-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868333</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114114070 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will be using the FEBRL data generated at the beginning of this workbook as our training data. We will slightly alter `dfA` and `dfB` to align column names to our unknowns data and reprocess comparisons.",
   "id": "4de5b91ca0751533"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T12:22:27.664788Z",
     "start_time": "2025-05-13T12:22:23.845021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfA_train = dfA.rename(columns={'suburb':'city', 'suburb_ph':'city_ph'})\n",
    "dfB_train = dfB.rename(columns={'suburb':'city', 'suburb_ph':'city_ph'})\n",
    "f_train = comp_ctgov_npi.compute(pairs=pairs_lsh, x=dfA_train, x_link=dfB_train)\n",
    "f_train"
   ],
   "id": "663b8ac396b2dd92",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\Users\\v_mar\\OneDrive\\Documents\\KU\\CPSC548\\FinalProject\\record_linkage\\venv\\Lib\\site-packages\\recordlinkage\\algorithms\\string.py:56: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - levenshtein_distance(x[0], x[1]) / np.max([len(x[0]), len(x[1])])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                             given_name_ph  surname_ph  given_name   surname  \\\n",
       "rec_id_1     rec_id_2                                                          \n",
       "rec-1070-org rec-4233-dup-0              0           0    0.527778  0.542857   \n",
       "             rec-3674-dup-0              0           0    0.513889  0.542857   \n",
       "             rec-2473-dup-0              0           0    0.713095  0.542857   \n",
       "rec-1016-org rec-1209-dup-0              1           0    1.000000  0.601190   \n",
       "             rec-2389-dup-0              1           0    1.000000  0.601190   \n",
       "...                                    ...         ...         ...       ...   \n",
       "rec-66-org   rec-987-dup-0               0           0    0.000000  0.403704   \n",
       "             rec-592-dup-0               0           0    0.466667  0.403704   \n",
       "             rec-2962-dup-0              0           0    0.447619  0.403704   \n",
       "             rec-852-dup-0               0           0    0.374074  0.403704   \n",
       "             rec-1156-dup-0              0           0    0.000000  0.403704   \n",
       "\n",
       "                             city_ph      city      postcode  state  \n",
       "rec_id_1     rec_id_2                                                \n",
       "rec-1070-org rec-4233-dup-0        0  0.461538  0.000000e+00      1  \n",
       "             rec-3674-dup-0        0  0.461538  0.000000e+00      1  \n",
       "             rec-2473-dup-0        0  0.538462  0.000000e+00      1  \n",
       "rec-1016-org rec-1209-dup-0        0  0.222222  0.000000e+00      1  \n",
       "             rec-2389-dup-0        0  0.111111  2.430865e-63      1  \n",
       "...                              ...       ...           ...    ...  \n",
       "rec-66-org   rec-987-dup-0         0  0.250000  3.622272e-71      1  \n",
       "             rec-592-dup-0         0  0.083333  0.000000e+00      1  \n",
       "             rec-2962-dup-0        0  0.250000  1.686752e-80      1  \n",
       "             rec-852-dup-0         0  0.071429  0.000000e+00      1  \n",
       "             rec-1156-dup-0        0  0.083333  1.019579e-56      1  \n",
       "\n",
       "[421590 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name_ph</th>\n",
       "      <th>surname_ph</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>city_ph</th>\n",
       "      <th>city</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rec-1070-org</th>\n",
       "      <th>rec-4233-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3674-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2473-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713095</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">rec-1016-org</th>\n",
       "      <th>rec-1209-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2389-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2.430865e-63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rec-66-org</th>\n",
       "      <th>rec-987-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.622272e-71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-592-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2962-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.686752e-80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-852-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374074</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1156-dup-0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.019579e-56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421590 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparison\n",
    "\n",
    "For our real-world test, we will compare one unsupervised (ECM) and one supeverised (Naive Bayesian Clssifier) learning algorithm with the goal being to match as many of the physicians listed in dfCTGov to physicians in dfNPI.\n",
    "\n",
    "#### Unsupervised Learning\n",
    "\n",
    "Since it is not necessary to train ECM, we will simply execute the `fit_predict` method and look at the resulting list of matches."
   ],
   "id": "e0e76ee7ea30b60b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:03:13.190306Z",
     "start_time": "2025-05-13T04:53:02.028213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ECM using LSH blocking\n",
    "rw_ecm = recordlinkage.ECMClassifier(binarize=0.97)\n",
    "rw_result_ecm = rw_ecm.fit_predict(f_unknown)\n",
    "rw_result_ecm\n"
   ],
   "id": "e313e890f52795ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(     3,  294912),\n",
       "            (     3,  329728),\n",
       "            (     3,  304132),\n",
       "            (     3,   36357),\n",
       "            (     3,  412676),\n",
       "            (     3,  527879),\n",
       "            (     3,  252936),\n",
       "            (     3,   73225),\n",
       "            (     3,  647175),\n",
       "            (     3, 1105927),\n",
       "            ...\n",
       "            (196587,  884678),\n",
       "            (196587, 1073098),\n",
       "            (196587, 1253328),\n",
       "            (196587,  532444),\n",
       "            (196587,  868318),\n",
       "            (196587,   73705),\n",
       "            (196587,   98281),\n",
       "            (196587,  253930),\n",
       "            (196587,  868333),\n",
       "            (196587,  819198)],\n",
       "           names=['dfA_rec_id', 'dfB_rec_id'], length=74007112)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T05:07:55.188178Z",
     "start_time": "2025-05-13T05:03:13.285655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfMatches = rw_result_ecm.to_frame(index=False)\n",
    "dfMergeLeft = dfMatches.merge(dfCTGov, left_on='dfA_rec_id', right_on='rec_id', how='inner')\n",
    "dfMergeRight = dfMatches.merge(dfNPI, left_on='dfB_rec_id', right_on='rec_id', how='inner')\n",
    "dfFinal = dfMergeLeft.merge(dfMergeRight, on=['dfA_rec_id','dfB_rec_id'], how='inner')\n",
    "dfFinal.set_index(['dfA_rec_id','dfB_rec_id'], inplace=True)\n",
    "dfFinal = dfFinal[['npi', 'nct_id', 'given_name_x','surname_x', 'city_x', 'state_x', 'postcode_x', 'given_name_y','surname_y', 'city_y', 'state_y', 'postcode_y']]\n",
    "dfFinal"
   ],
   "id": "36ddcce4f200c064",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              npi       nct_id given_name_x     surname_x  \\\n",
       "dfA_rec_id dfB_rec_id                                                       \n",
       "3          294912      1235179508  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "           329728      1558399709  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "           304132      1457393357  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "           36357       1114927472  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "           412676      1578572129  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "...                           ...          ...          ...           ...   \n",
       "196587     73705       1508853631  NCT02418442       EILEEN          RIFE   \n",
       "           98281       1952382202  NCT02418442       EILEEN          RIFE   \n",
       "           253930      1588615314  NCT02418442       EILEEN          RIFE   \n",
       "           868333      1649560806  NCT02418442       EILEEN          RIFE   \n",
       "           819198      1205068525  NCT02418442       EILEEN          RIFE   \n",
       "\n",
       "                           city_x  state_x postcode_x given_name_y surname_y  \\\n",
       "dfA_rec_id dfB_rec_id                                                          \n",
       "3          294912        MISSOULA  MONTANA      59804     KATHLEEN    ROGERS   \n",
       "           329728        MISSOULA  MONTANA      59804       THOMAS   MCMAHON   \n",
       "           304132        MISSOULA  MONTANA      59804       LAUREN    WILLIS   \n",
       "           36357         MISSOULA  MONTANA      59804      STEPHEN    POWELL   \n",
       "           412676        MISSOULA  MONTANA      59804       JUSTIN  JACOBSON   \n",
       "...                           ...      ...        ...          ...       ...   \n",
       "196587     73705       BIRMINGHAM  ALABAMA      35233       THOMAS  ATKINSON   \n",
       "           98281       BIRMINGHAM  ALABAMA      35233     KATHLEEN     BOWEN   \n",
       "           253930      BIRMINGHAM  ALABAMA      35233       TRACEY   HUMBERT   \n",
       "           868333      BIRMINGHAM  ALABAMA      35233         ADAM   EDWARDS   \n",
       "           819198      BIRMINGHAM  ALABAMA      35233     ANKREHAH   JOHNSON   \n",
       "\n",
       "                           city_y  state_y postcode_y  \n",
       "dfA_rec_id dfB_rec_id                                  \n",
       "3          294912        MISSOULA  MONTANA      59807  \n",
       "           329728        MISSOULA  MONTANA      59801  \n",
       "           304132        MISSOULA  MONTANA      59807  \n",
       "           36357         MISSOULA  MONTANA      59804  \n",
       "           412676        MISSOULA  MONTANA      59804  \n",
       "...                           ...      ...        ...  \n",
       "196587     73705       BIRMINGHAM  ALABAMA      35233  \n",
       "           98281       BIRMINGHAM  ALABAMA      35246  \n",
       "           253930      BIRMINGHAM  ALABAMA      35255  \n",
       "           868333      BIRMINGHAM  ALABAMA      35255  \n",
       "           819198      BIRMINGHAM  ALABAMA      35235  \n",
       "\n",
       "[74007112 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>given_name_x</th>\n",
       "      <th>surname_x</th>\n",
       "      <th>city_x</th>\n",
       "      <th>state_x</th>\n",
       "      <th>postcode_x</th>\n",
       "      <th>given_name_y</th>\n",
       "      <th>surname_y</th>\n",
       "      <th>city_y</th>\n",
       "      <th>state_y</th>\n",
       "      <th>postcode_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfA_rec_id</th>\n",
       "      <th>dfB_rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>294912</th>\n",
       "      <td>1235179508</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>KATHLEEN</td>\n",
       "      <td>ROGERS</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329728</th>\n",
       "      <td>1558399709</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>THOMAS</td>\n",
       "      <td>MCMAHON</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304132</th>\n",
       "      <td>1457393357</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>LAUREN</td>\n",
       "      <td>WILLIS</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36357</th>\n",
       "      <td>1114927472</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>POWELL</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412676</th>\n",
       "      <td>1578572129</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>JACOBSON</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">196587</th>\n",
       "      <th>73705</th>\n",
       "      <td>1508853631</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>THOMAS</td>\n",
       "      <td>ATKINSON</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98281</th>\n",
       "      <td>1952382202</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>KATHLEEN</td>\n",
       "      <td>BOWEN</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253930</th>\n",
       "      <td>1588615314</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>TRACEY</td>\n",
       "      <td>HUMBERT</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868333</th>\n",
       "      <td>1649560806</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>EDWARDS</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819198</th>\n",
       "      <td>1205068525</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>ANKREHAH</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74007112 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Supervised Learning\n",
    "\n",
    "Here we will train a Naive Bayesian Classifier using all 10k rows provided by the FEBRL dataset. Once the model is trained we will apply to our unknowns and again review results.\n"
   ],
   "id": "e341f73c1d9ed38c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:32:43.812623Z",
     "start_time": "2025-05-13T14:32:42.887716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#classify using Naive Bayes Classifier\n",
    "nbc_train = recordlinkage.NaiveBayesClassifier(binarize=0.97)\n",
    "nbc_train.fit(f_train, miTrueLinks)\n",
    "nbc_train_result = nbc_train.predict(f_train)\n",
    "recordlinkage.confusion_matrix(links_true=miTrueLinks, links_pred=nbc_train_result, total=len(dfA.index))"
   ],
   "id": "c284f47d509a80b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3945, 1055],\n",
       "       [ 314, -314]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:32:52.584240Z",
     "start_time": "2025-05-13T14:32:52.572218Z"
    }
   },
   "cell_type": "code",
   "source": "recordlinkage.fscore(links_true=miTrueLinks, links_pred=nbc_train_result)",
   "id": "b1a8103c7767b7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521438600280808"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:35:37.404768Z",
     "start_time": "2025-05-13T14:32:58.042641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rw_result_nbc = nbc_train.predict(f_unknown)\n",
    "dfMatches = rw_result_nbc.to_frame(index=False)\n",
    "dfMergeLeft = dfMatches.merge(dfCTGov, left_on='dfA_rec_id', right_on='rec_id', how='inner')\n",
    "dfMergeRight = dfMatches.merge(dfNPI, left_on='dfB_rec_id', right_on='rec_id', how='inner')\n",
    "dfFinal = dfMergeLeft.merge(dfMergeRight, on=['dfA_rec_id','dfB_rec_id'], how='inner')\n",
    "dfFinal.set_index(['dfA_rec_id','dfB_rec_id'], inplace=True)\n",
    "dfFinal = dfFinal[['npi', 'nct_id', 'given_name_x','surname_x', 'city_x', 'state_x', 'postcode_x', 'given_name_y','surname_y', 'city_y', 'state_y', 'postcode_y']]\n",
    "dfFinal"
   ],
   "id": "727196d28135a723",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              npi       nct_id given_name_x     surname_x  \\\n",
       "dfA_rec_id dfB_rec_id                                                       \n",
       "3          388097      1265455018  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "           36357       1114927472  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "           412676      1578572129  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "           252936      1962453159  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "           36368       1831199090  NCT06422806         JOHN  SCHALLENKAMP   \n",
       "...                           ...          ...          ...           ...   \n",
       "196587     515969      1942380290  NCT02418442       EILEEN          RIFE   \n",
       "           1253310     1043913155  NCT02418442       EILEEN          RIFE   \n",
       "           1073098     1538693742  NCT02418442       EILEEN          RIFE   \n",
       "           1253328     1164125282  NCT02418442       EILEEN          RIFE   \n",
       "           73705       1508853631  NCT02418442       EILEEN          RIFE   \n",
       "\n",
       "                           city_x  state_x postcode_x given_name_y  \\\n",
       "dfA_rec_id dfB_rec_id                                                \n",
       "3          388097        MISSOULA  MONTANA      59804         JOHN   \n",
       "           36357         MISSOULA  MONTANA      59804      STEPHEN   \n",
       "           412676        MISSOULA  MONTANA      59804       JUSTIN   \n",
       "           252936        MISSOULA  MONTANA      59804       TRAVIS   \n",
       "           36368         MISSOULA  MONTANA      59804      MICHAEL   \n",
       "...                           ...      ...        ...          ...   \n",
       "196587     515969      BIRMINGHAM  ALABAMA      35233       DANIEL   \n",
       "           1253310     BIRMINGHAM  ALABAMA      35233          DAX   \n",
       "           1073098     BIRMINGHAM  ALABAMA      35233      STEPHEN   \n",
       "           1253328     BIRMINGHAM  ALABAMA      35233         HOPE   \n",
       "           73705       BIRMINGHAM  ALABAMA      35233       THOMAS   \n",
       "\n",
       "                          surname_y      city_y  state_y postcode_y  \n",
       "dfA_rec_id dfB_rec_id                                                \n",
       "3          388097      SCHALLENKAMP    BILLINGS  MONTANA      59107  \n",
       "           36357             POWELL    MISSOULA  MONTANA      59804  \n",
       "           412676          JACOBSON    MISSOULA  MONTANA      59804  \n",
       "           252936         STRATFORD    MISSOULA  MONTANA      59804  \n",
       "           36368            SCHUTTE    MISSOULA  MONTANA      59804  \n",
       "...                             ...         ...      ...        ...  \n",
       "196587     515969              FEIG  BIRMINGHAM  ALABAMA      35233  \n",
       "           1253310          BUSHWAY  BIRMINGHAM  ALABAMA      35233  \n",
       "           1073098           WALKER  BIRMINGHAM  ALABAMA      35233  \n",
       "           1253328           HODSON  BIRMINGHAM  ALABAMA      35233  \n",
       "           73705           ATKINSON  BIRMINGHAM  ALABAMA      35233  \n",
       "\n",
       "[19039606 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>nct_id</th>\n",
       "      <th>given_name_x</th>\n",
       "      <th>surname_x</th>\n",
       "      <th>city_x</th>\n",
       "      <th>state_x</th>\n",
       "      <th>postcode_x</th>\n",
       "      <th>given_name_y</th>\n",
       "      <th>surname_y</th>\n",
       "      <th>city_y</th>\n",
       "      <th>state_y</th>\n",
       "      <th>postcode_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfA_rec_id</th>\n",
       "      <th>dfB_rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>388097</th>\n",
       "      <td>1265455018</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>BILLINGS</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36357</th>\n",
       "      <td>1114927472</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>POWELL</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412676</th>\n",
       "      <td>1578572129</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>JACOBSON</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252936</th>\n",
       "      <td>1962453159</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>TRAVIS</td>\n",
       "      <td>STRATFORD</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36368</th>\n",
       "      <td>1831199090</td>\n",
       "      <td>NCT06422806</td>\n",
       "      <td>JOHN</td>\n",
       "      <td>SCHALLENKAMP</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>SCHUTTE</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>59804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">196587</th>\n",
       "      <th>515969</th>\n",
       "      <td>1942380290</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>DANIEL</td>\n",
       "      <td>FEIG</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253310</th>\n",
       "      <td>1043913155</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>DAX</td>\n",
       "      <td>BUSHWAY</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073098</th>\n",
       "      <td>1538693742</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>WALKER</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253328</th>\n",
       "      <td>1164125282</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>HOPE</td>\n",
       "      <td>HODSON</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73705</th>\n",
       "      <td>1508853631</td>\n",
       "      <td>NCT02418442</td>\n",
       "      <td>EILEEN</td>\n",
       "      <td>RIFE</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "      <td>THOMAS</td>\n",
       "      <td>ATKINSON</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19039606 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Discussion\n",
    "\n",
    "The results we were able to achieve were promising but still in need of significant additional work. The output of both the ECM and Naive Bayes Classifier (NBC) did yield a significant number of matches, but it was clear that the matches identified were not well aligned with what a human would consider to be a match. The most obvious examples of this are the cases where the first name, city and state all matched but the last names did not. Here, both classifiers did not weight the last name score higher than the other values and thus identified a number of matches that clearly are not the same person. As humans, we subconsciously weight last names as a better indicator of matching than other values. Underlying the issue is that both ECM and NBC make the Conditional Independence assumption, which in this case is not accurate.\n",
    "\n",
    "In examples that were presented with the framework, initial index blocking was done using exact matching of the metaphone of last name. This technique effectively hides/compensates for the weighting of last name at the expense of eliminating possible matches that included a misspelling of the last name that impacted the metaphone.\n",
    "\n",
    "More recent work has focused on using LLMs for blocking and neural networks for classification to better compensate for the different weighting of values. Future work on this will build out a codebase based on LLM and NN.\n",
    "\n",
    "With respect to the use of LSH for blocking, further work is warranted. The current rate limiter is the time it takes to generate the MinHashes. This can be improved by parallelizing that step but time did not permit. Overall match performance was impacted by the tuning parameters provided to LSH and the selection of tuning parameters was driven mainly by runtime performance.\n",
    "\n",
    "Finally, it is suspected that better performance from NBS could be achieved if training data was developed from the two real-world datasets. The FEBRL dataset, while convenient, likely does not represent real-world matching problems. A manual matching effort that links a subset of these two datasets would likely have led to better outcomes as well."
   ],
   "id": "64206b6da320814e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "Christen, P. (2019). Data linkage: the big picture. Harvard Data Science Review, 1(2). https://doi.org/10.1162/99608f92.84deb5c4\n",
    "\n",
    "Christen, P (2012). *Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection*. Springer. DOI 10.1007/978-3-642-31164-2.\n",
    "\n",
    "Fellegi, I. P., & Sunter, A. B. (1969). A Theory for Record Linkage. Journal of the American Statistical Association, 64(328), 1183. https://doi.org/10.2307/2286061\n",
    "\n",
    "Winkler, W. (2002). Methods for Record Linkage and Bayesian Networks Methods for Record Linkage and Bayesian Networks. Retrieved May 5, 2025, from https://www.census.gov/content/dam/Census/library/working-papers/2002/adrm/rrs2002-05.pdf\n",
    "\n",
    "De Bruin, J. [J535D165]. (2023, July 20). Python Record Linkage Toolkit Documentation — Python Record Linkage Toolkit 0.15 documentation. Retrieved April 17, 2025, from https://recordlinkage.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Dutt, V. (2023, August 1). Understanding Locality-Sensitive hashing for entity matching. Medium. https://medium.com/@mailvdutt/understanding-locality-sensitive-hashing-for-entity-matching-ebed7998c64b\n",
    "\n",
    "Zhu, E. (Erik) \\[ekzhu\\]. (2024, June 3). datasketch: Big Data Looks Small — datasketch 1.6.5 documentation. Retrieved May 6, 2025, from https://ekzhu.com/datasketch/index.html\n",
    "\n",
    "Turk, J. (2023, November 17). Jellyfish. Retrieved May 6, 2025, from https://jamesturk.github.io/jellyfish/\n",
    "\n",
    "The closer, the better | ElasticSearch: The Definitive Guide [2.x] | Elastic. (n.d.). Elastic. Retrieved May 6, 2025, from https://www.elastic.co/guide/en/elasticsearch/guide/current/decay-functions.html#img-decay-functions\n",
    "\n",
    "AACT Database | Clinical Trials Transformation Initiative. (2025, April 30). Retrieved May 2, 2025, from https://aact.ctti-clinicaltrials.org/download\n",
    "\n",
    "NPI files. (2025, April 15). https://download.cms.gov/nppes/NPI_Files.html\n",
    "\n",
    "Boyanov, M. [mboyanov]. (2020, January 29). Google Colab. Retrieved May 7, 2025, from https://colab.research.google.com/github/mboyanov/minhash-demo/blob/master/Datasketch%20Demo.ipynb#scrollTo=wzZfQeLMeP3N"
   ],
   "id": "7442bf75306b9eb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Appendix 1: Computing Environment\n",
    "\n",
    "This is the computing environment used for metrics benchmarks reported in this workbook.\n",
    "\n",
    "![Computing Environment](images/ReferenceArchitecture.png)\n",
    "\n"
   ],
   "id": "9fc8f4d0350cc98d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
